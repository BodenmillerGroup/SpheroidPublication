#####################################################################
#### General setup of the environment
import pathlib
from snakemake.io import strip_wildcard_constraints, expand
from scripts import zenodo
import pandas as pd

# Global conda container
base_container = 'docker://votti/miniconda3mamba:mamba0.3.0'
# Ilastik configuration
## Rules to run ilastik pixel classification
include: 'rules/ilastik.smk'
## Ilastik container
ilastik_container = 'docker://ilastik/ilastik-from-binary:1.3.3b1'
# Cellprofiler (CP) configuration
## Rules to run cellprofiler via snakemake
include: 'rules/cellprofiler.smk'
## Cellprofiler container
cellprofiler_container = 'docker://cellprofiler/cellprofiler:3.1.9'
## Cellprofiler plugins
cp_plugins = 'resources/cp_plugins/ImcPluginsCP/plugins'

#####################################################################
#### External input data:
"""
Contains the repository ID on Zenodo of the data
used in this pipeline.
"""
input_zenodo_bf_repositories = [655990, 655992, 655994, 655996]


####################################################################
#### Input/output folder structure
# Resources folder: contains input data files
folder_resources = pathlib.Path('resources')
### Content
"""
Zipped, raw image data:
 -> This is automatically downloaded from Zenodo:
"""
folder_zip = folder_resources / 'zips'

"""
CP pipeline to prepare brightfield images for pixel classifiction
"""
fn_cp_scaling =  folder_resources / 'cp_pipelines/1_rescale_bf.cppipe'

"""
Trained Ilastik project that classifies pixels:
Classifies pixels as a) sphere center, b) sphere border, c) background
"""
fn_ilastik_proj = folder_resources / 'classifiers/bfsegmentation.ilp'

"""
CP pipeline to segment pixel probabilities
"""
fn_cp_segmentation =  folder_resources / 'cp_pipelines/2_segment_bf.cppipe'

"""
CP pipeline to measure segmented sphere masks
"""
fn_cp_measurement =  folder_resources / 'cp_pipelines/3_measure_bf.cppipe'

"""
CSV containing manual quality control classifications
This file was generated by runing the notebook: notebooks/2_manual_qc_results.ipynb
After manually sorting the QC images generated in the: notebooks/1_sphere_size.py.ipynb script
In order to adapt this for new data, first generate a CSV the columns but without
any entries, run notebooks/1_sphere_size.py.ipynb, then notebooks/1_sphere_size.py.ipynb
and then rerun the snakemake workflow.
"""
fn_manual_qc = folder_resources / 'bfqc_manual_v1.csv'

# Result folder for output/ temporary output for processing
folder_results = pathlib.Path('results')
"""
"""
folder_input = folder_results / 'bfimages'
"""
Temporary table that contains all input files:
Generated in order to cache the list of input files to avoid
repeated querying of Zenodo.
"""
fn_dat_input = folder_results / 'input_files.csv'

"""
Folder containing the images processed by cellprofiler
"""
folder_analysis = folder_results / 'tiff'

"""
Folder containing the scaled tiff images
"""
folder_scaled = folder_analysis / ('scaled')

"""
Folder containing the pixel probabilities
"""
folder_probab = folder_analysis / ('probab')

"""
Folder containing the masks
"""
folder_mask = folder_analysis / ('mask')

"""
Folder containing the cell profiler measurements:
fn_image: table of image level metadata and measurements
fn_mask: table of sphere level measurements
fn_experiment: metadata about the measurement pipeline
"""
folder_cp = folder_results / ('cpout')
fn_image = folder_cp / 'Image.csv'
fn_mask = folder_cp / 'mask.csv'
fn_experiment = folder_cp / 'Experiment.csv'
# Produce a list of all cellprofiler output files
cp_meas_output = [fn_image, fn_mask, fn_experiment]

"""
Folder containing overlays of the masks on the BF images
for visual inspection.
"""
folder_cp_ov = folder_cp / 'overlays'

"""
Folder containing plate overviews
"""
folder_plateov = folder_results / 'plate_overviews'

"""
Folder containing well overviews
"""
folder_wellov = folder_results / 'well_overviews'

"""
CSV containing sphere measurements for spheres that passed the manual
quality control
"""
fn_hqspheres = folder_results / 'hq_spheres.csv'

"""
Image containing the plate overview used in the workflow of Fig 1
"""
fn_fig1_bfspheres = folder_results / 'fig1_bfspheres.png'

####################################################################
#### Define helper variables
# Define filename suffixes
suffix_plate = '_p{platenr}'
suffix_scale = '_r5'
suffix_mask = '_mask'
suffix_probablities = '_Probabilities'
suffix_overlay = '_overlay'
suffix_tiff = '.tiff'
suffix_done = '.done'

## Generate patterns for files
pat_fn_zip = folder_zip / ('{zipfol}.zip')
pat_zenodo_rep = str(folder_resources / '{zenodo_folder}_zenodo_{zenodo_id}.done')
pat_has_zenodo_bfzip_repositories = str(folder_resources / f'{folder_zip.name}_zenodo_{{zenodo_id}}.done')


## Generate folders
folder_input.mkdir(exist_ok=True)
folder_zip.mkdir(exist_ok=True)

## Flag files
done_rescale = folder_analysis / 'rescale.done'
pat_fn_unzip_done = str(folder_input / ('{zipfol}' + suffix_done))
all_has_zenodo_bfzip_repositories = folder_zip / 'zenodo.done'

#######################################################################
# Derived (expected) files
"""
List of expected downloaded repository fodlers
"""
fns_has_zenodo_bfzip_repositories = expand(str(pat_has_zenodo_bfzip_repositories), zenodo_id=input_zenodo_bf_repositories)

def fns_zenodo_bfzips_done(wildcards):
    """
    Helper function that returns enumerates expedted
    unziped files once all data downloaded
    Returns: Expected unzip-flags

    """
    checkpoints.all_zenodo_bfzips.get()
    zipfols, = glob_wildcards(pat_fn_zip)
    return expand(pat_fn_unzip_done, zipfol=zipfols)


#####################################################################
# Snakemake rules
rule all:
    message: 'Listing output from this pipeline'
    input: fn_hqspheres

checkpoint define_input_files:
    """
    Generates and caches the list of files contained in the Zenodo repository.
    This is done to avoid the Zenodo API to be queried with each
    Snakemake invocation.
    """
    message: "Generate a list of input filenames from Zenodo"
    output: fn_dat_input
    run:
        dic_fn = zenodo.get_file_dicts(input_zenodo_bf_repositories)
        tup_fn = [(k, v) for k, v in dic_fn.items()]
        dat_input = pd.DataFrame(tup_fn, columns=['output_filename','input_url'])
        dat_input.to_csv(fn_dat_input, index=False)

rule retrieve_zenodo:
    message: 'Download files from Zenodo.'
    output:
          touch(pat_zenodo_rep)
    conda:
         'envs/env_zenodo.yml'
    params:
          fol_out = str(folder_resources / '{zenodo_folder}')
    shell:
         '''cd {params.fol_out}
         python -m zenodo_get  --sandbox {wildcards.zenodo_id}'''

checkpoint all_zenodo_bfzips:
    """
    Rule that checks if all files downloaded from Zenodo.
    """
    message: "All zip files downloaded from Zenodo"
    input: fns_has_zenodo_bfzip_repositories
    output: touch(all_has_zenodo_bfzip_repositories)


rule unzip_bf_folder:
    message: "Unzip input zip files"
    input:
         fn_zip = pat_fn_zip
    output: touch(pat_fn_unzip_done)
    threads: 1
    params:
          fol_input = folder_input
    resources:
             mem_mb=lambda wildcards, attempt: (attempt * 4000),
             time='60'
    shell:
         'unzip -o {input.fn_zip} -d {params.fol_input}'

# Configuration for cellprofiler pipeline steps
# (Please look at rules/cellprofiler.smk for the documentation of this structure)
config_dict_cp = {
    'rescale': {
        'message':
            """
            Rescales the input images 0.5x smaller to speed up computations
            """,
        'run_size': 50,
        'plugins': cp_plugins,
        'pipeline': str(fn_cp_scaling),
        'input_files': [folder_input, fns_zenodo_bfzips_done],
        'output_patterns': {'scaled': directory(folder_scaled)},
    },
    'segmasks': {
        'message':
            """
            Segment probability maps into sphere masks.
            """,
        'run_size': 50,
        'plugins': cp_plugins,
        'pipeline': str(fn_cp_segmentation),
        'input_files': [folder_probab],
        'output_patterns': {'.': directory(folder_mask)},
    },
    'measuremasks': {
        'message':
            """
            Measures sphere masks.
            """,
        'run_size': 50,
        'plugins': cp_plugins,
        'pipeline': str(fn_cp_measurement),
        'input_files': [folder_mask, folder_scaled, folder_probab],
        'output_patterns': {'.': cp_meas_output, 'overlays': directory(folder_cp_ov)}
    }
}
## Rules to target Cellprofiler batch runs
define_cellprofiler_rules(config_dict_cp, folder_results, container_cp=cellprofiler_container)

# Configuration for Ilastik steps
# (Please look at rules/cellprofiler.smk for the documentation of this structure)
config_dict_ilastik = {
    'spheres': {
         'message':
            """
            Classifier to convert brightfield images into a probability
            mask with classes:
                sphere center: pixels in sphere center,
                sphere border: pixels at sphere border,
                background: background pixels
            
            For training only in-focus planes have been used.
            """,
         'project': str(fn_ilastik_proj),
         'run_size': 50,
         'output_format': 'tiff',
         'output_filename': f'{{nickname}}{suffix_probablities}{suffix_tiff}',
         'export_source': 'Probabilities',
         'export_dtype': 'uint8',
         'pipeline_result_drange': '"(0.0, 1.0)"',
         'input_files': str(folder_scaled),
         'output_pattern': directory(folder_probab)
         }
}

define_ilastik_rules(config_dict_ilastik, folder_results, threads=4,
                     mem_mb=15000, container_ilastik=ilastik_container)

rule nb_sphere_size:
    """
    This notebook analyses the sphere quantifications:
    - Fixing some errors in the metadata of the filenames
    - Identifying the plain most in focus plane
    - Printing images for manual quality control
    - Printing well/plate level overview images
    - Reading in manual quality control results
    - Writing out a table of sphere measurements for downstream analyses
    """
    message: 'Run notebook to consolidate sphere quantifications.'
    input:
        fol_images=folder_scaled,
        fn_mask=fn_mask,
        fn_images=fn_image,
        fol_overviews=folder_cp_ov,
        fol_masks=folder_mask,
        fn_manual_qc=fn_manual_qc
    output:
        fol_plateov = directory(folder_plateov),
        fol_wellov = directory(folder_wellov),
        fn_hqspheres = fn_hqspheres,
        fn_fig1_bfspheres = fn_fig1_bfspheres
    conda:
        'envs/bf.yml'
    container: base_container
    threads: 8
    resources:
        mem='32G'
    log:
        # optional path to the processed notebook
        notebook="logs/notebooks/1_sphere_size.py.ipynb"
    notebook:
        "notebooks/1_sphere_size.py.ipynb"



###################################################################
# Helpers:
fol_local = pathlib.Path('/mnt/scratch/vitoz/Git/SpheroidPublication')
fol_cluster = pathlib.Path('vizano@cluster.s3it.uzh.ch:/scratch/vizano/SpheroidPublication')
rule sync_to_cluster:
    shell:
         f'rsync -rtu {fol_local / "subworkflows/bf_preproc"} {fol_cluster / "subworkflows"} --progress --exclude=".*" --exclude="pkgs/" --exclude=".snakemake" --exclude="results/"'

rule sync_from_cluster:
    shell:
         f'rsync -rtu {fol_cluster / "subworkflows/bf_preproc"} {fol_local / "subworkflows"}  --progress --exclude=".*" --exclude="phys/resources" --exclude "phys/pkgs" --exclude="results/align_trakem2"'

