import pathlib
import os

from scripts import helpers as hpr
from snakemake.utils import validate
from snakemake.io import strip_wildcard_constraints, expand
import pandas as pd

# Global conda container
container: 'docker://votti/miniconda3mamba:mamba0.3.0'

# Cellprofiler/Ilastik rules
include: 'rules/cellprofiler.smk'
include: 'rules/ilastik.smk'

# Read Configuration
configfile: 'config/config_bf.yml'
validate(config, "schemas/config_bf.schema.yml")

# Extract variables from configuration
## Input/output
input_data_folders = config['input_data_folders']
input_file_regexp = config['input_file_regexp']
folder_base = pathlib.Path('results')

fn_dat_input = 'config/input_files.csv'

## Ilastik run config
ilastik_container = config['ilastik_container']

# Cellprofiler default config
cellprofiler_container = config['cellprofiler_container']
cp_plugins = config['cellprofiler_plugins']
# Define hardcoded variables
## Define basic folder structrue
folder_resources = pathlib.Path('resources')
fn_cp_scaling =  folder_resources / 'cp_pipelines/1_rescale_bf.cppipe'
fn_cp_segmentation =  folder_resources / 'cp_pipelines/2_segment_bf.cppipe'
fn_cp_measurement =  folder_resources / 'cp_pipelines/3_measure_bf.cppipe'
fn_ilastik_proj = folder_resources / 'classifiers/bfsegmentation.ilp'

fn_manual_qc = 'resources/bfqc_manual_v1.csv'

folder_analysis = folder_base / 'tiff'
folder_scaled = folder_analysis / ('scaled')
folder_probab = folder_analysis / ('probab')
folder_mask = folder_analysis / ('mask')
folder_cp = folder_base / ('cpout')
folder_cp_ov = folder_cp / 'overlays'

## Define Output files
fn_image = folder_cp / 'Image.csv'
fn_mask = folder_cp / 'mask.csv'
fn_experiment = folder_cp / 'Experiment.csv'

# Produce a list of all cellprofiler output files
cp_meas_output = [fn_image, fn_mask, fn_experiment]

# Identify a dictionary of input folders/zips containing .mcd files to process
dict_zip_fns = hpr.get_filenames_by_re(input_data_folders, input_file_regexp)

## Define suffixes
suffix_plate = '_p{platenr}'
suffix_scale = '_r5'
suffix_mask = '_mask'
suffix_probablities = '_Probabilities'
suffix_overlay = '_overlay'
suffix_tiff = '.tiff'

## Define derived file patterns
pat_basename_input = '{img_base}_Plate_{platenr, [0-9]+}/TimePoint_1/{img_base}{well}.TIF'
pat_basename_image = '{img_base}{well}'

folder_input = folder_resources / 'bfimages'
pat_fn_input= folder_input / pat_basename_input
pat_fn_plate = folder_analysis / (f'{pat_basename_image}{suffix_plate}{suffix_tiff}')
pat_fn_scaled = folder_analysis / (f'{pat_fn_plate.stem}{suffix_scale}{suffix_tiff}')
pat_fn_probabilities = folder_analysis / (f'{pat_fn_scaled.stem}{suffix_probablities}{suffix_tiff}')
pat_fn_mask= folder_analysis / (f'{pat_fn_probabilities.stem}{suffix_mask}{suffix_tiff}')
pat_fn_overlay= folder_cp_ov / (f'{pat_fn_scaled.stem}{suffix_overlay}{suffix_tiff}')

done_rescale = folder_analysis / 'rescale.done'
fol_scale_combined =  folder_analysis / 'cp_rescale'/ 'combined'

FN_DICT = None
def get_dict():
    global FN_DICT
    if FN_DICT is None:
        dat = pd.read_csv(fn_dat_input)
        d = {str(out): str(inp) for inp, out in dat.loc[:, ['input_filename', 'output_filename']].values}
        FN_DICT = d
    else:
        d = FN_DICT
    return d

# Define dynamic files
## Define (dynamic) input file functions
def fkt_fns_input(wildcards):
    """
    Identifies the input images.
    :param wildcards: wildcards dynamically provided by snakemake
    :return: A list of all `.ome.tiffs` generated.
    """
    checkpoints.define_input_files.get()
    fns_output = pd.read_csv(fn_dat_input)['output_filename']
    fns = [str(folder_input / fn) for fn in fns_output]
    return fns

## Define derived (dynamic) input files functions
## This generates functions to define input filenames based on other input filename functions

# Analysis scripts
folder_results = pathlib.Path('results')
folder_plateov = folder_results / 'plate_overviews'
folder_wellov = folder_results / 'well_overviews'
fn_hqspheres = folder_results / 'hq_spheres.csv'
fn_fig1_bfspheres = folder_results / 'fig1_bfspheres.png'

# Configuration for cellprofiler pipeline steps
# (Please look at rules/cellprofiler.smk for the documentation of this structure)
config_dict_cp = {
    'rescale': {
        'run_size': 50,
        'plugins': cp_plugins,
        'pipeline': str(fn_cp_scaling),
        'input_files': [fkt_fns_input],
        'output_patterns': {'scaled': directory(folder_scaled)},
    },
    'segmasks': {
        'run_size': 50,
        'plugins': cp_plugins,
        'pipeline': str(fn_cp_segmentation),
        'input_files': [folder_probab],
        'output_patterns': {'.': directory(folder_mask)},
    },
    'measuremasks': {
        'run_size': 50,
        'plugins': cp_plugins,
        'pipeline': str(fn_cp_measurement),
        'input_files': [folder_mask, folder_scaled, folder_probab],
        'output_patterns': {'.': cp_meas_output, 'overlays': directory(folder_cp_ov)}
    }
}



# Configuration for Ilastik steps
# (Please look at rules/cellprofiler.smk for the documentation of this structure)
config_dict_ilastik = {
    'spheres':
        {'project': str(fn_ilastik_proj),
         'run_size': 50,
         'output_format': 'tiff',
         'output_filename': f'{{nickname}}{suffix_probablities}{suffix_tiff}',
         'export_source': 'Probabilities',
         'export_dtype': 'uint8',
         'pipeline_result_drange': '"(0.0, 1.0)"',
         'input_files': str(folder_scaled),
         'output_pattern': directory(folder_probab)
         }
}

# Target rules
rule all:
    input: cp_meas_output, folder_cp_ov, folder_scaled, fn_hqspheres

rule scaled_imgs:
    input:
         folder_scaled

rule input_imgs:
    input:
         fkt_fns_input

checkpoint define_input_files:
    output:
        fn_dat_input
    run:
        fns = hpr.get_filenames_by_re(input_data_folders, input_file_regexp)
        dat_input = (pd.DataFrame({'input_filename': fns})
                 .assign(output_filename= lambda d: d['input_filename']
        .map(lambda fn: fn.relative_to(fn.parent.parent.parent)))
                 )
        dat_input.to_csv('config/input_files.csv', index=False)

def get_fn_from(wildcards):
    rel_fol = expand(strip_wildcard_constraints(str(pathlib.Path(pat_fn_input).relative_to(folder_input))), **wildcards)[0]
    return get_dict()[rel_fol]

rule retrieve_input_files:
    input: fn_dat_input
    output: pat_fn_input
    params:
        fn_input_file = get_fn_from
    threads: 1
    shell:
        'rsync -u {params.fn_input_file} {output[0]}'
    #run:
    #    fn_output = pathlib.Path(output[0])
    #    fn_base_output = fn_output.relative_to(folder_input)
    #    fn_input = params[0][str(fn_base_output)]
    #    pathlib.Path(fn_output).parent.mkdir(exist_ok=True)
    #    shutil.copy(fn_input, fn_output)



rule nb_sphere_size:
    input:
        fol_images=folder_scaled,
        fn_mask=fn_mask,
        fn_images=fn_image,
        fol_overviews=folder_cp_ov,
        fol_masks=folder_mask,
        fn_manual_qc=fn_manual_qc
    output:
        fol_plateov = directory(folder_plateov),
        fol_wellov = directory(folder_wellov),
        fn_hqspheres = fn_hqspheres,
        fn_fig1_bfspheres = fn_fig1_bfspheres
    conda:
        'envs/bf.yml'
    threads: 8
    resources:
        mem='32G'
    log:
        # optional path to the processed notebook
        notebook="logs/notebooks/1_sphere_size.py.ipynb"
    notebook:
        "notebooks/1_sphere_size.py.ipynb"

fol_local = pathlib.Path('/mnt/scratch/vitoz/Git/SpheroidPublication')
fol_cluster = pathlib.Path('vizano@cluster.s3it.uzh.ch:/scratch/vizano/SpheroidPublication')
rule sync_to_cluster:
    shell:
         f'rsync -rtu {fol_local / "subworkflows/bf_preproc"} {fol_cluster / "subworkflows"} --progress --exclude=".*" --exclude="pkgs/" --exclude=".snakemake" --exclude="results/"'

rule sync_from_cluster:
    shell:
         f'rsync -rtu {fol_cluster / "subworkflows/bf_preproc"} {fol_local / "subworkflows"}  --progress --exclude=".*" --exclude="phys/resources" --exclude "phys/pkgs" --exclude="results/align_trakem2"'


## Rules to target Cellprofiler batch runs
define_cellprofiler_rules(config_dict_cp, folder_base, container_cp=cellprofiler_container)
define_ilastik_rules(config_dict_ilastik, folder_base, threads=4,
                     mem_mb=15000, container_ilastik=ilastik_container)

### Varia

rule clean:
    shell:
        "rm -R {folder_base}"