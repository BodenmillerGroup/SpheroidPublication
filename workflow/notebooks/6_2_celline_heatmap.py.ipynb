{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spherpro.bro as spb\n",
    "import spherpro.datastore as spd\n",
    "import spherpro.library as spl\n",
    "import spherpro.configuration as conf\n",
    "import spherpro.db as db\n",
    "import sqlalchemy as sa\n",
    "import imp\n",
    "import pycytools as pct\n",
    "import pycytools.library\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as gg\n",
    "import spherpro.library as lib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import pdb\n",
    "import pathlib\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = snakemake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the general correlation structure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spherpro.bromodules.helpers_vz as helpers_vz\n",
    "imp.reload(helpers_vz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurVariableHelper(helpers_vz.VariableBaseHelper):\n",
    "    COL_D2RIM = 'DistRim'\n",
    "    COL_GENE = 'gene'\n",
    "    COL_GENE_UNTAGGED = 'gene_untagged'\n",
    "    COL_TAG = 'tag'\n",
    "    COL_DOXO = 'doxocycline'\n",
    "    COL_DILUTION = 'dilution'\n",
    "    COL_GOODNAME = 'goodname'\n",
    "    COL_ISNB = 'isnb'\n",
    "    COL_FITTED = 'fitted'\n",
    "    COL_RESID = 'residual'\n",
    "    COL_IMGID = db.images.image_id.key\n",
    "    COL_OBJ_NR = db.objects.object_number.key\n",
    "    COL_FC = 'fc'\n",
    "    COL_P = 'p'\n",
    "    COL_DF = 'DF'\n",
    "    COL_DELTA = 'delta'\n",
    "    COL_TSTAT = 't'\n",
    "    COL_TAGSTAT = 'TagStat'\n",
    "    COL_POSSTAT = 'PosStat'\n",
    "    COL_WORKING = 'working'\n",
    "    COL_N = 'n'\n",
    "    COL_N_OVEREXPR = 'n_overexpr'\n",
    "    COL_FC_CENS = 'fc_cens'\n",
    "    COL_NB = 'nb'\n",
    "    COL_P_CORR = 'p_corrected'\n",
    "    COL_ISSIG = 'is_sig_sel'\n",
    "    COL_FITCONDITIONNAME = 'FitConditionName'\n",
    "    COL_VALUES = db.object_measurements.value.key\n",
    "\n",
    "    COL_COEFNAME = 'coefname'\n",
    "    \n",
    "    LAB_CELLLINE = 'Cellline'\n",
    "    LAB_TP = 'Timepoint'\n",
    "    LAB_CONC = 'Size'\n",
    "    \n",
    "V = CurVariableHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_MODTYPE = 'modtype'\n",
    "V.COL_MODEL = 'model'\n",
    "V.COL_MODELCLASS = 'modelclass'\n",
    "V.COL_METAL = 'metal'\n",
    "V.COL_MARKER_CLASS = 'marker_class'\n",
    "V.COL_IS_CC = 'is_cc'\n",
    "\n",
    "V.COL_CONDITION = V.COL_CONDNAME\n",
    "V.COL_TP = 'timepoint'\n",
    "V.COL_CONC = 'concentration'\n",
    "V.COL_CELLLINE = 'cellline'\n",
    "\n",
    "V.COL_CHANNEL = 'channel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    main_conds = [f'{cl}_c{c}_te%_tp{tp}' \n",
    "                  for cl, c, tp in \n",
    "                  [('293T', '0.5', '96'),\n",
    "                   ('HT29','0.5','96'),\n",
    "                   ('DLD1','0.5', '96'),\n",
    "                   ('T47D', '1.0', '96')] ]\n",
    "    main_conds_cl = ['293T', 'HT29', 'DLD1', 'T47D']\n",
    "    all_conds =  [f'{cl}_c{c}_te%_tp{tp}'  for cl in ['293T', 'HT29', 'DLD1', 'T47D'] for tp in ['72', '96'] for c in [  '0.25', '0.5', '1.0'] ]\n",
    "    fig2_cond = [main_conds[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_MEASTYPE = db.measurement_types.measurement_type.key\n",
    "V.COL_MEASID = db.measurements.measurement_id.key\n",
    "V.COL_VALUE = db.object_measurements.value.key\n",
    "MEAS_INTENSITY = 'Intensity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_cells = [colors.to_hex(c) for c in sns.color_palette('deep')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I added consoring as there were hugh outliers in the data\n",
    "def censor_dat(x, q=99.9):\n",
    "    x = np.copy(x)\n",
    "    p = np.percentile(x,q=q)\n",
    "    x[x> p] = p\n",
    "    return x\n",
    "\n",
    "def cur_logtransf(x):\n",
    "    return np.log10(x+0.1)\n",
    "\n",
    "def cur_transf(x):\n",
    "    x= censor_dat(x)\n",
    "    x= cur_logtransf(x)\n",
    "    return x\n",
    "\n",
    "def transf_intensities(dat, dat_measmeta):\n",
    "    ids = dat_measmeta.loc[dat_measmeta[V.COL_MEASTYPE] == MEAS_INTENSITY, V.COL_MEASID]\n",
    "    fil = dat[V.COL_MEASID].isin(ids)\n",
    "    dat = dat.copy()\n",
    "    dat.loc[fil, V.COL_VALUE] = dat.loc[fil, :].groupby(V.COL_MEASID).transform(cur_transf)\n",
    "    return dat\n",
    "\n",
    "def get_imgs_for_cond(condition_name):\n",
    "    q = (bro.session.query(db.images.image_id)\n",
    "     .join(db.conditions)\n",
    "     .join(db.valid_images)\n",
    "     .filter(db.conditions.condition_name.like(f'{condition_name}%')))\n",
    "    return [i[0] for i in q.all()] \n",
    "\n",
    "def get_condids_for_cond(condition_name):\n",
    "    q = (bro.session.query(db.conditions.condition_id)\n",
    "     .join(db.images)\n",
    "     .join(db.valid_images)\n",
    "     .filter(db.conditions.condition_name.like(f'{condition_name}%')))\n",
    "    return [i[0] for i in q.all()] \n",
    "\n",
    "def get_valid_filename(s):\n",
    "    s = str(s).strip().replace(' ', '_')\n",
    "    return re.sub(r'(?u)[^-\\w.]', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_config = sm.input.fn_config\n",
    "fn_modstats_out = sm.input.fn_config\n",
    "#fn_modstats_perrep ='../../figures/marker_relations_r2_fullqc_perrep.csv'\n",
    "fol_out_paper = pathlib.Path(sm.output.fol_out)\n",
    "fn_params = sm.input.fn_modstats_params\n",
    "fol_out = pathlib.Path(sm.output.fol_out)\n",
    "os.makedirs(fol_out, exist_ok=True)\n",
    "os.makedirs(fol_out_paper, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "bro = spb.get_bro(fn_config)\n",
    "\n",
    "\n",
    "hpr = helpers_vz.HelperVZ(bro)\n",
    "\n",
    "dat_pannelcsv = hpr.get_pannelcsv()\n",
    "\n",
    "\n",
    "dat_pannelcsv.loc[dat_pannelcsv['metal'] == 'Gd155',V.COL_WORKING] = True\n",
    "\n",
    "dat_measmeta = hpr.get_measuremeta(dat_pannelcsv,additional_measfilt=sa.and_(db.stacks.stack_name == 'ObjectStack',\n",
    "                                                                            db.measurements.measurement_name.in_(['dist-rim','NbMeandist-rim']),\n",
    "                                                                            db.ref_planes.channel_name == 'object'))\n",
    "\n",
    "dat_imgmeta = hpr.get_imgmeta()\n",
    "#dat_imgmeta[V.COL_CONDLEVEL] = dat_imgmeta[V.COL_CONDID].map(str)\n",
    "#dat_imgmeta[V.COL_SITELEVEL] = dat_imgmeta[V.COL_SITEID].map(str)\n",
    "\n",
    "\n",
    "fil_good_meas = hpr.get_fil_good_meas(dat_measmeta)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dat_measmeta = dat_measmeta.merge(dat_pannelcsv[[V.COL_METAL, V.COL_MARKER_CLASS]],how='left')\n",
    "dat_measmeta = dat_measmeta.merge(dat_pannelcsv, how='left')\n",
    "dat_measmeta[V.COL_IS_CC] = dat_measmeta[V.COL_IS_CC] == 1\n",
    "#dat_measmeta[V.COL_IS_CC] = False\n",
    "dat_measmeta = dat_measmeta.set_index(V.COL_MEASID, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_dict = {r['metal']: r[V.COL_GOODNAME] for _, r in bro.data.pannel.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_PARAMS = 'params' \n",
    "V.COL_VAR = 'variable'\n",
    "MOD_DIST = 'dist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_params = pd.read_csv(fn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOD_DIST = 'site'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_PARAMS_SITE = V.COL_PARAMS+V.COL_SITELEVEL\n",
    "V.COL_PARAMS_IMG = V.COL_PARAMS+V.COL_IMGLEVEL\n",
    "V.COL_PARAMS_COND = V.COL_PARAMS+V.COL_CONDLEVEL\n",
    "V.COL_FITCOND_NAME = V.COL_CONDNAME+'Fit'\n",
    "def get_cor_params(dat_mod_params):\n",
    "    fil =  (dat_mod_params[V.COL_MODELCLASS] == MOD_DIST)\n",
    "    cur_params = dat_mod_params.loc[fil, :]\n",
    "    fil = cur_params[V.COL_VAR].map(lambda x: ((x.startswith(V.COL_CONDLEVEL))))\n",
    "    cur_params_cond = cur_params.loc[fil, :].copy()\n",
    "    fil = cur_params[V.COL_VAR].map(lambda x: ((x.startswith(V.COL_IMGLEVEL))))\n",
    "    cur_params_img = cur_params.loc[fil, :].copy()\n",
    "    cur_params_img[V.COL_IMGLEVEL] = cur_params_img.groupby([V.COL_VAR])[V.COL_VAR].transform(\n",
    "        lambda x: x.values[0].replace(V.COL_IMGLEVEL,'').replace('[T.','').replace(']',''))\n",
    "    cur_params_img = cur_params_img.rename(columns={V.COL_PARAMS: V.COL_PARAMS_IMG,\n",
    "                                                     V.COL_CONDNAME: V.COL_FITCOND_NAME})\n",
    "    #cur_params_site = cur_params_site.rename(columns={V.COL_PARAMS: V.COL_PARAMS_SITE,\n",
    "    #                                                 V.COL_CONDNAME: V.COL_FITCOND_NAME})\n",
    "    #cur_params_cond[V.COL_CONDLEVEL] = cur_params_cond.groupby([V.COL_VAR])[V.COL_VAR].transform(\n",
    "    #    lambda x: x.values[0].replace(V.COL_CONDLEVEL,'').replace('[T.','').replace(']',''))\n",
    "    #cur_params_cond = cur_params_cond.rename(columns={V.COL_PARAMS: V.COL_PARAMS_COND,\n",
    "    #                                                 V.COL_CONDNAME: V.COL_FITCOND_NAME})\n",
    "    \n",
    "    return cur_params_img\n",
    "\n",
    "def cor_intensities(dat,  dat_sitecor, dat_measmeta, dat_imgmeta, condition):\n",
    "    ids = dat_measmeta.loc[dat_measmeta[V.COL_MEASTYPE] == MEAS_INTENSITY, V.COL_MEASID]\n",
    "    fil = dat.index[dat[V.COL_MEASID].isin(ids)]\n",
    "    dat = dat.copy()\n",
    "    dat_cor = (dat[[V.COL_MEASID, V.COL_IMID, V.COL_OBJID]]\n",
    "               .merge(dat_measmeta[[V.COL_MEASID, V.COL_CHANNELNAME]])\n",
    "     .merge(dat_imgmeta[[V.COL_IMID, V.COL_SITELEVEL, V.COL_CONDITION, V.COL_CONDLEVEL, V.COL_IMGLEVEL]])\n",
    "     #.merge(dat_condcor[[V.COL_CHANNELNAME, V.COL_PARAMS_COND, V.COL_CONDLEVEL]]\n",
    "     .merge(dat_sitecor[[V.COL_CHANNELNAME, V.COL_PARAMS_IMG, V.COL_IMGLEVEL,V.COL_FITCOND_NAME]].query(f'{V.COL_FITCOND_NAME} == \"{condition}\"'))\n",
    "              )\n",
    "              \n",
    "    dat= dat.merge(dat_cor[[V.COL_MEASID, V.COL_OBJID, V.COL_PARAMS_IMG]], how='left').fillna(0)\n",
    "\n",
    "    dat[V.COL_VALUE] = dat[V.COL_VALUE] - dat[V.COL_PARAMS_IMG]\n",
    "    dat = dat.drop([V.COL_PARAMS_IMG], axis=1)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_sitecor = get_cor_params(dat_mod_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dat_hm_all = hpr.get_data( fil_good_meas=fil_good_meas, object_type='cell')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_d2rim = hpr.get_d2rim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate number of cells per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_imgmeta[V.COL_CONDNAME] = dat_imgmeta[db.images.condition_id.key].replace({i: c for c in C.all_conds for i in get_condids_for_cond(c)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_stats = dat_d2rim[[V.COL_IMGID]].merge(dat_imgmeta).groupby(V.COL_CONDNAME)[V.COL_IMGID, V.COL_CONDID].agg(**{'n': len, 'nu': lambda x: len(np.unique(x))})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_stats.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hm_data(cur_cond):\n",
    "    img_ids=get_imgs_for_cond(cur_cond)\n",
    "    dat = dat_hm_all.query(f'{V.COL_IMID} in {img_ids}')\n",
    "    dat = transf_intensities(dat, dat_measmeta)\n",
    "    #dat_transf_cor = cor_intensities(dat_transf, dat_sitecor, dat_condcor, dat_measmeta, dat_imgmeta)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conds = C.main_conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_measmeta = dat_measmeta.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "c = conds[1]\n",
    "d = get_hm_data(c)\n",
    "d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_cms = [get_hm_data(c) for c in conds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_ISNB = 'isnb'\n",
    "def plt_clustmat(dat_meas_raw, dat_measmeta, title=None, link=None,\n",
    "                         linkage_method='average', linkage_metric='Euclidean',\n",
    "                         corrmethod='pearson'):       \n",
    "    dat_meas = dat_meas_raw.pivot_table(values=V.COL_VALUES,\n",
    "                        index=V.COL_OBJID,\n",
    "                        columns=V.COL_MEASID)\n",
    "\n",
    "    dat_meas = dat_meas.dropna()\n",
    "    if corrmethod == 'pearson':\n",
    "        corrdat = np.corrcoef(dat_meas.T)\n",
    "    elif corrmethod == 'spearman':\n",
    "        corrdat, p = stats.spearmanr(dat_meas)\n",
    "    else:\n",
    "        raise f'{corrmethod} is not a valid corrmethod'\n",
    "        \n",
    "    dat_measmeta = dat_measmeta.set_index(V.COL_MEASID)\n",
    "\n",
    "    colnames = dat_measmeta.loc[dat_meas.columns.values,:].apply(\n",
    "        lambda x: ' - '.join([x[V.COL_ISNB], x[V.COL_GOODNAME]]), axis=1)\n",
    "    \n",
    "    c = sns.color_palette(\"Set2\", 10)\n",
    "\n",
    "    cols = []\n",
    "\n",
    "    for ch in colnames:\n",
    "        if ch.startswith('Int - object'):\n",
    "            cols.append(c[5])\n",
    "        elif ch.startswith('Int -'):\n",
    "            cols.append(c[7])\n",
    "        elif ch.startswith('Nb -'):\n",
    "            cols.append(c[2])\n",
    "        else:\n",
    "            raise('Invalid name')\n",
    "\n",
    "    cmap =sns.color_palette(\"RdBu_r\", 21)\n",
    "    hide_link = link is not None\n",
    "    if link is None:\n",
    "        link = hierarchy.linkage(corrdat, method=linkage_method,\n",
    "                                 metric=linkage_metric, optimal_ordering=True)\n",
    "    cg = sns.clustermap(pd.DataFrame(corrdat, index=colnames, columns=colnames),\n",
    "                       row_colors=cols, figsize=(15,15), row_linkage=link, col_linkage=link,\n",
    "                       center=0,cmap=cmap,  yticklabels=1, xticklabels=1,\n",
    "                       dendrogram_ratio=0.1)\n",
    "    plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "    plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), rotation=-90)\n",
    "    plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), size=8)\n",
    "    plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), size=8)\n",
    "    #cg.fig.subplots_adjust(bottom=0.3)\n",
    "    #cg.fig.subplots_adjust(right=0.7)\n",
    "    #sns.set(font_scale=0.2)\n",
    "    if hide_link:\n",
    "        cg.ax_row_dendrogram.set_visible(False)\n",
    "        cg.ax_col_dendrogram.set_visible(False)\n",
    "    if title is not None:\n",
    "        plt.suptitle(title)\n",
    "    return cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_metric = 'correlation'\n",
    "link_method = 'average'\n",
    "cgs_cor = [plt_clustmat(cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c),\n",
    "                                 dat_measmeta, title=c+'-Corr',\n",
    "                                linkage_metric=link_metric,\n",
    "                                 linkage_method=link_method,\n",
    "                                ) for d,c in zip([dat_cms[1]], [conds[1]])]\n",
    "\n",
    "for cg, c in zip(cgs_cor, conds):\n",
    "    cg.savefig(fol_out_paper / get_valid_filename(f'corrmat_{c}_{link_metric}_{link_method}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_metric = 'correlation'\n",
    "link_method = 'complete'\n",
    "cgs_cor = [plt_clustmat(cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c),\n",
    "                                 dat_measmeta, title=c+'-Corr',\n",
    "                             corrmethod='spearman',\n",
    "                                linkage_metric=link_metric,\n",
    "                                \n",
    "                                  linkage_method=link_method,\n",
    "                                ) for d,c in zip([dat_cms[1]], [conds[1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs_cor = [plt_clustmat(cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c),\n",
    "                                 dat_measmeta, title=c+'-Corr',\n",
    "                                linkage_metric='euclidean',\n",
    "                                 linkage_method='ward'\n",
    "                                ) for d,c in zip([dat_cms[1]], [conds[1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_metric = 'correlation'\n",
    "link_method = 'complete'\n",
    "cgs_cor = [plt_clustmat(cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c),\n",
    "                                 dat_measmeta, title=c+'-Corr',\n",
    "                                linkage_metric=link_metric,\n",
    "                                 linkage_method=link_method,\n",
    "                                ) for d,c in zip(dat_cms, conds)]\n",
    "\n",
    "for cg, c in zip(cgs_cor, conds):\n",
    "    cg.savefig(fol_out_paper / get_valid_filename(f'corrmat_{c}_{link_metric}_{link_method}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs_cor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs_cor = [plt_clustmat(cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c),\n",
    "                                 dat_measmeta, title=c+'-Corr',\n",
    "                                linkage_metric='cosine',\n",
    "                                 linkage_method='complete'\n",
    "                                ) for d,c in zip(dat_cms, conds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs_corcor = [plt_clustmat(cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c),\n",
    "                                 dat_measmeta, title=c+'-Corr',\n",
    "                                linkage_metric='euclidean',\n",
    "                                 linkage_method='average'\n",
    "                                ) for d,c in zip(dat_cms, conds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quick check if the correlations make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = get_hm_data(C.fig2_cond[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcorr = cor_intensities(dat, dat_sitecor, dat_measmeta, dat_imgmeta, C.fig2_cond[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_d2rim = dat_measmeta.query(f'{V.COL_MEASNAME} == \"dist-rim\"')[V.COL_MEASID].iloc[0]\n",
    "\n",
    "meas_cyclin  =  dat_measmeta.query(f'({V.COL_MEASNAME} == \"MeanIntensityComp\") &\\\n",
    "                ({V.COL_CHANNELNAME} == \"Nd145\")')[V.COL_MEASID].iloc[0]\n",
    "d= dcorr.query(f'{V.COL_MEASID} in {[meas_d2rim, meas_cyclin]}').pivot_table(V.COL_VALUE, V.COL_OBJID,\n",
    "                                                                         V.COL_MEASID)\n",
    "plt.hexbin(d[meas_d2rim], d[meas_cyclin])\n",
    "plt.show()\n",
    "d= dat.query(f'{V.COL_MEASID} in {[meas_d2rim, meas_cyclin]}').pivot_table(V.COL_VALUE, V.COL_OBJID,\n",
    "                                                                         V.COL_MEASID)\n",
    "plt.hexbin(d[meas_d2rim], d[meas_cyclin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "from patsy.builtins import Q\n",
    "from patsy import bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= dcorr.query(f'{V.COL_MEASID} in {[meas_d2rim, meas_cyclin]}').pivot_table(V.COL_VALUE, V.COL_OBJID,\n",
    "                                                                         V.COL_MEASID)\n",
    "ren = helpers_vz.Renamer()\n",
    "d=d.rename(columns=ren.rename)\n",
    "x=ren.rename(meas_d2rim)\n",
    "y=ren.rename(meas_cyclin)\n",
    "mod = smf.ols(f'{y}~bs({x},df=10)',d).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(d[x], d[y])\n",
    "plt.scatter(d[x], mod.predict(d[x]), s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mod.fittedvalues, mod.resid_pearson,s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "meas_cyclin  =  dat_measmeta.query(f'({V.COL_MEASNAME} == \"MeanIntensityComp\") &\\\n",
    "                ({V.COL_CHANNELNAME} == \"Yb171\")')[V.COL_MEASID].iloc[0]\n",
    "d= dcorr.query(f'{V.COL_MEASID} in {[meas_d2rim, meas_cyclin]}').pivot_table(V.COL_VALUE, V.COL_OBJID,\n",
    "                                                                         V.COL_MEASID)\n",
    "plt.hexbin(d[meas_d2rim], d[meas_cyclin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_cyclin  =  dat_measmeta.query(f'({V.COL_MEASNAME} == \"MeanIntensityComp\") &\\\n",
    "                ({V.COL_CHANNELNAME} == \"Yb171\")')[V.COL_MEASID].iloc[0]\n",
    "d= dat.query(f'{V.COL_MEASID} in {[meas_d2rim, meas_cyclin]}').pivot_table(V.COL_VALUE, V.COL_OBJID,\n",
    "                                                                         V.COL_MEASID)\n",
    "plt.hexbin(d[meas_d2rim], d[meas_cyclin])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Make a heatmap: d2rim bin vs marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_d2rim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_D2RIM = 'distrim'\n",
    "V.COL_D2RIM_BIN = V.COL_D2RIM+'bin'\n",
    "V.bin_stepsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_d2rim[V.COL_D2RIM_BIN] = np.digitize(dat_d2rim[V.COL_D2RIM], bins=np.arange(0,400,V.bin_stepsize))*V.bin_stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_d2rim = dat_measmeta.query(f'{V.COL_MEASNAME} == \"dist-rim\"')[V.COL_MEASID].iloc[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_d2rim_hm(dat, dat_d2rim, min_n=50, stat_agg='median', labs=[V.COL_GOODNAME],\n",
    "                 meas_name='MeanIntensityComp', title='', cmax=None, figsize=None, link=None):\n",
    "    cmap =sns.color_palette(\"RdBu_r\", 101)\n",
    "    dat_bin = (dat\n",
    "           .merge(dat_d2rim[[V.COL_OBJID, V.COL_D2RIM_BIN]])\n",
    "           .groupby([V.COL_MEASID, V.COL_D2RIM_BIN])[V.COL_VALUE]\n",
    "           .agg(**{V.COL_VALUE: stat_agg, 'n': 'count'})\n",
    "           #.apply(lambda x: stats.trim_mean(x,0.01))\n",
    "          .reset_index(drop=False)\n",
    "            .query(f'n > {min_n}')\n",
    "          )\n",
    "    dat_bin[V.COL_VALUE] =dat_bin.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda x: x-x.mean())\n",
    "    dat_bin =dat_bin.merge(dat_measmeta[[V.COL_MEASID, V.COL_MEASNAME]+labs])\n",
    "    if meas_name is not None:\n",
    "        dat_bin = dat_bin.query(f'{V.COL_MEASNAME} == \"{meas_name}\"')\n",
    "    dat_bin = (dat_bin\n",
    "               .pivot_table(index=labs,columns=V.COL_D2RIM_BIN, values=V.COL_VALUE))\n",
    "    if link is None:\n",
    "        link = hierarchy.linkage(dat_bin, metric='correlation', method='complete', optimal_ordering=True)\n",
    "    cg=sns.clustermap(dat_bin,\n",
    "               col_cluster=False, row_linkage=link,yticklabels=1, xticklabels=1,\n",
    "                      cmap=cmap, center=0,vmin=-cmax, vmax=cmax, figsize=figsize,\n",
    "                      dendrogram_ratio=0.1\n",
    "        \n",
    "              )\n",
    "    plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "    plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), rotation=-90)\n",
    "    plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), size=8)\n",
    "    plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), size=8)\n",
    "    #cg.fig.subplots_adjust(bottom=0.3)\n",
    "    #cg.fig.subplots_adjust(right=0.7)\n",
    "    plt.title(title)\n",
    "    return cg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs =[plot_d2rim_hm(cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c), dat_d2rim, title=c+'-Corr',\n",
    "                   stat_agg=lambda x: stats.trim_mean(x, 0.01), cmax=np.log10(3),figsize=(4,6)) for d,c in zip(dat_cms, conds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cg, c in zip(cgs, conds):\n",
    "    cg.savefig(fol_out_paper / get_valid_filename(f'main_dist_vs_mark_{c}.pdf'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "#all_cds = dat_condmeta[V.COL_CONDNAME].unique()\n",
    "cgs =[plot_d2rim_hm(cor_intensities(get_hm_data(c), dat_sitecor, dat_measmeta, dat_imgmeta, c), dat_d2rim, title=c+'-Corr',\n",
    "                   stat_agg=lambda x: stats.trim_mean(x, 0.01), cmax=np.log10(3),\n",
    "                   figsize=(6,8)) for c in all_cds]\n",
    "for cg, c in zip(cgs, all_cds):\n",
    "    cg.savefig(fol_out_paper / get_valid_filename(f'dist_vs_mark_{c}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_d2rim_hm_cont(dat, dat_d2rim, min_n=50, stat_agg='median', labs=[V.COL_GOODNAME, V.COL_CHANNELNAME],\n",
    "                 meas_name='MeanIntensityComp', title='', cmax=None):\n",
    "    cmap =sns.color_palette(\"viridis\", 101)\n",
    "    dat_bin = (dat\n",
    "           .merge(dat_d2rim[[V.COL_OBJID, V.COL_D2RIM_BIN]])\n",
    "           .groupby([V.COL_MEASID, V.COL_D2RIM_BIN])[V.COL_VALUE]\n",
    "           .agg(**{V.COL_VALUE: stat_agg, 'n': 'count'})\n",
    "           #.apply(lambda x: stats.trim_mean(x,0.0|1))\n",
    "          .reset_index(drop=False)\n",
    "            .query(f'n > {min_n}')\n",
    "          )\n",
    "    dat_bin[V.COL_VALUE] =dat_bin.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda x: x-x.min())\n",
    "    dat_bin =dat_bin.merge(dat_measmeta[[V.COL_MEASID, V.COL_MEASNAME]+labs])\n",
    "    if meas_name is not None:\n",
    "        dat_bin = dat_bin.query(f'{V.COL_MEASNAME} == \"{meas_name}\"')\n",
    "    dat_bin = (dat_bin\n",
    "               .pivot_table(index=labs,columns=V.COL_D2RIM_BIN, values=V.COL_VALUE))\n",
    "    link = hierarchy.linkage(dat_bin, metric='correlation', method='complete', optimal_ordering=True)\n",
    "    cg=sns.clustermap(dat_bin,\n",
    "               col_cluster=False, row_linkage=link,yticklabels=1, xticklabels=1,\n",
    "                      cmap=cmap\n",
    "                      #, center=0,vmin=-cmax, vmax=cmax\n",
    "\n",
    "              )\n",
    "    plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "    plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), rotation=-90)\n",
    "    plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), size=8)\n",
    "    plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), size=8)\n",
    "    cg.fig.subplots_adjust(bottom=0.3)\n",
    "    cg.fig.subplots_adjust(right=0.7)\n",
    "    plt.title(title)\n",
    "    return cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgs =[plot_d2rim_hm_cont(cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c), dat_d2rim, title=c+'-Corr',\n",
    "                   stat_agg=lambda x: stats.trim_mean(x, 0.01), cmax=np.log10(3)) for d,c in zip(dat_cms, conds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot distance to border vs pS6 in 293T, c1, tp=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = '293T_c1.0_te%_tp96'\n",
    "dat = get_hm_data(cond)\n",
    "\n",
    "dcorr = cor_intensities(dat, dat_sitecor, dat_measmeta, dat_imgmeta, C.fig2_cond[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_d2rim = dat_measmeta.query(f'{V.COL_MEASNAME} == \"dist-rim\"')[V.COL_MEASID].iloc[0]\n",
    "\n",
    "meas_cyclin  =  dat_measmeta.query(f'({V.COL_MEASNAME} == \"MeanIntensityComp\") &\\\n",
    "                ({V.COL_CHANNELNAME} == \"Yb171\")')[V.COL_MEASID].iloc[0]\n",
    "d= dcorr.query(f'{V.COL_MEASID} in {[meas_d2rim, meas_cyclin]}').pivot_table(V.COL_VALUE, V.COL_OBJID,\n",
    "                                                                         V.COL_MEASID)\n",
    "plt.hexbin(d[meas_d2rim], d[meas_cyclin])\n",
    "plt.show()\n",
    "d= dat.query(f'{V.COL_MEASID} in {[meas_d2rim, meas_cyclin]}').pivot_table(V.COL_VALUE, V.COL_OBJID,\n",
    "                                                                         V.COL_MEASID)\n",
    "plt.hexbin(d[meas_d2rim], d[meas_cyclin])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d2rim_hmdat(dat, dat_d2rim, stat_agg=np.mean, cmax=np.log10(3),min_n=100):\n",
    "    dat_bin = (dat\n",
    "           .merge(dat_d2rim[[V.COL_OBJID, V.COL_D2RIM_BIN]])\n",
    "           .groupby([V.COL_MEASID, V.COL_D2RIM_BIN])[V.COL_VALUE]\n",
    "           .agg(**{V.COL_VALUE: stat_agg, 'n': 'count'})\n",
    "           #.apply(lambda x: stats.trim_mean(x,0.01))\n",
    "          .reset_index(drop=False)\n",
    "            .query(f'n > {min_n}')\n",
    "          )\n",
    "    \n",
    "    dat_bin[V.COL_VALUE] =dat_bin.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda x: x-x.mean())     \n",
    "    dat_bin = (dat_bin\n",
    "               .pivot_table(index=[V.COL_MEASID],columns=V.COL_D2RIM_BIN, values=V.COL_VALUE))\n",
    "    return dat_bin\n",
    "    \n",
    "\n",
    "\n",
    "def plot_d2rim_hm(dat, dat_d2rim, min_n=50, stat_agg='median', labs=[V.COL_GOODNAME],\n",
    "                 meas_name='MeanIntensityComp', title='', cmax=None, figsize=None, link=None):\n",
    "    cmap =sns.color_palette(\"RdBu_r\", 101)\n",
    "    dat_bin = (dat\n",
    "           .merge(dat_d2rim[[V.COL_OBJID, V.COL_D2RIM_BIN]])\n",
    "           .groupby([V.COL_MEASID, V.COL_D2RIM_BIN])[V.COL_VALUE]\n",
    "           .agg(**{V.COL_VALUE: stat_agg, 'n': 'count'})\n",
    "           #.apply(lambda x: stats.trim_mean(x,0.01))\n",
    "          .reset_index(drop=False)\n",
    "            .query(f'n > {min_n}')\n",
    "          )\n",
    "    \n",
    "\n",
    "    dat_bin[V.COL_VALUE] =dat_bin.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda x: x-x.mean())\n",
    "    dat_bin =dat_bin.merge(dat_measmeta[[V.COL_MEASID, V.COL_MEASNAME]+labs])\n",
    "    if meas_name is not None:\n",
    "        dat_bin = dat_bin.query(f'{V.COL_MEASNAME} == \"{meas_name}\"')\n",
    "        \n",
    "\n",
    "    dat_bin = (dat_bin\n",
    "               .pivot_table(index=[V.COL_MEASID]+labs,columns=V.COL_D2RIM_BIN, values=V.COL_VALUE))\n",
    "    if link is None:\n",
    "        link = hierarchy.linkage(dat_bin, metric='correlation', method='complete', optimal_ordering=True)\n",
    "    \n",
    "    \n",
    "    cg=sns.clustermap(dat_bin,\n",
    "               col_cluster=False, row_linkage=link,yticklabels=1, xticklabels=1,\n",
    "                      cmap=cmap, center=0,vmin=-cmax, vmax=cmax, figsize=figsize,\n",
    "                      dendrogram_ratio=0.1\n",
    "        \n",
    "              )\n",
    "    plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
    "    plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), rotation=-90)\n",
    "    plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), size=8)\n",
    "    plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), size=8)\n",
    "    #cg.fig.subplots_adjust(bottom=0.3)\n",
    "    #cg.fig.subplots_adjust(right=0.7)\n",
    "    plt.title(title)\n",
    "    return cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cormat(dat, corrmethod='pearson'):       \n",
    "    dat_meas = dat.pivot_table(values=V.COL_VALUES,\n",
    "                        index=V.COL_OBJID,\n",
    "                        columns=V.COL_MEASID)\n",
    "\n",
    "    dat_meas = dat_meas.dropna()\n",
    "    if corrmethod == 'pearson':\n",
    "        corrdat = np.corrcoef(dat_meas.T)\n",
    "    elif corrmethod == 'spearman':\n",
    "        corrdat, p = stats.spearmanr(dat_meas)\n",
    "    else:\n",
    "        raise f'{corrmethod} is not a valid corrmethod'\n",
    "        \n",
    "    corrdat = pd.DataFrame(corrdat, index=dat_meas.columns, columns=dat_meas.columns)\n",
    "    return corrdat\n",
    "    \n",
    "    \n",
    "def get_measids(measmeta, col, val):\n",
    "    return measmeta.query(f'{col} == \"{val}\"')[V.COL_MEASID]\n",
    "    \n",
    "def calc_int_linkage(cormat, dat_measmeta, ref='Int', **kwargs):\n",
    "    int_measids =  get_measids(dat_measmeta, V.COL_ISNB, ref)\n",
    "    cm = cormat.loc[cormat.index.isin(int_measids), cormat.columns.isin(int_measids)]\n",
    "    link_clust = hierarchy.linkage(cm, optimal_ordering=True, **kwargs)\n",
    "    return link_clust, cm.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.fig2_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "c = C.fig2_cond[0]\n",
    "d = get_hm_data(c)\n",
    "d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_measids(dat_measmeta, label, idxvar=V.COL_MEASID):\n",
    "    lab_series = dat_measmeta[[idxvar, label]].drop_duplicates().set_index(idxvar)\n",
    "    return lab_series[label]\n",
    "\n",
    "def extend_linkage(link):\n",
    "    \"\"\"\n",
    "    Adds another row at index 0\n",
    "    \"\"\"\n",
    "    link = link.copy()\n",
    "    link[:, :2] +=1\n",
    "    new_row = [[0, max(link[:,0].max(),link[:,1].max())+1, link[:,2].max(), link[-1,3]+1]]\n",
    "    return np.concatenate((link, new_row))\n",
    "\n",
    "def plot_heatmaps(data, dat_measmeta, dat_d2rim, maskfkt=None,\n",
    "                 corrmethod='pearson', link_metric = 'correlation',\n",
    "                link_method = 'complete', dist_sep = True):\n",
    "    label = V.COL_GOODNAME\n",
    "    cmap =sns.color_palette(\"RdBu_r\", 21)\n",
    "    dend_space = 0.05\n",
    "    \n",
    "    cormat = calc_cormat(data,corrmethod=corrmethod)\n",
    "    if dist_sep:\n",
    "        m_dist = dat_measmeta.query(f'{V.COL_CHANNELNAME} == \"object\" & {V.COL_ISNB} == \"Int\"')[V.COL_MEASID].iloc[0]\n",
    "        print(m_dist)\n",
    "        link_clust, link_measids = calc_int_linkage(cormat, dat_measmeta.query(f'{V.COL_MEASID} not in [{m_dist}]'), method=link_method, metric=link_metric)\n",
    "        link_clust = extend_linkage(link_clust)\n",
    "        link_measids = [m_dist] + list(link_measids)\n",
    "    else:\n",
    "        link_clust, link_measids = calc_int_linkage(cormat, dat_measmeta, method=link_method, metric=link_metric)\n",
    "    \n",
    "    link_ord = hierarchy.leaves_list(link_clust)\n",
    "    # gete the channel names of these meas ids\n",
    "    link_channelnames = (dat_measmeta\n",
    "                       .set_index(V.COL_MEASID).loc[link_measids,:]\n",
    "                       [V.COL_CHANNELNAME]\n",
    "                      )\n",
    "    \n",
    "    int_meas = get_measids(dat_measmeta, V.COL_ISNB, 'Int')\n",
    "    \n",
    "\n",
    "    fil_measids = int_meas\n",
    "    cm = cormat.loc[cormat.index.isin(fil_measids), cormat.columns.isin(fil_measids)]\n",
    "    lab = label_measids(dat_measmeta, V.COL_CHANNELNAME)\n",
    "    cm = pd.DataFrame(cm.values, index=lab.loc[cm.index], columns=lab.loc[cm.columns])\n",
    "    cm = cm.loc[link_channelnames, link_channelnames]\n",
    "    \n",
    "    lab = label_measids(dat_measmeta, V.COL_GOODNAME, V.COL_CHANNELNAME)\n",
    "    cm = pd.DataFrame(cm.values, index=lab.loc[cm.index], columns=lab.loc[cm.columns])\n",
    "    cm = cm.iloc[:,link_ord]\n",
    "    if maskfkt is not None:\n",
    "        mask = maskfkt(cm.values)\n",
    "    else:\n",
    "        mask = None\n",
    "    cg_int = sns.clustermap(cm, row_linkage=link_clust, col_cluster=False, cmap=cmap, vmin=-1, vmax=1,\n",
    "               yticklabels=1, xticklabels=1,label='big', mask=mask)\n",
    "    \n",
    "    #cg_int.ax_col_dendrogram.set_visible(False)\n",
    "    cg_int.ax_heatmap.set_yticks([])\n",
    "    cg_int.ax_heatmap.set_ylabel('')\n",
    "    cg_int.ax_heatmap.set_xlabel('')\n",
    "    \n",
    "    \n",
    "    nb_meas = get_measids(dat_measmeta, V.COL_ISNB, 'Nb')\n",
    "    cm = cormat.loc[cormat.index.isin(int_meas), cormat.columns.isin(nb_meas)]\n",
    "    lab = label_measids(dat_measmeta, V.COL_CHANNELNAME)\n",
    "    cm = pd.DataFrame(cm.values, index=lab.loc[cm.index], columns=lab.loc[cm.columns])\n",
    "    cm = cm.loc[link_channelnames, link_channelnames]\n",
    "    \n",
    "    lab = label_measids(dat_measmeta, V.COL_GOODNAME, V.COL_CHANNELNAME)\n",
    "    cm = pd.DataFrame(cm.values, index=lab.loc[cm.index], columns=lab.loc[cm.columns])\n",
    "    cm = cm.iloc[link_ord,link_ord]\n",
    "    if maskfkt is not None:\n",
    "        mask = maskfkt(cm.values)\n",
    "    else:\n",
    "        mask = None\n",
    "    cg_nb = sns.clustermap(cm , row_cluster=False, col_cluster=False, cmap=cmap, vmin=-1, vmax=1,\n",
    "               yticklabels=1, xticklabels=1,label='big', mask=mask)\n",
    "    \n",
    "    \n",
    "    d_dat = data.query(f'{V.COL_MEASID} in {list(int_meas)}').copy()\n",
    "    # log transform d2rim\n",
    "    d2rim_idx = dat_measmeta.query(f'{V.COL_MEASID} in {list(int_meas)}').query(f'{V.COL_MEASNAME} == \"dist-rim\"')[V.COL_MEASID]\n",
    "    d_dat.loc[d_dat[V.COL_MEASID].isin(d2rim_idx), V.COL_VALUE] = d_dat.loc[d_dat[V.COL_MEASID].isin(d2rim_idx), V.COL_VALUE].map(np.log10)\n",
    "    \n",
    "    cm = get_d2rim_hmdat(d_dat, dat_d2rim, stat_agg=np.mean,min_n=100)\n",
    "                              \n",
    "    lab = label_measids(dat_measmeta, V.COL_CHANNELNAME)\n",
    "    cm = pd.DataFrame(cm.values, index=lab.loc[cm.index], columns=cm.columns)\n",
    "    cm = cm.loc[link_channelnames, :]\n",
    "    \n",
    "    lab = label_measids(dat_measmeta, V.COL_GOODNAME, V.COL_CHANNELNAME)\n",
    "    cm = pd.DataFrame(cm.values, index=lab.loc[cm.index], columns=cm.columns)\n",
    "                         \n",
    "    cmax = np.log10(3)\n",
    "    cg_d2rim= sns.clustermap(cm.iloc[link_ord, :], col_cluster=False, row_cluster=False,yticklabels=1, xticklabels=2,\n",
    "                      cmap=cmap, center=0,vmin=-cmax, vmax=cmax, figsize=(2,10),\n",
    "                      dendrogram_ratio=0.1,label='big'\n",
    "              )\n",
    "                       \n",
    "                       \n",
    "    cgs = [cg_int, cg_nb]\n",
    "    for cg in cgs:\n",
    "        cg.ax_heatmap.set_yticks([])\n",
    "    \n",
    "    cgs += [cg_d2rim]\n",
    "    \n",
    "    for cg in cgs:                        \n",
    "        cg.ax_heatmap.set_ylabel('')\n",
    "        cg.ax_heatmap.set_xlabel('')\n",
    "        cg.ax_heatmap.tick_params(labelsize=13)\n",
    "        plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), rotation=-90)\n",
    "        \n",
    "    return cormat, cgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.fig2_cond:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d_cor, dat_measmeta, dat_d2rim,\n",
    "                               link_metric = 'cosine',\n",
    "                link_method = 'average')\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)\n",
    "        #cg.savefig(fol_out_paper / get_valid_filename(f'corrmat_fig2_{cond}_{lab}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.main_conds:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d_cor, dat_measmeta, dat_d2rim,\n",
    "                               link_metric = 'cosine',\n",
    "                link_method = 'average')\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)\n",
    "        cg.savefig(fol_out_paper / get_valid_filename(f'corrmat_fig2_{cond}_{lab}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.main_conds:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d_cor, dat_measmeta, dat_d2rim, corrmethod='spearman',\n",
    "                               link_metric = 'cosine',\n",
    "                link_method = 'average')\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)\n",
    "        cg.savefig(fol_out_paper / get_valid_filename(f'corrmat_spearman_fig2_{cond}_{lab}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.fig2_cond:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d_cor, dat_measmeta, dat_d2rim, maskfkt = lambda x: np.abs(x) < 0.5,\n",
    "                               link_metric = 'cosine',\n",
    "                link_method = 'average')\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_measmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measids = dat_measmeta.query(f'({V.COL_CHANNELNAME}==\"Lu175\")')[V.COL_MEASID]\n",
    "\n",
    "cormat.loc[measids, measids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.fig2_cond:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d_cor, dat_measmeta, dat_d2rim,\n",
    "                       maskfkt = lambda x: np.abs(x) < 0.5)\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.main_conds:\n",
    "    d = get_hm_data(cond)\n",
    "    #d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d, dat_measmeta, dat_d2rim)\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)\n",
    "        cg.savefig(fol_out_paper / get_valid_filename(f'corrmat_uncorr_fig2_{cond}_{lab}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.fig2_cond:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d_cor, dat_measmeta, dat_d2rim, maskfkt = lambda x: (x) < 0.)\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.fig2_cond:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d_cor, dat_measmeta, dat_d2rim, maskfkt = lambda x: np.abs(x) < 0.99)\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.fig2_cond:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps(d_cor, dat_measmeta, dat_d2rim, maskfkt = lambda x: np.abs(x) < 0.4)\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.fig2_cond:\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    cormat, cgs = plot_heatmaps_3(d_cor, dat_measmeta, dat_d2rim,\n",
    "                               link_metric = 'cosine',\n",
    "                link_method = 'average', dist_sep=True)\n",
    "    for cg, lab in zip(cgs, ['int', 'nb', 'dist']):\n",
    "        cg.fig.suptitle(cond)\n",
    "        #cg.savefig(fol_out_paper / get_valid_filename(f'corrmat_fig2_{cond}_{lab}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cc = ['Dy163', 'Sm147', 'Er168',\n",
    "          'Lu175','Yb171',  'Eu153','Sm152','Dy161','Gd158'\n",
    "         ]\n",
    "\n",
    "measid_cc = dat_measmeta.query(f'({V.COL_CHANNELNAME} in {idx_cc}) &  ({V.COL_ISNB} == \"Int\")')[V.COL_MEASID]\n",
    "\n",
    "cm = get_d2rim_hmdat(d_cor.query(f'{V.COL_MEASID} in {list(measid_cc)}'), dat_d2rim,\n",
    "                     stat_agg=np.mean,min_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cm.stack().rename(V.COL_VALUE).reset_index().merge(dat_measmeta) \n",
    "    .assign(**{'normval':lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE]\n",
    "               .transform(lambda y: y/y.max())})\n",
    " \n",
    " >>\n",
    "    gg.ggplot(gg.aes(x=V.COL_D2RIM_BIN, y='normval', color = V.COL_GOODNAME))+\n",
    " gg.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cm.stack().rename(V.COL_VALUE).reset_index().merge(dat_measmeta) \n",
    "    .assign(**{'normval':lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE]\n",
    "               .transform(lambda y: y/y.max())})\n",
    " \n",
    " >>\n",
    "    gg.ggplot(gg.aes(x=V.COL_D2RIM_BIN, y='normval', color = V.COL_GOODNAME))+\n",
    " gg.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_cc = ['Dy163', 'Sm147', 'Er168',\n",
    "          'Lu175','Yb171',  'Eu153',\n",
    "          #'Sm152',\n",
    "          'Gd160',\n",
    "          'Dy161','Gd158'\n",
    "         ]\n",
    "meas_int = dat_measmeta.query(f'({V.COL_ISNB} == \"Int\")')[V.COL_MEASID]\n",
    "\n",
    "cm = get_d2rim_hmdat(d_cor.query(f'{V.COL_MEASID} in {list(meas_int)}'), dat_d2rim\n",
    "                     .assign(**{\n",
    "                         V.COL_D2RIM_BIN:\n",
    "                         lambda x: np.digitize(x[V.COL_D2RIM], bins=np.arange(0,400,5))*5}),\n",
    "                     stat_agg=np.mean,min_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cm.stack().rename(V.COL_VALUE).reset_index().merge(dat_measmeta) \n",
    "  .query(f'{V.COL_D2RIM_BIN} < 100') \n",
    "    .assign(**{'normval':lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE]\n",
    "               .transform(lambda y: (y-y.min())/(y.max()-y.min()))})\n",
    ">>\n",
    "     gg.ggplot(gg.aes(x=V.COL_D2RIM_BIN, y='normval', color = V.COL_GOODNAME))+\n",
    " gg.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod = (d_cor.query(f'{V.COL_MEASID} in {list(meas_int)}')\n",
    "     .merge(dat_d2rim)\n",
    "     .groupby(V.COL_MEASID)\n",
    "        .apply(lambda d: smf.ols(f'{V.COL_VALUE}~bs({V.COL_D2RIM},df=5)',d).fit())\n",
    ").rename('model')\n",
    "d_vals =  pd.DataFrame({V.COL_D2RIM: np.arange(2,100,1)})\n",
    "\n",
    "tdat = (dat_mod.groupby(V.COL_MEASID).apply(lambda x: \n",
    "                    pd.DataFrame({V.COL_D2RIM: d_vals[V.COL_D2RIM],\n",
    "                                  V.COL_VALUE: x.values[0].predict(d_vals)}),\n",
    "                          )\n",
    "  .assign(**{'val': lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda d:\n",
    "                                   (d-d.min())/(d.max()-d.min()))})\n",
    " .reset_index(V.COL_MEASID)\n",
    " .merge(dat_measmeta)\n",
    "       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat_mod.groupby(V.COL_MEASID).apply(lambda x: \n",
    "                    pd.DataFrame({V.COL_D2RIM: d_vals[V.COL_D2RIM],\n",
    "                                  V.COL_VALUE: x.values[0].predict(d_vals)}),\n",
    "                          )\n",
    "  .assign(**{'val': lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda d:\n",
    "                                   (d-d.min())/(d.max()-d.min()))})\n",
    " .reset_index(V.COL_MEASID)\n",
    " .merge(dat_measmeta)\n",
    " >>\n",
    "gg.ggplot(gg.aes(x=V.COL_D2RIM, y='val', color=V.COL_GOODNAME))+\n",
    " gg.geom_line()\n",
    "\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdat = (dat_mod.groupby(V.COL_MEASID).apply(lambda x: \n",
    "                    pd.DataFrame({V.COL_D2RIM: d_vals[V.COL_D2RIM],\n",
    "                                  V.COL_VALUE: x.values[0].predict(d_vals)}),\n",
    "                          )\n",
    "  .assign(**{'val': lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda d:\n",
    "                                   (d-d.min())/(d.max()-d.min()))})\n",
    " .reset_index(V.COL_MEASID)\n",
    " .merge(dat_measmeta)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tdat.query(f'{V.COL_CHANNELNAME} in {chan_cc}')\n",
    "\n",
    " >>\n",
    "gg.ggplot(gg.aes(x=V.COL_D2RIM, y='val', color=V.COL_GOODNAME))+\n",
    " gg.geom_line()\n",
    "\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tdat.query(f\"{V.COL_CHANNELNAME} in {['Yb171', 'Dy163', 'Er168', 'Lu175','Dy161', 'Eu153']}\")\n",
    "\n",
    " >>\n",
    "gg.ggplot(gg.aes(x=V.COL_D2RIM, y='val', color=V.COL_GOODNAME))+\n",
    " gg.geom_line()\n",
    " + gg.xlab('Distance-to-border [um]')\n",
    " + gg.ylab('Relative mean intensity [a.u.]')\n",
    "\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan = ['Dy163','Yb171','Er168', 'Lu175','Dy161' , 'Eu153']\n",
    "cm = (tdat.query(f\"{V.COL_CHANNELNAME} in {chan}\")\n",
    " .pivot_table(index=V.COL_CHANNELNAME, columns='distrim', values='val').loc[chan,:]\n",
    ")\n",
    "\n",
    "cg_d2rim= sns.clustermap(cm, col_cluster=False, row_cluster=False,yticklabels=1, xticklabels=2,\n",
    "                  center=0.5, figsize=(5,10),    cmap =sns.color_palette(\"RdBu_r\", 21),\n",
    "                  dendrogram_ratio=0.1,label='big'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.main_conds:\n",
    "    chan = ['Dy163','Yb171','Er168', 'Lu175','Eu153','Dy161']\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    d2r = dat_d2rim[[V.COL_OBJID,V.COL_D2RIM]].merge(d_cor[[V.COL_OBJID]])\n",
    "    d2r_min, d2r_max = d2r[V.COL_D2RIM].min(), d2r[V.COL_D2RIM].max()\n",
    "    dat_mod = (d_cor.query(f'{V.COL_MEASID} in {list(meas_int)}')\n",
    "         .merge(dat_d2rim)\n",
    "         .groupby(V.COL_MEASID)\n",
    "            .apply(lambda d: smf.ols(f'{V.COL_VALUE}~bs({V.COL_D2RIM},df=5)',d).fit())\n",
    "    ).rename('model')\n",
    "    d_vals =  pd.DataFrame({V.COL_D2RIM: np.arange(d2r_min,d2r_max,1)})\n",
    "\n",
    "    tdat = (dat_mod.groupby(V.COL_MEASID).apply(lambda x: \n",
    "                        pd.DataFrame({V.COL_D2RIM: d_vals[V.COL_D2RIM],\n",
    "                                      V.COL_VALUE: x.values[0].predict(d_vals)}),\n",
    "                              )\n",
    "      .assign(**{'val': lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda d:\n",
    "                                       (d-d.min())/(d.max()-d.min()))})\n",
    "     .reset_index(V.COL_MEASID)\n",
    "     .merge(dat_measmeta)\n",
    "           )\n",
    "\n",
    "    p = (tdat.query(f\"{V.COL_CHANNELNAME} in {chan}\")\n",
    "\n",
    "     >>\n",
    "    gg.ggplot(gg.aes(x=V.COL_D2RIM, y='val', color=V.COL_GOODNAME))+\n",
    "     gg.geom_line()+\n",
    "     gg.ggtitle(f'{cond}')\n",
    "          + gg.xlab('Distance-to-border [um]')\n",
    " + gg.ylab('Relative mean intensity [a.u.]')\n",
    "    +gg.theme(figure_size=(5,5))\n",
    "           )\n",
    "    p.draw()\n",
    "\n",
    "    cm = (tdat.query(f\"{V.COL_CHANNELNAME} in {chan}\")\n",
    "     .pivot_table(index=V.COL_CHANNELNAME, columns='distrim', values='val').loc[chan,:]\n",
    "    )\n",
    "    cm.columns = map(np.round, cm.columns)\n",
    "    cg_d2rim= sns.clustermap(cm, col_cluster=False, row_cluster=False,yticklabels=1, xticklabels=10,\n",
    "                      center=0.5, figsize=(5,10),    cmap =sns.color_palette(\"RdBu_r\", 199),\n",
    "                      dendrogram_ratio=0.1,label='big'\n",
    "              )\n",
    "    plt.suptitle(cond)\n",
    "    cg_d2rim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.main_conds:\n",
    "    chan = ['Yb171', 'Dy163', 'Lu175','Er168', 'Eu153', 'Dy161']\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    d2r = dat_d2rim[[V.COL_OBJID,V.COL_D2RIM]].merge(d_cor[[V.COL_OBJID]])\n",
    "    d2r_min, d2r_max = d2r[V.COL_D2RIM].min(), d2r[V.COL_D2RIM].max()\n",
    "    dat_mod = (d_cor.query(f'{V.COL_MEASID} in {list(meas_int)}')\n",
    "         .merge(dat_d2rim)\n",
    "         .groupby(V.COL_MEASID)\n",
    "            .apply(lambda d: smf.ols(f'{V.COL_VALUE}~cr({V.COL_D2RIM},df=10)',d).fit())\n",
    "    ).rename('model')\n",
    "    d_vals =  pd.DataFrame({V.COL_D2RIM: np.arange(d2r_min,d2r_max,1)})\n",
    "\n",
    "    tdat = (dat_mod.groupby(V.COL_MEASID).apply(lambda x: \n",
    "                        pd.DataFrame({V.COL_D2RIM: d_vals[V.COL_D2RIM],\n",
    "                                      V.COL_VALUE: x.values[0].predict(d_vals)}),\n",
    "                              )\n",
    "      .assign(**{'val': lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda d:\n",
    "                                       (d-d.min())/(d.max()-d.min()))})\n",
    "     .reset_index(V.COL_MEASID)\n",
    "     .merge(dat_measmeta)\n",
    "           )\n",
    "\n",
    "    p = (tdat.query(f\"{V.COL_CHANNELNAME} in {chan}\")\n",
    "\n",
    "     >>\n",
    "    gg.ggplot(gg.aes(x=V.COL_D2RIM, y='val', color=V.COL_GOODNAME))+\n",
    "     gg.geom_line()+\n",
    "     gg.ggtitle(f'{cond}')\n",
    "          + gg.xlab('Distance-to-border [um]')\n",
    " + gg.ylab('Relative mean intensity [a.u.]')\n",
    "    +gg.theme(figure_size=(5,5))\n",
    "           )\n",
    "    p.draw()\n",
    "\n",
    "    cm = (tdat.query(f\"{V.COL_CHANNELNAME} in {chan}\")\n",
    "     .pivot_table(index=V.COL_CHANNELNAME, columns='distrim', values='val').loc[chan,:]\n",
    "    )\n",
    "\n",
    "    cg_d2rim= sns.clustermap(cm, col_cluster=False, row_cluster=False,yticklabels=1, xticklabels=20,\n",
    "                      center=0.5, figsize=(5,10),    cmap =sns.color_palette(\"RdBu_r\", 21),\n",
    "                      dendrogram_ratio=0.1,label='big'\n",
    "              )\n",
    "    plt.suptitle(cond)\n",
    "    cg_d2rim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.main_conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in C.main_conds:\n",
    "    chan = ['Yb171', 'Dy163', 'Lu175','Er168', 'Eu153', 'Dy161']\n",
    "    d_min = 2\n",
    "    d_max = 81\n",
    "    d = get_hm_data(cond)\n",
    "    d_cor = cor_intensities(d, dat_sitecor, dat_measmeta, dat_imgmeta, cond)\n",
    "    d2r = dat_d2rim[[V.COL_OBJID,V.COL_D2RIM]].merge(d_cor[[V.COL_OBJID]])\n",
    "    d2r_min, d2r_max = d2r[V.COL_D2RIM].min(), d2r[V.COL_D2RIM].max()\n",
    "    dat_mod = (d_cor.query(f'{V.COL_MEASID} in {list(meas_int)}')\n",
    "         .merge(dat_d2rim)\n",
    "         .groupby(V.COL_MEASID)\n",
    "            .apply(lambda d: smf.ols(f'{V.COL_VALUE}~cr({V.COL_D2RIM},df=10)',d).fit())\n",
    "    ).rename('model')\n",
    "    d_vals =  pd.DataFrame({V.COL_D2RIM: np.arange(d_min,d_max,1)})\n",
    "    d_vals =  pd.DataFrame({V.COL_D2RIM: np.arange(d_min,d_max,1)})\n",
    "\n",
    "    tdat = (dat_mod.groupby(V.COL_MEASID).apply(lambda x: \n",
    "                        pd.DataFrame({V.COL_D2RIM: d_vals[V.COL_D2RIM],\n",
    "                                      V.COL_VALUE: x.values[0].predict(d_vals)}),\n",
    "                              )\n",
    "      .assign(**{'val': lambda x: x.groupby(V.COL_MEASID)[V.COL_VALUE].transform(lambda d: d-d.mean())})\n",
    "                                     #  (d-d.min())/(d.max()-d.min()))})\n",
    "     .reset_index(V.COL_MEASID)\n",
    "     .merge(dat_measmeta)\n",
    "           )\n",
    "\n",
    "    cm = (tdat.query(f\"{V.COL_CHANNELNAME} in {chan}\")\n",
    "     .pivot_table(index=V.COL_CHANNELNAME, columns='distrim', values='val').loc[chan,:]\n",
    "    )\n",
    "    cm.index= [chan_dict[c] for c in cm.index]\n",
    "\n",
    "    cg_d2rim= sns.clustermap(cm, col_cluster=False, row_cluster=False,yticklabels=1, xticklabels=20,\n",
    "                      center=0., figsize=(2.5,2),    cmap =sns.color_palette(\"RdBu_r\", 21),\n",
    "                      dendrogram_ratio=0.1,label='big',vmin=-np.log10(3), vmax=np.log10(3))\n",
    "          \n",
    "    cg_d2rim.ax_heatmap.set_xlabel('Distance to border [um]')\n",
    "    plt.suptitle(cond)\n",
    "    cg_d2rim.savefig(fol_out_paper / f'cellcycle_{cond}.pdf')\n",
    "    cg_d2rim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "10**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.3.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
