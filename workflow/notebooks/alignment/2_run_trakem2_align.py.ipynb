{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align IF to imc\n",
    "\n",
    "This will fine-align the coarsly IMC to IF images in two steps:\n",
    "- Align each slidescan scene to the matching IMC panorama images\n",
    "- Crop the Slidescan scene around the estimated spheroid crop location and fine-align IF and IMC on the spheroid level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import workflow.scripts.utils_alignment.library_java as libj\n",
    "import workflow.scripts.utils_alignment.library as lib\n",
    "import workflow.scripts.utils_alignment.alignment as alignment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import workflow.scripts.utils_alignment.variables as V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cin = snakemake.input\n",
    "Cout = snakemake.output\n",
    "Cparams = snakemake.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fol in [Cout.fol_out_trakem2, Cout.fol_spherecrop_aligned]:\n",
    "    pathlib.Path(Cout.fol_out_trakem2).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cout.fol_out_trakem2 = pathlib.Path(Cout.fol_out_trakem2).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cout.fol_spherecrop_aligned = pathlib.Path(Cout.fol_spherecrop_aligned ).resolve()\n",
    "Cout.fol_spherecrop_aligned.mkdir(parents=True, exist_ok=True)\n",
    "Cin.fol_cp_full = pathlib.Path(Cin.fol_cp_full).resolve()\n",
    "Cin.fol_out_imgs = pathlib.Path(Cin.fol_out_imgs).resolve()\n",
    "Cin.fol_crop = pathlib.Path(Cin.fol_crop).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dat_cords = pd.read_csv(Cin.fn_cords)\n",
    "\n",
    "dat_scenecords = pd.read_csv(Cin.fn_scenecords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_cropmeta = pd.read_csv(Cin.fn_cropmeta)\n",
    "dat_cropmeta = dat_cropmeta.merge(dat_cords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Get metadata for scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_if_imc_params = np.loadtxt(Cin.fn_transf_ifslide_imcslide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_if2imc = libj.params_to_affinetransform(transf_if_imc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow: https://imagej.net/TrakEM2_Scripting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Align IF to IMC using a rigid transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_coarse, params_fine = alignment.get_scene_alignparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_align = [params_coarse, params_fine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for idx, row in dat_cords[[V.SLIDESCAN, V.SCENEID]].drop_duplicates().iterrows():\n",
    "    alignment.align_scene(row[V.SLIDESCAN], row[V.SCENEID],\n",
    "                dat_scenecords,\n",
    "                dat_cords,\n",
    "                transf_scene2imc=at_if2imc,\n",
    "                fol_trakem2=Cout.fol_out_trakem2,\n",
    "                fol_imgs_scene=Cin.fol_out_imgs,\n",
    "                fol_imgs_imc=Cin.fol_cp_full,\n",
    "                align_params=params_align,\n",
    "                channel_slide=Cparams.channel_slide,\n",
    "                desc='v1')\n",
    "    print(list(filter(lambda x: 'corresponding features with an average displacement of' in x, filter(lambda x: x != '\\n', libj.logger.out))))\n",
    "    libj.logger.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now crop the 'spheres' using the cellprofiler file names, both in IF as well as IMC. then fine align the spheres and save out the aligned images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import skimage.io as skio\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rlist = []\n",
    "for idx, row in dat_cords[[V.SLIDESCAN, V.SCENEID]].drop_duplicates().iterrows():\n",
    "    slidescan, sceneid = row[V.SLIDESCAN], row[V.SCENEID]\n",
    "    d=alignment.get_params_from_project(Cout.fol_out_trakem2/ V.TPL_SLIDESCENE_ALIGN.format(slide=slidescan, scene=sceneid,\n",
    "                                                                             desc='v1'))\n",
    "    dat= pd.DataFrame(d)\n",
    "    dat[V.SLIDESCAN] = slidescan\n",
    "    dat[V.SCENEID] = sceneid\n",
    "    rlist.append(dat)\n",
    "    \n",
    "dat_params_scenealign = pd.concat(rlist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dat_scene_rcrop = dat_params_scenealign.merge(dat_cropmeta).apply(alignment.get_scene_rough_imccrop, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dat_scene_rcrop = dat_cropmeta.apply(alignment.get_scene_rough_imccrop, fol_trakem=Cout.fol_out_trakem2,\n",
    "                  axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Check which scenes have obviously not been matched correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_scene_rcrop.loc[(dat_scene_rcrop[V.CROPY] < 0) | (dat_scene_rcrop[V.CROPX] < 0) ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_scene_rcrop.to_csv(Cout.fn_scene_rcrop, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "-> Only 1 scene which is also blurry & out of focus, quite acceptable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alignment.crop_scene(dat_scene_rcrop, Cin.fol_out_imgs, Cin.fol_out_imgs, 'rcrop', channel=Cparams.channel_slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_scene_rcrop = pd.read_csv(Cout.fn_scene_rcrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramAffine = alignment.get_crop_alignparms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "libj.logger.clear_output()\n",
    "for (croppath), d in tqdm(dat_scene_rcrop.groupby(by=[V.CROPPATH])):\n",
    "    alignment.align_crops(croppath, dat_scene_rcrop, dat_cropmeta,\n",
    "                          Cout.fol_out_trakem2, Cin.fol_out_imgs, Cin.fol_crop, align_params=[paramAffine], cropdesc='rcrop', channel_slide=Cparams.channel_slide)\n",
    "    print(list(filter(lambda x: 'displacement' in x, filter(lambda x: x != '\\n', libj.logger.out))))\n",
    "    libj.logger.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rlist = []\n",
    "for idx, row in dat_scene_rcrop[[V.CROPPATH]].drop_duplicates().iterrows():\n",
    "    croppath = row[V.CROPPATH]\n",
    "    try:\n",
    "        d=alignment.get_params_from_project(Cout.fol_out_trakem2/ V.TPL_SLIDESCENE_CROP_ALIGN.format(\n",
    "                crop_path=croppath, cropdesc='rcrop', desc='v1'))\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    dat= pd.DataFrame(d)\n",
    "    dat[V.CROPPATH] = croppath \n",
    "    rlist.append(dat)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_params_fine = pd.concat(rlist).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(dat_params_fine.merge(dat_cropmeta, on=V.CROPPATH)\n",
    " .apply(alignment.crop_scene_fine, axis=1, fol_imgs=Cin.fol_out_imgs,\n",
    "        fol_out=Cout.fol_spherecrop_aligned, scale=2, channels=[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualize a random example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as skio\n",
    "import skimage.transform as sktransf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d= dat_params_fine.merge(dat_cropmeta, on=V.CROPPATH).iloc[20]\n",
    "transf = alignment.get_scene_fine_croptransf(d, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fn = Cin.fol_out_imgs/ V.TPL_SLIDESCENE_CROP_IMG.format(\n",
    "            crop_path=d[V.CROPPATH], channel=Cparams.channel_slide, cropdesc='rcrop', desc='v1')\n",
    "img = skio.imread(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fn = Cin.fol_crop/ (d[V.CROPPATH]+'.tiff')\n",
    "img_crop = skio.imread(fn)\n",
    "img_crop = sktransf.rescale(img_crop, 2)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "img_t = sktransf.warp(img, transf.inverse, output_shape=np.array(img_crop.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.sqrt(img_crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "im = np.zeros(list(img_t.shape)+[3])\n",
    "im[:,:,0] = img_t/img_t.max()\n",
    "im[:,:,1] = np.sqrt(img_crop)/np.sqrt(img_crop).max()\n",
    "im[im>1] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "fn = Cin.fol_out_imgs/ V.TPL_SLIDESCENE_CROP_IMG.format(\n",
    "            crop_path=d[V.CROPPATH], channel=Cparams.channel_slide, cropdesc='rcrop', desc='v1')\n",
    "img = skio.imread(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fn = Cin.fol_crop/ (d[V.CROPPATH]+'.tiff')\n",
    "img_crop = skio.imread(fn)\n",
    "img_crop = sktransf.rescale(img_crop, 2)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_t = sktransf.warp(img, transf.inverse, output_shape=np.array(img_crop.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.sqrt(img_crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.zeros(list(img_t.shape)+[3])\n",
    "im[:,:,0] = img_t/img_t.max()\n",
    "im[:,:,1] = np.sqrt(img_crop)/np.sqrt(img_crop).max()\n",
    "im[im>1] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.3.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
