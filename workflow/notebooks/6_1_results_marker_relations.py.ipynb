{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = snakemake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spherpro.bro as spb\n",
    "import spherpro.datastore as spd\n",
    "import spherpro.library as spl\n",
    "import spherpro.configuration as conf\n",
    "import spherpro.db as db\n",
    "import sqlalchemy as sa\n",
    "import imp\n",
    "import pycytools as pct\n",
    "import pycytools.library\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as gg\n",
    "import spherpro.library as lib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import pdb\n",
    "import pathlib\n",
    "import colorcet\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display\n",
    "\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.variables import Vars\n",
    "from src.config import Conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aim:\n",
    "\n",
    "Use the results from the variability analysis show that variability should not be seen as an additive effect.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Variability analysis\n",
    "Changes: try log10(x+0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spherpro.bromodules.helpers_vz as helpers_vz\n",
    "imp.reload(helpers_vz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_filename(s):\n",
    "    s = str(s).strip().replace(' ', '_')\n",
    "    return re.sub(r'(?u)[^-\\w.]', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurVariableHelper(Vars):\n",
    "    COL_D2RIM = 'DistRim'\n",
    "    COL_GENE = 'gene'\n",
    "    COL_GENE_UNTAGGED = 'gene_untagged'\n",
    "    COL_TAG = 'tag'\n",
    "    COL_DOXO = 'doxocycline'\n",
    "    COL_DILUTION = 'dilution'\n",
    "    COL_GOODNAME = 'goodname'\n",
    "    COL_ISNB = 'isnb'\n",
    "    COL_FITTED = 'fitted'\n",
    "    COL_RESID = 'residual'\n",
    "    COL_IMGID = db.images.image_id.key\n",
    "    COL_OBJ_NR = db.objects.object_number.key\n",
    "    COL_FC = 'fc'\n",
    "    COL_P = 'p'\n",
    "    COL_DF = 'DF'\n",
    "    COL_DELTA = 'delta'\n",
    "    COL_TSTAT = 't'\n",
    "    COL_TAGSTAT = 'TagStat'\n",
    "    COL_POSSTAT = 'PosStat'\n",
    "    COL_WORKING = 'working'\n",
    "    COL_N = 'n'\n",
    "    COL_N_OVEREXPR = 'n_overexpr'\n",
    "    COL_FC_CENS = 'fc_cens'\n",
    "    COL_NB = 'nb'\n",
    "    COL_P_CORR = 'p_corrected'\n",
    "    COL_ISSIG = 'is_sig_sel'\n",
    "    COL_FITCONDITIONNAME = 'FitConditionName'\n",
    "    COL_VALUES = db.object_measurements.value.key\n",
    "\n",
    "    COL_COEFNAME = 'coefname'\n",
    "    \n",
    "    LAB_CELLLINE = 'Cellline'\n",
    "    LAB_TP = 'Timepoint'\n",
    "    LAB_CONC = 'Size'\n",
    "    \n",
    "V = CurVariableHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_MODTYPE = 'modtype'\n",
    "V.COL_MODEL = 'model'\n",
    "V.COL_MODELCLASS = 'modelclass'\n",
    "V.COL_METAL = 'metal'\n",
    "V.COL_MARKER_CLASS = 'marker_class'\n",
    "V.COL_IS_CC = 'is_cc'\n",
    "\n",
    "V.COL_CONDITION = V.COL_CONDNAME\n",
    "V.COL_TP = 'timepoint'\n",
    "V.COL_CONC = 'concentration'\n",
    "V.COL_CELLLINE = 'cellline'\n",
    "\n",
    "V.COL_CHANNEL = 'channel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(Conf):  \n",
    "    main_conds = sm.params.main_conds\n",
    "    main_conds_cl = sm.params.celllines\n",
    "    all_conds =  sm.params.all_conds\n",
    "    fig2_cond = [main_conds[1]]\n",
    "    fn_config = sm.input.fn_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_MEASTYPE = db.measurement_types.measurement_type.key\n",
    "V.COL_MEASID = db.measurements.measurement_id.key\n",
    "V.COL_VALUE = db.object_measurements.value.key\n",
    "MEAS_INTENSITY = 'Intensity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_cells = [colors.to_hex(c) for c in sns.color_palette('deep')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I added consoring as there were hugh outliers in the data\n",
    "def censor_dat(x, q=99.9):\n",
    "    x = np.copy(x)\n",
    "    p = np.percentile(x,q=q)\n",
    "    x[x> p] = p\n",
    "    return x\n",
    "\n",
    "def cur_logtransf(x):\n",
    "    return np.log10(x+0.1)\n",
    "\n",
    "def cur_transf(x):\n",
    "    x= censor_dat(x)\n",
    "    x= cur_logtransf(x)\n",
    "    return x\n",
    "\n",
    "def transf_intensities(dat, dat_measmeta):\n",
    "    ids = dat_measmeta.loc[dat_measmeta[V.COL_MEASTYPE] == MEAS_INTENSITY, V.COL_MEASID]\n",
    "    fil = dat[V.COL_MEASID].isin(ids)\n",
    "    dat = dat.copy()\n",
    "    dat.loc[fil, V.COL_VALUE] = dat.loc[fil, :].groupby(V.COL_MEASID).transform(cur_transf)\n",
    "    return dat\n",
    "\n",
    "def get_imgs_for_cond(condition_name):\n",
    "    q = (bro.session.query(db.images.image_id)\n",
    "     .join(db.conditions)\n",
    "     .join(db.valid_images)\n",
    "     .filter(db.conditions.condition_name.like(f'{condition_name}%')))\n",
    "    return [i[0] for i in q.all()] \n",
    "\n",
    "def get_condids_for_cond(condition_name):\n",
    "    q = (bro.session.query(db.conditions.condition_id)\n",
    "     .join(db.images)\n",
    "     .join(db.valid_images)\n",
    "     .filter(db.conditions.condition_name.like(f'{condition_name}%')))\n",
    "    return [i[0] for i in q.all()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_config = C.fn_config\n",
    "fn_modstats_out = sm.input.fn_modstats\n",
    "fn_modstats_perrep = sm.input.fn_modstats_perrep\n",
    "fol_out_paper = pathlib.Path(sm.output.fol_out)\n",
    "fn_params = sm.input.fn_modstats_params\n",
    "fol_out = pathlib.Path(sm.output.fol_out)\n",
    "os.makedirs(fol_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_pannel_ord = pd.read_csv(sm.input.fn_panel_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "bro = spb.get_bro(fn_config)\n",
    "\n",
    "\n",
    "hpr = helpers_vz.HelperVZ(bro)\n",
    "\n",
    "dat_pannelcsv = hpr.get_pannelcsv()\n",
    "\n",
    "\n",
    "dat_pannelcsv.loc[dat_pannelcsv['metal'] == 'Gd155',V.COL_WORKING] = True\n",
    "\n",
    "dat_measmeta = hpr.get_measuremeta(dat_pannelcsv,additional_measfilt=sa.and_(db.stacks.stack_name == 'Dist',\n",
    "                                                                            db.measurements.measurement_name == 'dist-rim',\n",
    "                                                                            db.ref_planes.channel_name == 'object'))\n",
    "\n",
    "dat_imgmeta = hpr.get_imgmeta()\n",
    "#dat_imgmeta[V.COL_CONDLEVEL] = dat_imgmeta[V.COL_CONDID].map(str)\n",
    "#dat_imgmeta[V.COL_SITELEVEL] = dat_imgmeta[V.COL_SITEID].map(str)\n",
    "\n",
    "\n",
    "fil_good_meas = hpr.get_fil_good_meas(dat_measmeta)\n",
    "\n",
    "\n",
    "\n",
    "#dat_measmeta = dat_measmeta.merge(dat_pannelcsv[[V.COL_METAL, V.COL_MARKER_CLASS]],how='left')\n",
    "dat_measmeta = dat_measmeta.merge(dat_pannelcsv[[V.COL_METAL, V.COL_IS_CC]], how='left')\n",
    "dat_measmeta[V.COL_IS_CC] = dat_measmeta[V.COL_IS_CC] == 1\n",
    "#dat_measmeta[V.COL_IS_CC] = False\n",
    "dat_measmeta = dat_measmeta.set_index(V.COL_MEASID, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fol_out_paper.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_layout = pd.read_csv(bro.data.conf['layout_csv']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats = pd.read_csv(fn_modstats_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_var= V.COL_R2 = 'r2_adj_corr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as hclust\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.stats as spstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cluster_models = ['dist', 'nb', 'self', 'cc','int']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Make names for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COL_CLASS = 'class'\n",
    "COL_ORD_WITHIN = 'ord_within_class'\n",
    "cols = [V.COL_METAL, COL_CLASS, COL_ORD_WITHIN]\n",
    "class_ord = ['tag','egf','mtor', 'cellcycle', 'stress', 'apoptosis','total']\n",
    "dat_pannel_ord[COL_CLASS] = pd.Categorical(dat_pannel_ord[COL_CLASS], categories=class_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_d = {c: n for c, n in zip(dat_measmeta[V.COL_CHANNELNAME], dat_measmeta[V.COL_GOODNAME])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats[V.COL_GOODNAME] = dat_mod_stats[V.COL_CHANNELNAME].replace(name_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_IDCHANNAME = 'channel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats[V.COL_IDCHANNAME] = dat_mod_stats.apply(lambda x: x[V.COL_GOODNAME], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_pltname = dat_mod_stats.merge(dat_pannel_ord[[V.COL_METAL, COL_CLASS, COL_ORD_WITHIN]], left_on=V.COL_CHANNELNAME,\n",
    "                             right_on=V.COL_METAL).sort_values([ COL_CLASS, COL_ORD_WITHIN])[V.COL_IDCHANNAME].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats[V.COL_IDCHANNAME] = pd.Categorical(dat_mod_stats[V.COL_IDCHANNAME], categories=ord_pltname )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ord_pltname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Determine clustering of markers via clustering of the R2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_r2_clustering(dat):\n",
    "    cdat = (dat\n",
    "        .pivot_table(columns=V.COL_IDCHANNAME, values=V.COL_R2,\n",
    "                     index=[V.COL_MODELCLASS, V.COL_CONDNAME],\n",
    "                     aggfunc=np.median))\n",
    "\n",
    "    rlink =  hclust.linkage(cdat.T, metric='correlation', method='complete',optimal_ordering=True)\n",
    "    labels = cdat.columns\n",
    "    return rlink, labels\n",
    "\n",
    "def run_r2_clustering_cond(dat):\n",
    "    cdat = (dat\n",
    "        .pivot_table(columns=[V.COL_MODELCLASS,V.COL_IDCHANNAME], values=V.COL_R2, index=[ V.COL_CONDNAME],\n",
    "                                                                                            aggfunc=np.mean))\n",
    "\n",
    "    rlink =  hclust.linkage(cdat, metric='correlation', method='average',optimal_ordering=True)\n",
    "    labels = cdat.index\n",
    "    return rlink, labels\n",
    "\n",
    "def get_order_from_clust(rlink, labels):\n",
    "    return labels[hclust.leaves_list(rlink)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rlink, labs = run_r2_clustering(dat_mod_stats.loc[dat_mod_stats[V.COL_MODELCLASS].isin(cluster_models), :])\n",
    "\n",
    "#marklvl = (get_order_from_clust(rlink, labs))\n",
    "\n",
    "fig = plt.figure(figsize=(15,0.5))\n",
    "clust_res = hclust.dendrogram(rlink,labels=labs,\n",
    "                              leaf_rotation=90,color_threshold=0.4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "rlink, labs = run_r2_clustering(dat_mod_stats.loc[dat_mod_stats[V.COL_MODELCLASS].isin(cluster_models), :])\n",
    "\n",
    "marklvl = reversed(get_order_from_clust(rlink, labs))\n",
    "\n",
    "fig = plt.figure(figsize=(10,1))\n",
    "clust_res = hclust.dendrogram(rlink,labels=labs,\n",
    "                              leaf_rotation=90,color_threshold=1.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_modstats_perrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fol_out_paper/'marker_dendrogram.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlink, labs = run_r2_clustering_cond(dat_mod_stats.loc[dat_mod_stats[V.COL_MODELCLASS].isin(cluster_models), :])\n",
    "\n",
    "condlevel = get_order_from_clust(rlink, labs)\n",
    "plt.figure(figsize=(10,20))\n",
    "l = hclust.dendrogram(rlink,labels=labs, leaf_rotation=0, orientation=\"left\",color_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cat(x):\n",
    "    return pd.Categorical(x, categories=sorted(np.unique(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_layout.columns\n",
    "\n",
    "\n",
    "dat_layout=dat_layout.rename(columns={bro.data.conf['layout_csv']['condition_col']: V.COL_CONDNAME})\n",
    "\n",
    "dat_condmeta=(dat_layout.groupby(by=[V.COL_CELLLINE, V.COL_CONC, V.COL_TP])['well'].count()\n",
    "   .reset_index()\n",
    "   .assign(**{V.COL_CONDNAME: \n",
    "              lambda x: x.apply(\n",
    "                  lambda g: f'{g[V.COL_CELLLINE]}_c{g[V.COL_CONC]}_tp{g[V.COL_TP]}', axis=1)}))\n",
    "\n",
    "dat_condmeta[V.COL_CELLLINE] = pd.Categorical(dat_condmeta[V.COL_CELLLINE],\n",
    "                                              categories=C.main_conds_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M:\n",
    "    \"contains the strings of the different models\"\n",
    "    dist = 'dist'\n",
    "    nb = 'nb'\n",
    "    int = 'int'\n",
    "    cc ='cc'\n",
    "    self = 'self'\n",
    "    dist_nb = '_'.join([dist, nb])\n",
    "    dist_nb_self = '_'.join([dist, nb, self])\n",
    "    nb_self = '_'.join([nb, self])\n",
    "    dist_int_nb_self = '_'.join([dist,int, nb, self])\n",
    "    \n",
    "dat_mod_stats_wide = (dat_mod_stats.pivot_table(columns = V.COL_MODELCLASS, index=[V.COL_IDCHANNAME, V.COL_CONDITION], values=V.COL_R2)\n",
    " .reset_index() \n",
    "\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_MODELCLASS_F = V.COL_MODELCLASS+'_factor'\n",
    "dat_mod_stats[V.COL_MODELCLASS_F] =  dat_mod_stats[V.COL_MODELCLASS].astype(CategoricalDtype(\n",
    "                                                                        categories=\n",
    "                                                                        [\"dist_int_nb_self\",\n",
    "                                                                         'int',\n",
    "                                                                         'cc',\n",
    "                                                                         \"dist_nb_self\",\n",
    "                                                                         \"dist_nb\",\n",
    "                                                                         'nb_self',\n",
    "                                                                         'self',\n",
    "                                                                         'nb',\n",
    "                                                                         'nbcc',\n",
    "                                                                         'dist'\n",
    "                                                                         ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist_int_nb_self'])\n",
    "(gg.ggplot(dat_mod_stats.loc[fil], gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           #gg.facet_grid('.~'+V.COL_IDCHANNAME, scales='free_x')+\n",
    "          # gg.facet_grid(+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+\n",
    "              gg.geom_line(gg.aes(group=V.COL_IDCHANNAME), alpha=0.5)+\n",
    " gg.geom_point(gg.aes(color=V.COL_CONDNAME), position=gg.position_dodge(width=0.4))+\n",
    "           gg.expand_limits(y=1)+\n",
    "            gg.ggtitle('Prediction R2 of full model')+\n",
    "             gg.ylab('R2 [explained variance]')+\n",
    "             gg.xlab('')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1), figure_size=(6,3)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_ids = list((dat_mod_stats.merge(dat_measmeta\n",
    "                    .query(f'{db.measurements.measurement_name.key} == \"MeanIntensityComp\"'))\n",
    "            [db.measurements.measurement_id.key]\n",
    "           ).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q(c):\n",
    "    q = (bro.session.query(db.object_measurements.measurement_id,\n",
    "                          func.percentile_cont(0.5).within_group(\n",
    "                        db.object_measurements.value.asc()).label(db.object_measurements.value.key))\n",
    "         .join(db.measurements,\n",
    "               db.object_measurements.measurement_id==db.measurements.measurement_id)\n",
    "         .join(db.planes)\n",
    "          .join(db.ref_stacks, db.ref_stacks.ref_stack_id == db.planes.ref_stack_id)\n",
    "         .join(db.objects, db.object_measurements.object_id== db.objects.object_id)\n",
    "         .join(db.images)\n",
    "         .join(db.conditions)\n",
    "         .join(db.valid_objects)\n",
    "         .join(db.valid_images)\n",
    "         .filter(db.conditions.condition_name.like(c))\n",
    "         .filter(db.object_measurements.measurement_id.in_([int(i) for i in meas_ids]))\n",
    "         .group_by(db.object_measurements.measurement_id, db.ref_stacks.scale)\n",
    "        )\n",
    "    return q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "q_obj = (bro.data.get_objectmeta_query()\n",
    "         .filter(db.objects.object_type == 'cell')\n",
    "         .join(db.conditions, db.conditions.condition_id==db.images.condition_id)\n",
    "         .add_columns(db.conditions.condition_name)\n",
    "        )\n",
    "\n",
    "q_meas = (bro.data.get_measmeta_query()\n",
    "         .filter(db.measurements.measurement_id.in_([int(m) for m in meas_ids]))\n",
    "         .add_column(db.ref_stacks.scale)\n",
    "         .add_column(db.ref_planes.channel_name))\n",
    "\n",
    "adat_objmeas = bro.io.objmeasurements.get_measurements(q_obj=q_obj, q_meas=q_meas)\n",
    "adat_objmeas = bro.io.objmeasurements.scale_anndata(adat_objmeas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conds(conpat):\n",
    "    return [r[0] for r in bro.session.query(db.conditions.condition_name)\n",
    "         .filter(db.conditions.condition_name.like(conpat))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(adat, c):\n",
    "    return np.median(adat.X[adat.obs[V.COL_CONDNAME].isin(get_conds(c)),:], axis=0)\n",
    "\n",
    "c_names = dat_mod_stats[V.COL_CONDNAME].unique()\n",
    "dat_med =(pd.DataFrame([get_median(adat_objmeas, c) for c in c_names], index=pd.Index(c_names, name=V.COL_CONDNAME), columns=adat_objmeas.var[V.COL_CHANNELNAME]\n",
    "                  )\n",
    "          .stack()\n",
    "          .rename(V.COL_VALUE)\n",
    "          .reset_index())\n",
    "dat_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats[V.COL_MODELCLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats.loc[fil]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_condmeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_total(x):\n",
    "    return x.map(lambda x: (x.startswith('t-')| x.startswith('DNA')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist_int_nb_self'])\n",
    "p=(gg.ggplot(dat_mod_stats.loc[fil]\n",
    "           .merge(dat_condmeta)\n",
    "           .merge(dat_med), gg.aes(x=f'np.log10({V.COL_VALUE}+0.1)', y=V.COL_R2))+\n",
    "           #gg.facet_grid('.~'+V.COL_IDCHANNAME, scales='free_x')+\n",
    "          # gg.facet_grid(+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+\n",
    " gg.geom_point(gg.aes(color=V.COL_CELLLINE, size=f'{V.COL_CONC}')\n",
    "              #        shape=f'to_cat({V.COL_TP})')\n",
    "              )+\n",
    "             gg.geom_smooth(gg.aes(group=1),method='loess')+\n",
    "           gg.expand_limits(y=1)+\n",
    " gg.scale_size(range=(1,2), breaks=sorted(dat_condmeta[V.COL_CONC].unique()))+\n",
    "            gg.ggtitle('Prediction R2 of full model')+\n",
    "             gg.ylab('R2 [explained variance]')+\n",
    "             gg.xlab('Median channel intensity [log10(counts per pixel)]')+\n",
    "             gg.scale_color_manual(cmap_cells)+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1), figure_size=(6,3)\n",
    "            )\n",
    ")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist_int_nb_self'])\n",
    "p=(gg.ggplot(dat_mod_stats.loc[fil]\n",
    "           .merge(dat_condmeta)\n",
    "           .merge(dat_med), gg.aes(x=f'np.log10({V.COL_VALUE}+0.1)', y=V.COL_R2))+\n",
    "           #gg.facet_grid('.~'+V.COL_IDCHANNAME, scales='free_x')+\n",
    "          # gg.facet_grid(+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+\n",
    " gg.geom_point(gg.aes(color=V.COL_CELLLINE, size=f'{V.COL_CONC}',\n",
    "                      shape=f'to_cat({V.COL_TP})'))+\n",
    "             gg.geom_smooth(gg.aes(group=1),method='loess')+\n",
    "           gg.scale_y_continuous(limits=(0,1),expand=(0,0.01))+\n",
    " gg.scale_size(range=(1,2), breaks=sorted(dat_condmeta[V.COL_CONC].unique()))+\n",
    "            gg.ggtitle('Prediction R2 of full model')+\n",
    "             gg.ylab('R2 [explained variance]')+\n",
    "                         gg.xlab('Median channel intensity [log10(counts per pixel)]')+\n",
    "             gg.scale_color_manual(cmap_cells)+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1), figure_size=(6,3)\n",
    "            )\n",
    ")\n",
    "gg.ggsave(p, fol_out_paper/'subfig_r2_vs_median.pdf')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "(dat_mod_stats.loc[fil]\n",
    "           .merge(dat_condmeta)\n",
    "           .merge(dat_med)\n",
    "           .assign(**{db.object_measurements.value.key: lambda x: x[db.object_measurements.value.key]*2**16})\n",
    "           .query(f'{db.object_measurements.value.key} < 0.25')\n",
    "           .sort_values(V.COL_R2, ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist_int_nb_self'])\n",
    "p=(gg.ggplot(dat_mod_stats.loc[fil]\n",
    "           .merge(dat_condmeta)\n",
    "           .merge(dat_med)\n",
    "              .assign(**{'grp': \n",
    "              lambda x: x.apply(\n",
    "                  lambda g: f'{g[V.COL_CELLLINE]}c{g[V.COL_CHANNELNAME]}', axis=1)}),\n",
    "              gg.aes(x=f'np.log10({V.COL_VALUE}+0.1)', y=V.COL_R2))+\n",
    "        # gg.facet_wrap(f'{V.COL_IDCHANNAME}',ncol=1)+\n",
    "          # gg.facet_grid(+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+\n",
    "     gg.geom_line(gg.aes(color=V.COL_CELLLINE, group='grp'), alpha=0.3)+\n",
    " gg.geom_point(gg.aes(color=V.COL_CELLLINE, size=f'{V.COL_CONC}',\n",
    "                      shape=f'to_cat({V.COL_TP})'))+\n",
    "             #gg.geom_smooth(gg.aes(group=1),method='loess')+\n",
    "           gg.expand_limits(y=1)+\n",
    " gg.scale_size(range=(1,2), breaks=sorted(dat_condmeta[V.COL_CONC].unique()))+\n",
    "            gg.ggtitle('Prediction R2 of full model')+\n",
    "             gg.ylab('R2 [explained variance]')+\n",
    "             gg.xlab('')+\n",
    "             gg.scale_color_manual(cmap_cells)+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1),\n",
    "                    figure_size=(6,3),\n",
    "                    strip_text_y = gg.element_text(angle = 0)\n",
    "            )\n",
    ")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat_mod_stats.loc[fil][V.COL_R2] > 0.5).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "465/792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist_int_nb_self'])\n",
    "(gg.ggplot(dat_mod_stats.loc[fil]\n",
    "           .merge(dat_condmeta)\n",
    "           .merge(dat_med)\n",
    "              .assign(**{'grp': \n",
    "              lambda x: x.apply(\n",
    "                  lambda g: f'{g[V.COL_CELLLINE]}c{g[V.COL_CHANNELNAME]}', axis=1)}),\n",
    "              gg.aes(x=f'np.log10({V.COL_VALUE}*2**16+0.1)', y=V.COL_R2))+\n",
    "         gg.facet_wrap(f'{V.COL_IDCHANNAME}',ncol=1)+\n",
    "          # gg.facet_grid(+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+\n",
    "     gg.geom_line(gg.aes(color=V.COL_CELLLINE, group='grp'))+\n",
    " gg.geom_point(gg.aes(color=V.COL_CELLLINE, size=f'{V.COL_CONC}',\n",
    "                      shape=f'to_cat({V.COL_TP})'))+\n",
    "             #gg.geom_smooth(gg.aes(group=1),method='loess')+\n",
    "           gg.expand_limits(y=1)+\n",
    " gg.scale_size(range=(1,2), breaks=sorted(dat_condmeta[V.COL_CONC].unique()))+\n",
    "            gg.ggtitle('Prediction R2 of full model')+\n",
    "             gg.ylab('R2 [explained variance]')+\n",
    "             gg.xlab('')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1),\n",
    "                    figure_size=(3,38),\n",
    "                    strip_text_y = gg.element_text(angle = 0)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist_int_nb_self'])\n",
    "p = (gg.ggplot(dat_mod_stats.loc[fil].merge(dat_condmeta), gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           #gg.facet_grid('.~'+V.COL_IDCHANNAME, scales='free_x')+\n",
    "          # gg.facet_grid(+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+\n",
    "              #gg.geom_line(gg.aes(group=V.COL_IDCHANNAME, color=V.COL_CELLLINE), alpha=0.5)+\n",
    " gg.geom_point(gg.aes(color=V.COL_CELLLINE, size=f'{V.COL_CONC}',\n",
    "                      shape=f'to_cat({V.COL_TP})'), position=gg.position_dodge(width=0.4))+\n",
    "           gg.scale_y_continuous(limits=(0,1),expand=(0,0.01))+\n",
    " gg.scale_size(range=(1,2), breaks=sorted(dat_condmeta[V.COL_CONC].unique()), name=V.LAB_CONC)+\n",
    "            gg.ggtitle('Prediction R2 of full model')+\n",
    "             gg.ylab('R2 [explained variance]')+\n",
    "             gg.xlab('')+\n",
    "             gg.scale_color_manual(cmap_cells,name = V.LAB_CELLLINE)+\n",
    "             gg.scale_shape(name=V.LAB_TP)+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = -90, hjust = 0.1), figure_size=(4,2),\n",
    "                    text=gg.element_text(size=6)\n",
    "            )\n",
    ")\n",
    "\n",
    "fig=p.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig( fol_out_paper/'subfig_r2_full_all.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "fig.savefig fol_out_paper/'subfig_r2_full_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist','nb', 'dist_nb'])\n",
    "(gg.ggplot(dat_mod_stats.loc[fil].query(f'{V.COL_CONDNAME} in {C.main_conds}'),\n",
    "           \n",
    "           gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           gg.facet_grid(V.COL_CONDITION+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+ \n",
    "           gg.geom_line(gg.aes(group=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "           gg.geom_point(gg.aes(color=V.COL_MODELCLASS_F), position=gg.position_dodge(width=0.9))+\n",
    "           gg.expand_limits(y=1)+\n",
    "            gg.ggtitle('Dist-to-rim vs neighbourhood')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = -90, hjust = 0.1), figure_size=(5,6)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist','nb', 'dist_nb'])\n",
    "(gg.ggplot(dat_mod_stats.loc[fil].query(f'{V.COL_CONDNAME} in {C.fig2_cond}'),\n",
    "           \n",
    "           gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           gg.facet_grid(V.COL_CONDITION+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+ \n",
    "           gg.geom_line(gg.aes(group=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "           gg.geom_point(gg.aes(color=V.COL_MODELCLASS_F), position=gg.position_dodge(width=0.9))+\n",
    "           gg.expand_limits(y=1)+\n",
    "            gg.ggtitle('Dist-to-rim vs neighbourhood')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = -90, hjust = 0.1), figure_size=(5,3)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist_nb','self', 'dist_nb_self'])\n",
    "(gg.ggplot(dat_mod_stats.loc[fil].query(f'{V.COL_CONDNAME} in {C.fig2_cond}'),\n",
    "           \n",
    "           gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           gg.facet_grid(V.COL_CONDITION+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+ \n",
    "           gg.geom_line(gg.aes(group=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "           gg.geom_point(gg.aes(color=V.COL_MODELCLASS_F), position=gg.position_dodge(width=0.9))+\n",
    "           gg.expand_limits(y=1)+\n",
    "            gg.ggtitle('Dist-to-rim vs neighbourhood')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1), figure_size=(5,3)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(['dist_nb_self','int','cc', 'dist_int_nb_self'])\n",
    "(gg.ggplot(dat_mod_stats.loc[fil].query(f'{V.COL_CONDNAME} in {C.fig2_cond}'),\n",
    "           \n",
    "           gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           gg.facet_grid(V.COL_CONDITION+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+ \n",
    "           gg.geom_line(gg.aes(group=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "           gg.geom_point(gg.aes(color=V.COL_MODELCLASS_F), position=gg.position_dodge(width=0.9))+\n",
    "           gg.expand_limits(y=1)+\n",
    "            gg.ggtitle('Dist-to-rim vs neighbourhood')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1), figure_size=(5,3)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "dist_groups = {'neightbourhood': ['dist', 'nb', 'dist_nb'],\n",
    "               'autocorrelation': ['dist_nb', 'self', 'dist_nb_self'],\n",
    "               'internal': ['cc', 'int', 'dist_nb_self', 'dist_int_nb_self']}\n",
    "COL_MODGROUP = 'model_groups'\n",
    "COL_HIER_MODELCLASS = 'model'\n",
    "\n",
    "\n",
    "dat_mod_hier = (pd.concat({k: dat_mod_stats.query(f'{V.COL_MODELCLASS} in {f}') for k, f in dist_groups.items()}\n",
    "                         , names=[COL_MODGROUP,None]).reset_index(COL_MODGROUP, drop=False)\n",
    "                .assign(**{COL_MODGROUP: lambda x: pd.Categorical(x[COL_MODGROUP], categories=dist_groups.keys())})\n",
    ")\n",
    "\n",
    "dat_mod_hier[V.COL_MODELCLASS] = pd.Categorical(dat_mod_hier[V.COL_MODELCLASS],categories=['dist', 'nb','dist_nb','self',\n",
    "                                                                                           'dist_nb_self', 'cc', 'int',\n",
    "                                                                                      'dist_int_nb_self'])\n",
    "\n",
    "dat_mod_hier[V.COL_MODELCLASS] = dat_mod_hier[V.COL_MODELCLASS].cat.rename_categories({'dist': 'distance',\n",
    "                                                                                      'nb': 'neightbour markers',\n",
    "                                                                                      'dist_nb': 'distance + neightbour markers',\n",
    "                                                                                      'self': 'autocorrelation',\n",
    "                                                                                      'dist_nb_self': 'all neighttbourhood terms',\n",
    "                                                                                     'cc': 'internal cellcycle markers',\n",
    "                                                                                      'int': 'all internal markers',\n",
    "                                                                                      'dist_int_nb_self': 'full model'}\n",
    "                                                                                     )\n",
    "\n",
    "(gg.ggplot(dat_mod_hier.query(f'{V.COL_CONDNAME} in {C.main_conds}'),\n",
    "           gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           gg.facet_grid(f'{COL_MODGROUP}~{V.COL_CONDNAME}')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+ \n",
    "            # gg.geom_vline(gg.aes(xintercept=V.COL_IDCHANNAME))+ \n",
    "           #gg.geom_line(gg.aes(xgroup=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "             gg.geom_segment(gg.aes(y=V.COL_R2, xend=V.COL_IDCHANNAME,color=V.COL_MODELCLASS), yend=0,\n",
    "                             position=gg.position_dodge(width=0.9)) +            \n",
    "             #gg.geom_line(gg.aes(xgroup=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "           gg.geom_point(gg.aes(color=V.COL_MODELCLASS), position=gg.position_dodge(width=0.9))+\n",
    "           gg.expand_limits(y=1)+\n",
    "                 gg.ylab('R2')+\n",
    "            gg.ggtitle('Dist-to-rim vs neightbourhood')+\n",
    "         gg.scale_color_brewer(type='qual',palette='Dark2')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1), figure_size=(15,5)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_groups = {'Neighbourhood': ['dist', 'nb', 'dist_nb'],\n",
    "               'Autocorrelation': ['dist_nb', 'self', 'dist_nb_self'],\n",
    "               'Internal': ['int', 'dist_nb_self', 'dist_int_nb_self']}\n",
    "COL_MODGROUP = 'model_groups'\n",
    "COL_HIER_MODELCLASS = 'model'\n",
    "\n",
    "\n",
    "dat_mod_hier = (pd.concat({k: dat_mod_stats.query(f'{V.COL_MODELCLASS} in {f}') for k, f in dist_groups.items()}\n",
    "                         , names=[COL_MODGROUP,None]).reset_index(COL_MODGROUP, drop=False)\n",
    "                .assign(**{COL_MODGROUP: lambda x: pd.Categorical(x[COL_MODGROUP], categories=dist_groups.keys())})\n",
    ")\n",
    "\n",
    "dat_mod_hier[V.COL_MODELCLASS] = pd.Categorical(dat_mod_hier[V.COL_MODELCLASS]\n",
    "                                                ,categories=['dist',\n",
    "                                                             'nb', 'dist_nb', 'self','dist_nb_self', \n",
    "                                                                                            'cc', 'int',\n",
    "                                                                                      'dist_int_nb_self'])\n",
    "\n",
    "dat_mod_hier[V.COL_MODELCLASS] = dat_mod_hier[V.COL_MODELCLASS].cat.rename_categories({'dist': 'global env',\n",
    "                                                                                      'nb': 'nb markers',\n",
    "                                                                                      'dist_nb': 'global env\\n + nb markers',\n",
    "                                                                                        'self': 'autocorr',\n",
    "                                                                                                                                                                           \n",
    "                                                                                      'dist_nb_self': 'global env\\n + nb markers\\n +autocorr',\n",
    "                                                                                    # 'cc': 'cellcycle state',\n",
    "                                                                                      'int': 'cell state',\n",
    "                                                                                      'dist_int_nb_self': 'full model'}\n",
    "                                                                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(dat_mod_hier.query(f'{V.COL_CONDNAME} in {C.main_conds}'),\n",
    "           gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           gg.facet_grid(f'{COL_MODGROUP}~{V.COL_CONDNAME}')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+ \n",
    "            # gg.geom_vline(gg.aes(xintercept=V.COL_IDCHANNAME))+ \n",
    "           #gg.geom_line(gg.aes(xgroup=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "             gg.geom_segment(gg.aes(y=V.COL_R2, xend=V.COL_IDCHANNAME,color=V.COL_MODELCLASS), yend=0,\n",
    "                             position=gg.position_dodge(width=0.9)) +            \n",
    "             #gg.geom_line(gg.aes(xgroup=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "           gg.geom_point(gg.aes(color=V.COL_MODELCLASS), position=gg.position_dodge(width=0.9))+\n",
    "           gg.expand_limits(y=1)+\n",
    "                 gg.ylab('R2')+\n",
    "            gg.ggtitle('Dist-to-rim vs neighbourhood')+\n",
    "         gg.scale_color_brewer(type='qual',palette='Dark2')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1), figure_size=(15,5)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_paper = ['#c957dbff', '#5784dbff', '#7570b3ff', '#57db94ff', '#66a61eff', '#b9db57ff', '#db5f57ff', '#666666ff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=(gg.ggplot(dat_mod_hier.query(f'{V.COL_CONDNAME} in {C.fig2_cond}'),\n",
    "           \n",
    "           gg.aes(x=V.COL_IDCHANNAME, y=V.COL_R2))+\n",
    "           gg.facet_grid(f'{COL_MODGROUP}~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+ \n",
    "            # gg.geom_vline(gg.aes(xintercept=V.COL_IDCHANNAME))+ \n",
    "           #gg.geom_line(gg.aes(xgroup=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "             gg.geom_segment(gg.aes(y=V.COL_R2, xend=V.COL_IDCHANNAME,color=V.COL_MODELCLASS), yend=0,\n",
    "                             position=gg.position_dodge(width=0.9)) +            \n",
    "             #gg.geom_line(gg.aes(xgroup=V.COL_IDCHANNAME), alpha=0.5)+\n",
    "           gg.geom_point(gg.aes(color=V.COL_MODELCLASS), position=gg.position_dodge(width=0.9))+\n",
    "           gg.scale_y_continuous(limits=(0,1),expand=(0,0.01))+\n",
    "                 gg.ylab('Variance Explained [R2]')+\n",
    "   gg.xlab('')+\n",
    "           # gg.ggtitle('Dist-to-rim vs neightbourhood')+\n",
    "        gg.scale_color_manual(cmap_paper)+\n",
    "   #gg.scale_color_manual(colorcet.glasbey_dark)+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = -90, hjust = 0.1), \n",
    "                    figure_size=(4,5),\n",
    "                    text=gg.element_text(size=6)\n",
    "            )\n",
    ")\n",
    "\n",
    "fig = p.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fol_out_paper/'subfig3_performance_submodels.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLAB:\n",
    "    dist = '(global env)'\n",
    "    dist_nb = '(global env \\n local nb)'\n",
    "    all_vs_dist = 'local nb\\n vs\\n global env'\n",
    "    fullwodist_vs_fullnb = '(global env \\n local nb)\\n -\\n (local nb)'\n",
    "    fullwonb_vs_fullnb = '(global env \\n local nb)\\n -\\n (global env)'\n",
    "    auto = 'autocorr'\n",
    "    dist_vs_fullnb = '(global env \\n local nb \\n autocorr)\\n -\\n (local nb \\n autocorr)'\n",
    "    auto_vs_distnb =  '(global env \\n local nb \\n autocorr)\\n -\\n (global env \\n local nb)'\n",
    "    auto_vs_fullnb = '(global env \\n local nb \\n autocorr)\\n -\\n (autocorr)'\n",
    "    int_vs_fullnb = '(global env \\n local nb \\n autocorr)\\n  -\\n (cell state)'\n",
    "    fullnb_vs_int = '(cell state)\\n -\\n (global env \\n local nb \\n autocorr)'\n",
    "    nb = '(local nb)'\n",
    "    int_vs_full = '(global env \\n local nb \\n autocorr \\n cell state)\\n -\\n (cell state)'\n",
    "    int = '(cell state)'\n",
    "    fullnb = '(global env \\n local nb \\n autocorr)'\n",
    "    int_vs_woint = '(global env \\n local nb \\n autocorr\\n  cell state)\\n -\\n (global env \\n local nb \\n autocorr)'\n",
    "    full = '(global env \\n local nb \\n autocorr \\n int)'\n",
    "model_comp = {MLAB.dist: f'{M.dist}',\n",
    "              MLAB.nb: f'{M.nb}',\n",
    "              MLAB.fullwodist_vs_fullnb: f'{M.dist_nb}-{M.nb}',\n",
    "              MLAB.fullwonb_vs_fullnb: f'{M.dist_nb}-{M.dist}',\n",
    "              \n",
    "              MLAB.dist_nb: f'{M.dist_nb}',\n",
    "              MLAB.auto: f'{M.self}',\n",
    "              #MLAB.dist_vs_fullnb: f'{M.dist_nb_self}-{M.nb_self}',\n",
    "              MLAB.auto_vs_fullnb: f'{M.dist_nb_self}-{M.self}',\n",
    "              MLAB.auto_vs_distnb: f'{M.dist_nb_self}-{M.dist_nb}',\n",
    "\n",
    "              \n",
    "              MLAB.fullnb: f'{M.dist_nb_self}',\n",
    "              MLAB.int: f'{M.int}',\n",
    "              #MLAB.fullnb_vs_int: f'{M.int}-{M.dist_nb_self}',\n",
    "               MLAB.int_vs_full: f'{M.dist_int_nb_self}-{M.int}',\n",
    "              MLAB.int_vs_woint: f'{M.dist_int_nb_self}-{M.dist_nb_self}'\n",
    "              #MLAB.full: f'{M.dist_int_nb_self}'\n",
    "        }\n",
    "COL_MODGROUP = 'model_groups'\n",
    "\n",
    "\n",
    "\n",
    "dat_mod_comp = (pd.concat({k: dat_mod_stats_wide.eval(f'{V.COL_R2}={f}') for k, f in model_comp.items()}\n",
    "                         , names=[COL_MODGROUP,None]).reset_index(COL_MODGROUP, drop=False)\n",
    "                .assign(**{COL_MODGROUP: lambda x: pd.Categorical(x[COL_MODGROUP], categories=model_comp.keys())})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    sns.set_palette('deep')\n",
    "    fig = plt.figure(figsize=(14,4))\n",
    "    ax = sns.boxplot(x=COL_MODGROUP, y=V.COL_R2, data=dat_mod_comp, whis=0,fliersize=0, color='gray')\n",
    "    for patch in ax.artists:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, .1))\n",
    "    ax = sns.swarmplot(x=COL_MODGROUP, y=V.COL_R2,hue='is_delta',\n",
    "                       data=dat_mod_comp.merge(dat_condmeta)\n",
    "                           .assign(is_delta = lambda x: ['delta' if '-' in m else 'model' for m in x[COL_MODGROUP]]),\n",
    "                       size=1.5, \n",
    "                      rasterized=True)\n",
    "    ax.hlines(0,-20,20)\n",
    "    plt.ylabel('(Delta) Variance explained [R2]')\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    plt.xlabel('')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1., 0.5), ncol=1)\n",
    "fig.savefig(fol_out_paper/'subfig3_delta_submodels_overall.pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    sns.set_palette('deep')\n",
    "    fig = plt.figure(figsize=(13,4))\n",
    "    ax = sns.boxplot(x=COL_MODGROUP, y=V.COL_R2, data=dat_mod_comp, whis=0,fliersize=0, color='gray')\n",
    "    for patch in ax.artists:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, .1))\n",
    "    ax = sns.swarmplot(x=COL_MODGROUP, y=V.COL_R2,\n",
    "                       data=dat_mod_comp.merge(dat_condmeta),\n",
    "                       size=1.5, hue=V.COL_CELLLINE,\n",
    "                      rasterized=True)\n",
    "    ax.hlines(0,-20,20)\n",
    "    plt.ylabel('Δ(R2)')\n",
    "    ax.tick_params(axis='x', labelsize=8)\n",
    "    plt.xlabel('')\n",
    "    plt.ylim(-0.2,1)\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1., 0.5), ncol=1)\n",
    "fig.savefig(fol_out_paper/'subfig3_delta_submodels_overall.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p =(dat_mod_comp>>\n",
    " gg.ggplot(gg.aes(x=COL_MODGROUP, y=f'{V.COL_R2}'))+\n",
    "  # gg.geom_hline(gg.aes(yintercept=1))+\n",
    " gg.geom_hline(gg.aes(yintercept=0))+\n",
    " gg.geom_boxplot()+\n",
    " # gg.geom_violin(alpha=0.4)+\n",
    "\n",
    " gg.geom_jitter(alpha=0.1, width=0.2, size=1)+\n",
    " gg.ylim((-0.25,0.75))+\n",
    " #gg.ylab('(R2_self)-(R2_distance-to-rim +nb)')+\n",
    "             gg.xlab('')+\n",
    "         gg.ylab('Δ(R2)')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 0, hjust = 0.1, size=6), figure_size=(6,3)\n",
    "            ))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.all_vs_dist]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(np.mean(d[V.COL_R2] >=-0.0))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.dist].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}<0').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.fullwodist_vs_fullnb]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "#print(np.mean(d[V.COL_R2] >=-0.001))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.dist].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}>0.05').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.dist_vs_fullnb]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(np.mean(d[V.COL_R2] >=0))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.dist].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}>0.05').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.fullwodist_vs_fullnb]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.dist].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}>0.05').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.auto_vs_fullnb]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.self].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} < -0.05').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}<-0.05').sort_values(V.COL_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.eval(f'x={M.dist_nb}-{M.self}').sort_values('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.int_vs_fullnb]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(np.mean(d.sort_values(V.COL_R2, ascending=False)[V.COL_R2]<0))\n",
    "\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}<0').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.int_vs_full]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(np.mean(d.sort_values(V.COL_R2, ascending=False)[V.COL_R2]<0))\n",
    "x=d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}<-0.25').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "print(x)\n",
    "print(np.sum(x>=6))\n",
    "x=d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}<-0.1').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "print(x)\n",
    "print(np.sum(x>=6))\n",
    "x=d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}<-0.05').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "print(x)\n",
    "print(np.sum(x>=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=d.sort_values(V.COL_R2, ascending=False).query(f'{M.dist_nb_self}>0.25').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "print(x)\n",
    "print(np.sum(x>=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=d.sort_values(V.COL_R2, ascending=False).query(f'{M.dist_nb_self}>0.2').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "print(x)\n",
    "print(np.sum(x>=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.sort_values(V.COL_R2, ascending=False)[V.COL_R2].describe())\n",
    "print(d.sort_values(M.dist_nb_self, ascending=False)[M.dist_nb_self].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(d.sort_values(V.COL_R2, ascending=False)[V.COL_R2] < -0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(d.sort_values(V.COL_R2, ascending=False)[M.dist_nb_self] > 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.int_vs_full]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(np.mean(d.sort_values(V.COL_R2, ascending=False)[V.COL_R2]<0))\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{M.dist_nb_self}>0.05').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2}<0').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.all_vs_dist]\n",
    " .query(f'{V.COL_R2}<0').sort_values([M.dist_nb_self], ascending=False).head()\n",
    ")#.query(f'{M.dist_nb_self} > 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.all_vs_dist]\n",
    " .query(f'{V.COL_R2}<0').sort_values([M.dist_nb_self], ascending=False)\n",
    " .groupby(V.COL_CHANNEL)[V.COL_CHANNEL].count()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.all_vs_dist]\n",
    " .query(f'{V.COL_R2}<0').sort_values([M.dist_nb_self], ascending=False)\n",
    " .groupby(V.COL_CHANNEL)[V.COL_CHANNEL].count()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = (dat_mod_comp.merge(dat_condmeta).groupby([COL_MODGROUP, V.COL_CELLLINE, V.COL_TP, V.COL_CHANNEL])[V.COL_R2].mean()).reset_index()\n",
    "\n",
    "for g, d in dat[[COL_MODGROUP,V.COL_CHANNEL,V.COL_CELLLINE, V.COL_R2]].groupby(COL_MODGROUP):\n",
    "    display(d.sort_values(V.COL_R2).head(5))\n",
    "    display(d.sort_values(V.COL_R2, ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for g, d in (dat_mod_comp[[COL_MODGROUP,V.COL_CHANNEL, V.COL_R2]]\n",
    "             .groupby([COL_MODGROUP, V.COL_CHANNEL])[V.COL_R2].mean().reset_index()\n",
    "             .groupby(COL_MODGROUP)):\n",
    "    display(d.sort_values(V.COL_R2).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for g, d in dat_mod_comp[[COL_MODGROUP, 'channel',V.COL_CONDNAME, V.COL_R2]].groupby(COL_MODGROUP):\n",
    "    display(d.sort_values(V.COL_R2).head(5))\n",
    "    display(d.sort_values(V.COL_R2, ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dat_mod_stats_wide.eval(f'{M.self}-{M.dist_nb}').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "-> looks like this mostly holds - except cases where distance to rim + nb is super important, e.g. Ki67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.fullwodist_vs_fullnb]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.self].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} > 0.15').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} > 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.fullwonb_vs_fullnb]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.self].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} > 0.15').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} > 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.auto_vs_distnb]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.self].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} > 0.15').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} > 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dat_mod_comp.loc[dat_mod_comp[COL_MODGROUP]  == MLAB.int_vs_full]\n",
    "print(np.mean(d[V.COL_R2]))\n",
    "print(np.median(d[V.COL_R2]))\n",
    "print(d[V.COL_R2].describe())\n",
    "print(d[M.self].describe())\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} > 0.15').groupby(V.COL_CHANNEL).size().sort_values(ascending=False)\n",
    "d.sort_values(V.COL_R2, ascending=False).query(f'{V.COL_R2} > 0.15')[V.COL_CHANNEL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Make a stacked barplot with models according to the hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_tup = [(M.dist, 'global env'), \n",
    "        (M.dist_nb, ' +local nb'),\n",
    "        (M.dist_nb_self, ' +autocorr'),\n",
    "        ('dist_nb_self_cc', ' +cellcycle'),\n",
    "        (M.dist_int_nb_self, '+cell state')]\n",
    "mods = [m[0] for m in mod_tup]\n",
    "mod_lab = dict(mod_tup) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats[V.COL_MODELCLASS+'2'] = pd.Categorical(dat_mod_stats[V.COL_MODELCLASS], categories=mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = dat_mod_stats[V.COL_MODELCLASS].isin(mods)\n",
    "dat_mod_stats[V.COL_MODELCLASS+'2'] = pd.Categorical(\n",
    "    dat_mod_stats[V.COL_MODELCLASS], categories=reversed(mods)\n",
    "    ).rename_categories(mod_lab)\n",
    "\n",
    "\n",
    "\n",
    "tdat = dat_mod_stats.loc[fil].sort_values(V.COL_MODELCLASS+'2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tofac(s):\n",
    "    return pd.Categorical(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aim: Make a plot like the one above with matplotlib\n",
    "- Add small triangles on the bottom axis to indicate increasing size\n",
    "- colorcode the two timepoints\n",
    "- make the bars of consecutive sizes touching, add dashed line between timepoints\n",
    "- Separate markers by a small offset\n",
    "- plot every cellline as separate subplot\n",
    "\"\"\"\n",
    "from functools import reduce # Valid in Python 2.6+, required in Python 3\n",
    "import operator\n",
    "# 1) calculate x positions\n",
    "\n",
    "def make_category(col, categories=None):\n",
    "    if col.dtype.name != 'category':\n",
    "        if categories is None:\n",
    "            categories = sorted(np.unique(col))\n",
    "        return pd.Categorical((col),categories=categories)\n",
    "    else:\n",
    "        return col\n",
    "    \n",
    "def get_x_pos(datord,offsets):\n",
    "    \"\"\"\n",
    "    Gets x position the order of variables calculated by:\n",
    "        sum(order(var)*offset_var for var in datord)\n",
    "    Args:\n",
    "        datord: an dataframe with the variables usef for ordering\n",
    "        off: a vector with offsets per n_variable\n",
    "    Returns:\n",
    "        Postion\n",
    "    \"\"\"\n",
    "    assert(datord.shape[1] == len(offsets))\n",
    "    datord = datord.apply(make_category, axis=0)\n",
    "    \n",
    "    return np.sum([get_uniord(datord[col].cat.codes)*off for col, off in zip(list(datord), offsets)], axis=0)\n",
    "\n",
    "\n",
    "def get_uniord(vals):\n",
    "    \"\"\"\n",
    "    Gets replaces the values by the order of the unique values\n",
    "    \"\"\"\n",
    "    univals = vals.unique()\n",
    "    orderdic = {val: order for order, val in enumerate(sorted(univals))}\n",
    "    return vals.replace(orderdic)\n",
    "        \n",
    "def get_offsets(datord):\n",
    "    ncounts = datord.nunique()\n",
    "    offsets = [1] + [ reduce(operator.mul, ncounts[:(i+1)]) for i in range(len(ncounts)-1)]\n",
    "    return offsets\n",
    "    \n",
    "\n",
    "def add_triangle_annotations(dat, xgrpvars, xvar, ax, w_scale=0.9, y_offset=-0.01, h=0.075, colors=None):\n",
    "    if colors is None:\n",
    "        cols = plt.cm.Accent(range(10))\n",
    "    dat = dat.groupby(xgrpvars[1:]).agg({xvar: 'mean',\n",
    "                                                         xgrpvars[0]: 'nunique'}).rename(columns={xgrpvars[0]: 'n_width'}).reset_index()\n",
    "    dat[xgrpvars[1]] = make_category(dat[xgrpvars[1]])\n",
    "\n",
    "    for idx, row in dat.iterrows():\n",
    "        c= cols[dat.loc[[idx],xgrpvars[1]].cat.codes.values[0]]\n",
    "        x=row[xvar]\n",
    "        w=w_scale*row['n_width']\n",
    "        ax.add_patch(plt.Polygon(((x-w/2,y_offset),(x+w/2,y_offset),(x+w/2, y_offset-h)),\n",
    "                                   fill=True,clip_on=False, color=c))\n",
    "        \n",
    "def add_channel_annotations(dat, xvar, labelvar, ax, w_scale=0.9, y_offset=-0.01, h=0.075, colors=None):\n",
    "    if colors is None:\n",
    "        cols = plt.cm.Accent(range(10))\n",
    "    dat = dat.groupby(labelvar)[xvar].mean().reset_index()\n",
    "    lab_pos = dat[xvar]\n",
    "    lab_text = dat[labelvar]\n",
    "    ax.get_xaxis().set_ticks(lab_pos)\n",
    "    ax.get_xaxis().set_ticklabels(lab_text)\n",
    "    ax.xaxis.labelpad = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdat = (tdat.merge(dat_condmeta)\n",
    "           #.query(f'{V.COL_CELLLINE} == \"293T\"')\n",
    "           #.query(f'{V.COL_MODELCLASS} ==\"dist_int_nb_self\"')\n",
    "         \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mizani.palettes import hue_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "col_mclass = V.COL_MODELCLASS+'2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ncols = len(np.unique(testdat[col_mclass]))\n",
    "colors_hue = hue_pal(h=.01, l=.6, s=.65, color_space='hls')\n",
    "col_map = list((colors_hue(ncols)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "col_mclass = V.COL_MODELCLASS+'2'\n",
    "#testdat = testdat.sort_values(col_mclass)\n",
    "\n",
    "\n",
    "#col_map = colors_hue(ncols)\n",
    "\n",
    "\n",
    "xgrpvars = [V.COL_CONC, V.COL_TP,  V.COL_IDCHANNAME]\n",
    "ygrpvar = V.COL_CELLLINE\n",
    "group_offsets =[0,2,0.3]\n",
    "\n",
    "testdat = testdat\n",
    "offsets = get_offsets(testdat[[V.COL_CONC, V.COL_TP,  V.COL_IDCHANNAME]])\n",
    "offsets[-1] = offsets[-1] + 2\n",
    "offsets[-2] = offsets[-2] + 0.3\n",
    "\n",
    "xvar = 'xpos'\n",
    "testdat[xvar] = get_x_pos(testdat[xgrpvars], offsets)\n",
    "\n",
    "\n",
    "width = 1\n",
    "\n",
    "n_rows = testdat[ygrpvar].nunique()\n",
    "fig, axs = plt.subplots(n_rows,1,figsize=(15,5), dpi=600)\n",
    "try:\n",
    "    len(axs)\n",
    "except:\n",
    "    axs = [axs]\n",
    "\n",
    "for (ylab, dat), ax in zip(testdat.groupby(ygrpvar), axs):\n",
    "    dat = dat.sort_values(col_mclass,ascending=True)\n",
    "    c = [col_map[i] for i in dat[col_mclass].cat.codes.values]\n",
    "    ax.bar(np.unique(dat[xvar]), [1 for i in range(dat[xvar].nunique())], color='grey', width=width)\n",
    "    ax.bar(dat[xvar].values, dat[r_var].values, width=width, color=c)\n",
    "    # set ticks where your images will be\n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    # remove tick labels\n",
    "    ax.get_xaxis().set_ticklabels([])\n",
    "    ax.margins(x=0.01,y=0)\n",
    "    ax.text(dat[xvar].max()+5, 0.5, ylab)\n",
    "    \n",
    "add_channel_annotations(testdat, xvar=xvar, labelvar=xgrpvars[-1], ax=ax)\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(-60)\n",
    "    tick.set_size(12)\n",
    "    tick.set_ha('left')\n",
    "ax.xaxis.set_tick_params(length=0,pad=10)\n",
    "\n",
    "\n",
    "add_triangle_annotations(testdat, xgrpvars, xvar, ax, w_scale=0.9, y_offset=-0.01, h=0.12, colors=None)\n",
    "\n",
    "ax2 = fig.add_subplot(111, frameon=False)\n",
    "\n",
    "ax2.set_ylabel('Variance Explained [R2]')\n",
    "ax2.get_xaxis().set_ticks([])\n",
    "ax2.get_xaxis().set_ticklabels([])\n",
    "ax2.get_yaxis().set_ticks([])\n",
    "ax2.get_yaxis().set_ticklabels([])\n",
    "ax2.yaxis.labelpad = 40\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "lab_class = dat[col_mclass].cat.categories\n",
    "lab_cols = col_map\n",
    "lab_patches =[mpatches.Patch(color=c, label=lab) for c, lab in zip(lab_cols, lab_class)]\n",
    "\n",
    "ax2.legend(handles=lab_patches, loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "fig.savefig(fol_out_paper/'fig4_overview_variability_explained.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#dat = dat.sort_values(col_mclass)\n",
    "\n",
    "\n",
    "\n",
    "xgrpvars = [V.COL_CONC, V.COL_TP,  V.COL_IDCHANNAME]\n",
    "ygrpvar = V.COL_CELLLINE\n",
    "\n",
    "def do_r2_barplot(dat, # the dataframe\n",
    "                  y_var,\n",
    "                  xgrpvars,\n",
    "                  ygrpvars,\n",
    "                  col_mclass,\n",
    "                  figsize=(15,5),\n",
    "                  group_offsets=None,\n",
    "                  col_map=None,\n",
    "                  triangle_annotations=True,\n",
    "                  channel_annotations=True,\n",
    "                  legend=True,\n",
    "                  bar_width=1,\n",
    "                  legend_anchor=(1.05, 0.5),\n",
    "                  dpi=600,\n",
    "                  subplot_label_offset=5,\n",
    "                  channel_text_size=12,\n",
    "                  channel_rotation=-90,\n",
    "                  labelvar=None\n",
    "                 ):\n",
    "\n",
    "    ncols = len(np.unique(dat[col_mclass]))\n",
    "    if col_map is None:\n",
    "        colors_hue = hue_pal(h=.01, l=.6, s=.65, color_space='hls')\n",
    "        col_map = list((colors_hue(ncols)))\n",
    "    if group_offsets is None:\n",
    "        group_offsets =[0,0.3,2]\n",
    "\n",
    "    offsets = get_offsets(dat[xgrpvars])\n",
    "    offsets = [o+go for o, go in zip(offsets, group_offsets)]\n",
    "\n",
    "    XVAR = 'xpos'\n",
    "    dat[XVAR] = get_x_pos(dat[xgrpvars], offsets)\n",
    "    n_rows = dat[ygrpvars].nunique()\n",
    "    fig, axs = plt.subplots(n_rows,1,figsize=figsize, dpi=dpi)\n",
    "    try:\n",
    "        len(axs)\n",
    "    except:\n",
    "        axs = [axs]\n",
    "\n",
    "    for (ylab, dat), ax in zip(dat.groupby(ygrpvars), axs):\n",
    "        dat = dat.sort_values(col_mclass,ascending=True)\n",
    "        c = [col_map[i] for i in dat[col_mclass].cat.codes.values]\n",
    "        ax.bar(np.unique(dat[XVAR]), [1 for i in range(dat[XVAR].nunique())], color='grey', width=bar_width)\n",
    "        ax.bar(dat[XVAR].values, dat[y_var].values, width=bar_width, color=c)\n",
    "        # set ticks where your images will be\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "        # remove tick labels\n",
    "        ax.get_xaxis().set_ticklabels([])\n",
    "        ax.margins(x=0.01,y=0)\n",
    "        ax.text(dat[XVAR].max()+subplot_label_offset, 0.5, ylab)\n",
    "\n",
    "    if channel_annotations:\n",
    "        if labelvar is None:\n",
    "            labelvar = xgrpvars[-1]\n",
    "        add_channel_annotations(dat, xvar=XVAR, labelvar=labelvar, ax=ax)\n",
    "\n",
    "        for tick in ax.get_xticklabels():\n",
    "            tick.set_rotation(channel_rotation)\n",
    "            tick.set_size(channel_text_size)\n",
    "            tick.set_ha('left')\n",
    "        ax.xaxis.set_tick_params(length=0,pad=10)\n",
    "\n",
    "    if triangle_annotations:\n",
    "        add_triangle_annotations(dat, xgrpvars, XVAR, ax, w_scale=0.9, y_offset=-0.01, h=0.12, colors=None)\n",
    "\n",
    "    # xlabel\n",
    "    ax2 = fig.add_subplot(111, frameon=False)\n",
    "    ax2.set_ylabel('Variance Explained [R2]')\n",
    "    ax2.get_xaxis().set_ticks([])\n",
    "    ax2.get_xaxis().set_ticklabels([])\n",
    "    ax2.get_yaxis().set_ticks([])\n",
    "    ax2.get_yaxis().set_ticklabels([])\n",
    "    ax2.yaxis.labelpad = 40\n",
    "\n",
    "    if legend:\n",
    "        # Put a legend to the right of the current axis\n",
    "        lab_class = dat[col_mclass].cat.categories\n",
    "        lab_cols = col_map\n",
    "        lab_patches =[mpatches.Patch(color=c, label=lab) for c, lab in zip(lab_cols, lab_class)]\n",
    "\n",
    "        ax2.legend(handles=lab_patches, loc='center left', bbox_to_anchor=legend_anchor)\n",
    "\n",
    "    return fig, dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'font.size': 6}):\n",
    "    fig, dat = do_r2_barplot(tdat.merge(dat_condmeta),\n",
    "                             r_var,\n",
    "                             xgrpvars=[V.COL_CONC, V.COL_TP,  V.COL_IDCHANNAME],\n",
    "                  ygrpvars=V.COL_CELLLINE,\n",
    "                             col_mclass=V.COL_MODELCLASS+'2',\n",
    "                                              channel_text_size=5,\n",
    "                             figsize=(8,2),\n",
    "                  channel_rotation=-90)\n",
    "    for ax in fig.axes:\n",
    "        ax.set_yticks([0, 0.5, 1])\n",
    "fig.savefig(fol_out_paper/'fig4_overview_variability_explained.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compare pErk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (dat_mod_stats.merge(dat_condmeta).merge(dat_pannel_ord, left_on=V.COL_CHANNELNAME, right_on=V.COL_METAL, how='left')\n",
    " .rename(columns={'class': 'mark_class'})\n",
    " .query('mark_class== \"egf\"')\n",
    " #.query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    " .pivot_table(index=[V.COL_IDCHANNAME,V.COL_CHANNELNAME,  V.COL_CELLLINE],columns=[V.COL_MODELCLASS_F], values=V.COL_R2, aggfunc=np.mean)\n",
    ")\n",
    "t.columns = t.columns.astype('str')\n",
    "\n",
    "\n",
    "t= (t.assign(**{'full_vs_fulnb': lambda x: x['dist_nb_self']/x['dist_int_nb_self'],\n",
    "               'full_vs_self': lambda x: x['self']/x['dist_int_nb_self'],\n",
    "            'full_vs_dist': lambda x: x['dist']/x['dist_int_nb_self'],\n",
    "            })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(dat_mod_stats.merge(dat_condmeta).merge(dat_pannel_ord, left_on=V.COL_CHANNELNAME, right_on=V.COL_METAL, how='left')\n",
    " .rename(columns={'class': 'mark_class'})\n",
    " .query('mark_class== \"egf\"')\n",
    " .query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    " .pivot_table(index=[V.COL_IDCHANNAME,  V.COL_CELLLINE],columns=[V.COL_MODELCLASS_F], values=V.COL_R2)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, dat = do_r2_barplot(tdat.merge(dat_condmeta).merge(dat_pannel_ord, left_on=V.COL_CHANNELNAME, right_on=V.COL_METAL, how='left'),\n",
    "                         r_var,\n",
    "                         xgrpvars=[V.COL_CONC, V.COL_TP,  V.COL_IDCHANNAME, COL_CLASS],\n",
    "              ygrpvars=V.COL_CELLLINE,\n",
    "                         col_mclass=V.COL_MODELCLASS+'2',\n",
    "                        group_offsets =[0,0.3,2,1],\n",
    "                        labelvar=V.COL_IDCHANNAME)\n",
    "\n",
    "#fig.savefig(fol_out_paper/'fig4_overview_variability_explained.pdf')\n",
    "#fig"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, dat = do_r2_barplot(tdat\n",
    "                              .merge(dat_condmeta)\n",
    "                               .query(f'{V.COL_CONDNAME} in {C.main_conds}'),\n",
    "                         r_var,\n",
    "                         xgrpvars=[ V.COL_IDCHANNAME],\n",
    "              ygrpvars=V.COL_CELLLINE,\n",
    "                         group_offsets =[0],\n",
    "                         triangle_annotations=False,\n",
    "                         col_mclass=V.COL_MODELCLASS+'2',\n",
    "                            bar_width=0.9,\n",
    "                        figsize=(7,5),\n",
    "                        legend_anchor=(1.1,0.5),\n",
    "                        subplot_label_offset=1,\n",
    "                        channel_text_size=10)\n",
    "fig.savefig(fol_out_paper/'fig4_overview_variability_explained_maincond.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'font.size': 6}):\n",
    "    fig, dat = do_r2_barplot(tdat.merge(dat_condmeta).groupby([V.COL_CELLLINE, V.COL_MODELCLASS+'2'])[r_var]\n",
    "                         .mean().reset_index().assign(x=1),\n",
    "                         r_var,\n",
    "                         xgrpvars=[ V.COL_CELLLINE],\n",
    "                         \n",
    "              ygrpvars='x',\n",
    "                         group_offsets =[0],\n",
    "                         triangle_annotations=False,\n",
    "                         channel_annotations=True,\n",
    "                         col_mclass=V.COL_MODELCLASS+'2',\n",
    "                            bar_width=0.9,\n",
    "                        legend_anchor=(1.,0.5),\n",
    "                             channel_text_size=5,\n",
    "                             figsize=(1.7,1.7),\n",
    "                  channel_rotation=0)\n",
    "\n",
    "ax = fig.axes[0]\n",
    "ax.yaxis.set_ticks(np.arange(0, 1.2, 0.2))\n",
    "fig.savefig(fol_out_paper / 'overview_allcond.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, dat = do_r2_barplot(tdat.merge(dat_condmeta).merge(dat_med.query(f'{V.COL_VALUE} > (1/2**16)')).groupby([V.COL_TP, V.COL_CONC,V.COL_CELLLINE, V.COL_MODELCLASS+'2'])[r_var]\n",
    "                         .mean().reset_index().assign(x=1),\n",
    "                         r_var,\n",
    "                         xgrpvars=[V.COL_CONC, V.COL_TP, V.COL_CELLLINE],\n",
    "                         \n",
    "              ygrpvars='x',\n",
    "                        # group_offsets =[0],\n",
    "                         triangle_annotations=True,\n",
    "                         channel_annotations=True,\n",
    "                         col_mclass=V.COL_MODELCLASS+'2',\n",
    "                            bar_width=0.9,\n",
    "                        figsize=(7,5),\n",
    "                        legend_anchor=(1.1,0.5),\n",
    "                        subplot_label_offset=1,\n",
    "                        channel_text_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, dat = do_r2_barplot(tdat.merge(dat_condmeta).groupby([V.COL_TP, V.COL_CONC,V.COL_CELLLINE, V.COL_MODELCLASS+'2'])[r_var]\n",
    "                         .mean().reset_index().assign(x=1),\n",
    "                         r_var,\n",
    "                         xgrpvars=[V.COL_CONC, V.COL_TP, V.COL_CELLLINE],\n",
    "                         \n",
    "              ygrpvars='x',\n",
    "                        # group_offsets =[0],\n",
    "                         triangle_annotations=True,\n",
    "                         channel_annotations=True,\n",
    "                         col_mclass=V.COL_MODELCLASS+'2',\n",
    "                            bar_width=0.9,\n",
    "                        figsize=(7,5),\n",
    "                        legend_anchor=(1.1,0.5),\n",
    "                        subplot_label_offset=1,\n",
    "                        channel_text_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Do this plot filtered for markers with > log(1) median count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, dat = do_r2_barplot(tdat.merge(dat_condmeta).groupby([V.COL_CELLLINE, V.COL_MODELCLASS+'2', V.COL_MODELCLASS])[r_var]\n",
    "                         .mean().reset_index().assign(x=1),\n",
    "                         r_var,\n",
    "                         xgrpvars=[V.COL_CELLLINE],\n",
    "                         \n",
    "              ygrpvars='x',\n",
    "                        # group_offsets =[0],\n",
    "                         triangle_annotations=False,\n",
    "                         channel_annotations=True,\n",
    "                         col_mclass=V.COL_MODELCLASS+'2',\n",
    "                            bar_width=0.9,\n",
    "                        figsize=(7,5),\n",
    "                        legend_anchor=(1.1,0.5),\n",
    "                        subplot_label_offset=1,\n",
    "                        channel_text_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = (tdat.merge(dat_condmeta).groupby([V.COL_CELLLINE, V.COL_MODELCLASS+'2', V.COL_MODELCLASS])[r_var]\n",
    "                         .mean().reset_index().assign(x=1))\n",
    "fig, dat = do_r2_barplot(d,\n",
    "                         r_var,\n",
    "                         xgrpvars=[V.COL_CELLLINE],\n",
    "                         \n",
    "              ygrpvars='x',\n",
    "                        # group_offsets =[0],\n",
    "                         triangle_annotations=False,\n",
    "                         channel_annotations=True,\n",
    "                         col_mclass=V.COL_MODELCLASS+'2',\n",
    "                            bar_width=0.9,\n",
    "                        figsize=(3,2),\n",
    "                        legend_anchor=(1.1,0.5),\n",
    "                        subplot_label_offset=1,\n",
    "                        channel_text_size=5)\n",
    "fig.show()\n",
    "display(d.groupby([V.COL_MODELCLASS+'2'])[V.COL_R2].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def c_stats(x):\n",
    "    xnb = x.query(f'{V.COL_MODELCLASS} == \"dist_nb_self\"')[V.COL_R2].values[0]\n",
    "    xfull = x.query(f'{V.COL_MODELCLASS} == \"dist_int_nb_self\"')[V.COL_R2].values[0]\n",
    "    xcc = x.query(f'{V.COL_MODELCLASS} == \"dist_nb_self_cc\"')[V.COL_R2].values[0]\n",
    "    xdist = x.query(f'{V.COL_MODELCLASS} == \"dist\"')[V.COL_R2].values[0]\n",
    "    return pd.Series({'full': xfull,\n",
    "                      'nb': xnb,\n",
    "                      'frac_int': xnb/xfull,\n",
    "                     'eff_cc': xcc-xnb,\n",
    "                     'frac_dist': xdist/xnb})\n",
    "\n",
    "\n",
    "\n",
    "# overll\n",
    "d = (tdat.merge(dat_condmeta).groupby([V.COL_CELLLINE, V.COL_MODELCLASS+'2', V.COL_MODELCLASS])[r_var]\n",
    "                         .mean().reset_index().assign(x=1))\n",
    "dstat = d.groupby([V.COL_CELLLINE]).apply(c_stats)\n",
    "display(dstat)\n",
    "display(dstat.describe())\n",
    "# strong markers only\n",
    "d = (tdat.merge(dat_condmeta).merge(dat_med.query(f'{V.COL_VALUE} > (1/2**16)')).groupby([V.COL_CELLLINE, V.COL_MODELCLASS+'2', V.COL_MODELCLASS])[r_var]\n",
    "                         .mean().reset_index().assign(x=1))\n",
    "dstat = d.groupby([V.COL_CELLLINE]).apply(c_stats)\n",
    "display(dstat)\n",
    "display(dstat.describe())\n",
    "\n",
    "# all conditions\n",
    "# strong markers only\n",
    "d = (tdat.merge(dat_condmeta).merge(dat_med.query(f'{V.COL_VALUE} > -(1/2**16)')).groupby([V.COL_CELLLINE, V.COL_CONDNAME, V.COL_MODELCLASS+'2', V.COL_MODELCLASS])[r_var]\n",
    "                         .mean().reset_index().assign(x=1))\n",
    "dstat = d.groupby([V.COL_CONDNAME]).apply(c_stats)\n",
    "display(dstat)\n",
    "display(dstat.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Calculate the coefficient of variation of all the submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all conditions\n",
    "# strong markers only\n",
    "import scipy.stats\n",
    "\n",
    "d = (tdat.merge(dat_condmeta)\n",
    "     #.merge(dat_med.query(f'{V.COL_VALUE} > (1/2**16)'))\n",
    "     .groupby([V.COL_CELLLINE,  V.COL_MODELCLASS+'2', V.COL_MODELCLASS, V.COL_CHANNELNAME])[V.COL_R2]\n",
    "    .agg(**{'sd': np.std, 'mn': np.mean})\n",
    "    .groupby([V.COL_CELLLINE,  V.COL_MODELCLASS+'2', V.COL_MODELCLASS])\n",
    "        .apply(lambda x: np.mean(x['sd']))\n",
    "    )\n",
    "display(d)\n",
    "#display(d.groupby([ V.COL_MODELCLASS+'2', V.COL_MODELCLASS]).describe())\n",
    "display(d.groupby([ V.COL_MODELCLASS+'2', V.COL_MODELCLASS]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "d = (tdat.merge(dat_condmeta)\n",
    "     #.merge(dat_med.query(f'{V.COL_VALUE} > (1/2**16)'))\n",
    "     .groupby([V.COL_CELLLINE,  V.COL_MODELCLASS+'2', V.COL_MODELCLASS,\n",
    "               V.COL_CHANNELNAME])[V.COL_R2]\n",
    "     .mean()\n",
    "     .groupby([V.COL_MODELCLASS+'2', V.COL_MODELCLASS, V.COL_CHANNELNAME])\n",
    "    .agg(**{'sd': np.std, 'mn': np.mean})\n",
    "    .groupby([V.COL_MODELCLASS+'2', V.COL_MODELCLASS])\n",
    "        .apply(lambda x: np.mean(x['sd']))\n",
    "    )\n",
    "display(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all conditions\n",
    "# strong markers only.query(f'{V.COL_CONDNAME} in {C.main_conds}'),\n",
    "\n",
    "\n",
    "d = (tdat.merge(dat_condmeta)\n",
    "     #.merge(dat_med.query(f'{V.COL_VALUE} > (1/2**16)'))\n",
    "     .groupby([V.COL_CELLLINE,  V.COL_MODELCLASS+'2', V.COL_MODELCLASS, V.COL_CHANNELNAME])[V.COL_R2].mean()\n",
    "  .groupby([ V.COL_MODELCLASS+'2', V.COL_MODELCLASS, V.COL_CHANNELNAME]).apply(np.std)\n",
    "         .groupby([ V.COL_MODELCLASS+'2', V.COL_MODELCLASS ]).describe())\n",
    "display(d)\n",
    "\n",
    "d = (tdat.merge(dat_condmeta)\n",
    "     .query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    "    # .merge(dat_med.query(f'{V.COL_VALUE} > (1/2**16)'))\n",
    "     .groupby([V.COL_CELLLINE,  V.COL_MODELCLASS+'2', V.COL_MODELCLASS, V.COL_CHANNELNAME])[V.COL_R2].median()\n",
    "  .groupby([ V.COL_MODELCLASS+'2', V.COL_MODELCLASS, V.COL_CHANNELNAME]).apply(np.std)\n",
    "         .groupby([ V.COL_MODELCLASS+'2', V.COL_MODELCLASS ]).describe())\n",
    "display(d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate \n",
    "import scipy.stats\n",
    "import qgrid\n",
    "d = (tdat.merge(dat_condmeta)\n",
    "     #.merge(dat_med.query(f'{V.COL_VALUE} > (1/2**16)'))\n",
    "     .groupby([V.COL_CHANNEL, V.COL_MODELCLASS+'2', V.COL_MODELCLASS,V.COL_CELLLINE,  V.COL_CHANNELNAME ])[V.COL_R2]\n",
    "    .describe()\n",
    "\n",
    "    )\n",
    "d['frac_tot'] = ((d.groupby([V.COL_CHANNEL,\n",
    "            V.COL_CELLLINE,  V.COL_CHANNELNAME ],as_index=False)\n",
    "    .apply(lambda x: x['mean']/x.query(f'{V.COL_MODELCLASS}==\"dist_int_nb_self\"')['mean'].values[0])\n",
    "            ).reset_index(0, drop=True))\n",
    "d['frac_spac'] = ((d.groupby([V.COL_CHANNEL,\n",
    "            V.COL_CELLLINE,  V.COL_CHANNELNAME ],as_index=False)\n",
    "    .apply(lambda x: x['mean']/x.query(f'{V.COL_MODELCLASS}==\"dist_nb_self\"')['mean'].values[0])\n",
    "            ).reset_index(0, drop=True))\n",
    "qgrid.show_grid(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, dat = do_r2_barplot(tdat.merge(dat_condmeta).groupby([V.COL_TP, V.COL_CONC,V.COL_CELLLINE, V.COL_MODELCLASS+'2'])\n",
    "                         .mean().reset_index().assign(x=1),\n",
    "                         r_var,\n",
    "                         xgrpvars=[V.COL_CONC, V.COL_TP, V.COL_CELLLINE],\n",
    "                         \n",
    "              ygrpvars='x',\n",
    "                        # group_offsets =[0],\n",
    "                         triangle_annotations=True,\n",
    "                         channel_annotations=True,\n",
    "                         col_mclass=V.COL_MODELCLASS+'2',\n",
    "                            bar_width=0.9,\n",
    "                        figsize=(7,5),\n",
    "                        legend_anchor=(1.1,0.5),\n",
    "                        subplot_label_offset=1,\n",
    "                        channel_text_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(x):\n",
    "    return pd.Series({'dist': 0,\n",
    "       'dist_nb': x['dist_nb']-x['nb'],\n",
    "       'dist_nb_self':  x['dist_nb_self']-x['self'],\n",
    "       'dist_nb_self_cc': x['dist_nb_self_cc']-x['cc'],\n",
    "       'dist_int_nb_self':  x['dist_int_nb_self']-x['int']})\n",
    "\n",
    "def get_delta_dat(dat):\n",
    "    d_wide = dat.pivot_table(V.COL_R2, [V.COL_CHANNELNAME, V.COL_CONDNAME],V.COL_MODELCLASS)\n",
    "    return d_wide\n",
    "    #d_wide.apply(, axis=0)\n",
    "    \n",
    "\n",
    "curdat = dat_mod_stats\n",
    "\n",
    "d=get_delta_dat(curdat)\n",
    "d = d.apply(get_stats, axis=1)\n",
    "d.columns.name = V.COL_MODELCLASS\n",
    "d = d.stack()\n",
    "d.name = 'delta'\n",
    "d=d.reset_index(drop=False)\n",
    "curdat = curdat.merge(d)\n",
    "V.COL_TEST = 'test'\n",
    "curdat[V.COL_TEST] = pd.Categorical(curdat[V.COL_MODELCLASS], categories=['dist', 'nb','dist_nb', 'self', 'dist_nb_self', 'cc', 'dist_nb_self_cc', 'int', 'dist_int_nb_self'])\n",
    "curdat[V.COL_MODELCLASS+'2'] = pd.Categorical(\n",
    "    curdat[V.COL_MODELCLASS], categories=reversed(mods)\n",
    "    ).rename_categories(mod_lab)\n",
    "\n",
    "(gg.ggplot(curdat.query(f'({V.COL_CONDNAME} in {C.main_conds})'), gg.aes(x=V.COL_TEST))+\n",
    "     gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "    gg.geom_bar(gg.aes( y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity')+\n",
    "    gg.geom_bar(gg.aes( y='delta'),stat='identity')+\n",
    "    gg.theme(figure_size=(5,30))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(curdat.query(f'({V.COL_CONDNAME} in {C.main_conds})'), gg.aes(x=V.COL_TEST))+\n",
    "     gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "    gg.geom_bar(gg.aes( y=f'{V.COL_R2}-delta', fill=V.COL_MODELCLASS+'2'),stat='identity')+\n",
    "    gg.theme(figure_size=(5,30))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(x):\n",
    "    return pd.Series({'dist': 0,\n",
    "       'dist_nb': x['dist_nb']-x['nb'],\n",
    "       'dist_nb_self':  x['dist_nb_self']-x['self'],\n",
    "       'dist_nb_self_cc': x['dist_nb_self_cc']-x['cc'],\n",
    "       'dist_int_nb_self':  x['dist_int_nb_self']-x['int']})\n",
    "\n",
    "def get_delta_dat(dat):\n",
    "    d_wide = dat.pivot_table(V.COL_R2, [V.COL_CHANNELNAME, V.COL_CONDNAME],V.COL_MODELCLASS)\n",
    "    return d_wide\n",
    "    #d_wide.apply(, axis=0)\n",
    "    \n",
    "\n",
    "curdat = dat_mod_stats\n",
    "\n",
    "d=get_delta_dat(curdat)\n",
    "d = d.apply(get_stats, axis=1)\n",
    "d.columns.name = V.COL_MODELCLASS\n",
    "d = d.stack()\n",
    "d.name = 'delta'\n",
    "d=d.reset_index(drop=False)\n",
    "curdat = curdat.merge(d)\n",
    "V.COL_TEST = 'test'\n",
    "curdat[V.COL_TEST] = pd.Categorical(curdat[V.COL_MODELCLASS], categories=['dist', 'nb','dist_nb', 'self', 'dist_nb_self', 'cc', 'dist_nb_self_cc', 'int', 'dist_int_nb_self'])\n",
    "curdat[V.COL_MODELCLASS+'2'] = pd.Categorical(\n",
    "    curdat[V.COL_MODELCLASS], categories=reversed(mods)\n",
    "    ).rename_categories(mod_lab)\n",
    "\n",
    "(gg.ggplot(curdat.query(f'({V.COL_CONDNAME} in {C.main_conds})'), gg.aes(x=V.COL_TEST))+\n",
    "     gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "    gg.geom_bar(gg.aes( y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity')+\n",
    "    gg.geom_bar(gg.aes( y='delta'),stat='identity')+\n",
    "    gg.theme(figure_size=(5,30))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=(curdat.groupby([V.COL_MODELCLASS + '2',V.COL_TEST])[[V.COL_R2,'delta']].mean().reset_index()\n",
    " >>\n",
    "gg.ggplot(gg.aes(x=1, y=r_var))+\n",
    "           #gg.facet_grid('.~'+V.COL_IDCHANNAME, scales='free_x')+\n",
    "           #gg.facet_grid(V.COL_CONDITION+'~.')+\n",
    "              gg.geom_hline(gg.aes(yintercept=1))+\n",
    "             gg.geom_hline(gg.aes(yintercept=0))+ \n",
    "          \n",
    "           \n",
    " #gg.geom_line(gg.aes(group=V.COL_IDCHANNAME), position=gg.position_dodge(width=0.2), alpha=0.5)+\n",
    "             #gg.geom_segment(gg.aes(xend=V.COL_IDCHANNAME, y=0, yend=V.COL_R2, group=V.COL_IDCHANNAME))+\n",
    "             gg.geom_bar(gg.aes(y=1 ), fill='grey', stat=\"identity\",position = \"identity\")+\n",
    "  gg.geom_bar(gg.aes(fill=V.COL_MODELCLASS+'2'), stat=\"identity\",position = \"identity\")+\n",
    "           gg.expand_limits(y=1)+\n",
    "            gg.ggtitle('Additional variance explained by extended models')+\n",
    "           gg.theme(axis_text_x = gg.element_text(angle = 90, hjust = 0.1), figure_size=(5,6)\n",
    "                   )           \n",
    "  )\n",
    "gg.ggsave(p, fol_out_paper / 'bar_concept.pdf')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def full(**kwargs):\n",
    "#    return 'full'\n",
    "full='full'\n",
    "p=(gg.ggplot(curdat.groupby([V.COL_MODELCLASS + '2',V.COL_TEST])[[V.COL_R2,'delta']].mean().reset_index() , gg.aes(x=V.COL_TEST))+\n",
    "    # gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "    gg.geom_bar(gg.aes( y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity')+\n",
    "    gg.geom_bar(gg.aes( y='delta'),stat='identity',fill='grey',)+\n",
    " \n",
    "    gg.geom_bar(gg.aes(y=1,x='full' ), fill='grey', stat=\"identity\",position = \"identity\")+\n",
    "      gg.geom_bar(gg.aes(x='full', y=V.COL_R2, fill=V.COL_MODELCLASS+'2'), stat=\"identity\",position = \"identity\")+\n",
    "   \n",
    "      gg.theme(figure_size=(5,5))\n",
    "\n",
    ")\n",
    "gg.ggsave(p, fol_out_paper / 'bar_concept.pdf')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curdat[V.COL_TEST].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_bar = 0.6\n",
    "\n",
    "fillvar = 'fillvar'\n",
    "x_var = 'xvar'\n",
    "\n",
    "fill_labels = {'cell state': 'Full cell state',\n",
    "              'cellcycle': 'Cell cycle markers',\n",
    "              'autocorr': 'Autocorrelation',\n",
    "              'local nb': 'Neighbourhood',\n",
    "              'global env': 'Environment'}\n",
    "\n",
    "dtfill = curdat[V.COL_MODELCLASS + '2'].dtype\n",
    "curdat[fillvar] = (curdat[V.COL_MODELCLASS + '2'].cat\n",
    "                   .rename_categories({c: c.replace('+','').strip() for c in dtfill.categories}))\n",
    "curdat[x_var] = (curdat[V.COL_MODELCLASS+'2'].cat.set_categories(reversed(dtfill.categories)))\n",
    "\n",
    "tdat = (curdat\n",
    "   .groupby(list(set([fillvar, x_var])),observed=True)[[V.COL_R2,'delta']]\n",
    "   .mean()\n",
    "      .reset_index()\n",
    "   .assign(**{x_var: lambda x: x[x_var].cat.remove_unused_categories()\n",
    "                                     .cat.add_categories(['full'])\n",
    "                 }))\n",
    "        \n",
    "dt = tdat[x_var].dtype\n",
    "tdat[fillvar] = tdat[fillvar].cat.rename_categories(fill_labels)\n",
    "p= (tdat.sort_values(by=x_var, ascending=False)\n",
    "\n",
    "   >>\n",
    "    gg.ggplot(\n",
    "             gg.aes(x=x_var))\n",
    "    # gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "   + gg.geom_bar(gg.aes( y=V.COL_R2, fill=fillvar),stat='identity', width=width_bar)\n",
    "   + gg.geom_bar(gg.aes( y='delta'),stat='identity',fill='lightgrey', width=width_bar)\n",
    " \n",
    "   + gg.geom_bar(gg.aes(y=1,x='dt.categories[-1]' ), fill='grey', stat=\"identity\",position = \"identity\", width=width_bar)\n",
    "   +   gg.geom_bar(gg.aes(x='dt.categories[-1]', y=V.COL_R2, fill=fillvar),\n",
    "                  stat=\"identity\",position = \"identity\", width=width_bar)\n",
    "   # gg.geom_segment(gg.aes(x=f'({x_var}.cat.codes)+1-{width_bar}/2', xend=f'len(dt.categories)+{width_bar}/2',\n",
    "   #                        y=V.COL_R2, yend=V.COL_R2), linetype=':')+\n",
    "   + gg.geom_segment(gg.aes(x=f'({x_var}.cat.codes)+1-{width_bar}/2', xend=f'({x_var}.cat.codes)+2-{width_bar}/2',\n",
    "                          y=V.COL_R2, yend=V.COL_R2), linetype='-')\n",
    "       + gg.geom_segment(gg.aes(x=f'({x_var}.cat.codes)+1-{width_bar}/2', xend=f'({x_var}.cat.codes)+1+{width_bar}/2',\n",
    "                          y='delta', yend='delta'), linetype='-', color='grey')\n",
    "    \n",
    "           + gg.geom_segment(gg.aes(x=f'(len(dt.categories))-{width_bar}/2', xend=f'(len(dt.categories))+{width_bar}/2',\n",
    "                          y=V.COL_R2, yend=V.COL_R2), linetype='-', color='grey')\n",
    "   +    gg.geom_hline(yintercept=0)\n",
    "    \n",
    "   # + gg.scale_fill_manual(col_map)\n",
    "       #gg.geom_hline(yintercept=0.5,linetype='--')+\n",
    "   +    gg.xlab('')\n",
    "   +  gg.ylab('Variability Explained [R2]')\n",
    "   + gg.labs(fill='Modules')\n",
    "         + gg.theme_bw()\n",
    "   +   gg.theme(figure_size=(2.7,2),\n",
    "              axis_text_x=gg.element_text(size=5),\n",
    "              legend_text=gg.element_text(ha='left'),\n",
    "               text=gg.element_text(size=5))\n",
    "   + gg.coord_cartesian(ylim=(0,0.5))\n",
    "\n",
    "    + gg.scale_fill_manual(col_map,guide = gg.guide_legend(reverse = False),\n",
    "                    )\n",
    "    \n",
    "\n",
    ")\n",
    "#gg.ggsave(p, fol_out_paper / 'bar_concept.pdf')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.ggsave(p, fol_out_paper / 'bar_concept_1.pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "p_h = (p\n",
    " #+ gg.scale_x_discrete(limits=list(reversed((dt.categories))))\n",
    " + gg.coord_flip(xlim=(len(dt.categories),1), ylim=(0,0.6))\n",
    " + gg.theme(figure_size=(6,2))\n",
    "\n",
    "       +gg.scale_y_continuous(breaks=np.array(range(0,7))/10)\n",
    "           + gg.scale_fill_manual(col_map,guide = gg.guide_legend(reverse = True))\n",
    " #+ gg.geom_text(gg.aes(label=fillvar, y=f'({V.COL_R2}/2)+delta/2'),ha='center')\n",
    ")\n",
    "p_h"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "gg.ggsave(p_h, fol_out_paper / 'bar_concept_2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fol_out_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdat = (curdat\n",
    "   .groupby([V.COL_MODELCLASS + '2',V.COL_TEST],observed=True)[[V.COL_R2,'delta']]\n",
    "   .mean()\n",
    "      .reset_index()\n",
    "   .assign(**{V.COL_TEST: lambda x: x[V.COL_TEST].cat.remove_unused_categories()\n",
    "                                     .cat.add_categories(['full'])\n",
    "                 })\n",
    "       )\n",
    "dt = tdat[V.COL_TEST].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=tdat[V.COL_TEST].cat\n",
    "tdat[V.COL_TEST].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=(gg.ggplot(curdat.groupby([V.COL_MODELCLASS + '2',V.COL_TEST])[[V.COL_R2,'delta']].mean().reset_index() , gg.aes(x=V.COL_TEST))+\n",
    "    # gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "    gg.geom_bar(gg.aes( y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity')+\n",
    "    gg.geom_bar(gg.aes( y='delta'),stat='identity')+\n",
    "    gg.theme(figure_size=(5,5))\n",
    ")\n",
    "gg.ggsave(p, fol_out_paper / 'bar_concept.pdf')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(curdat.groupby([V.COL_MODELCLASS + '2',V.COL_TEST, V.COL_CONDNAME])[[V.COL_R2]].mean().reset_index().merge(dat_condmeta) ,\n",
    "           gg.aes(x=V.COL_CONC))+\n",
    "    gg.facet_grid(f'{V.COL_CELLLINE}~{V.COL_TP}+{V.COL_TEST}')+\n",
    "    gg.geom_bar(gg.aes( y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity')+\n",
    "    #gg.geom_bar(gg.aes( y='delta'),stat='identity')+\n",
    "    gg.theme(figure_size=(5,5))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(curdat.groupby([V.COL_MODELCLASS + '2',V.COL_TEST])[[V.COL_R2,'delta']].mean().reset_index() , gg.aes(x=V.COL_TEST))+\n",
    "    # gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "    gg.geom_bar(gg.aes( y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity')+\n",
    "    gg.geom_bar(gg.aes( y='delta'),stat='identity')+\n",
    "    gg.theme(figure_size=(5,5))\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "(gg.ggplot(curdat.groupby([V.COL_MODELCLASS + '2',V.COL_TEST])[[V.COL_R2,'delta']].mean().reset_index() , gg.aes(x=V.COL_TEST))+\n",
    "    # gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "    gg.geom_bar(gg.aes( y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity')+\n",
    "    gg.geom_bar(gg.aes( y='delta'),stat='identity')+\n",
    "    gg.geom_bar(gg.aes(x=\"all\", y=0.0222),stat='identity')+\n",
    "     gg.geom_bar(gg.aes(x=\"all\", y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity', position = \"identity\")+\n",
    "    gg.theme(figure_size=(2,5))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(curdat.groupby([V.COL_MODELCLASS + '2',V.COL_TEST])[[V.COL_R2,'delta']].mean().reset_index() ,\n",
    "           gg.aes(x='\"all\"'))+\n",
    "    # gg.facet_grid(f'{V.COL_GOODNAME}~{V.COL_CONDNAME}')+\n",
    "    gg.geom_bar(gg.aes( y=V.COL_R2, fill=V.COL_MODELCLASS+'2'),stat='identity', position = \"identity\")+\n",
    "    #gg.geom_bar(gg.aes( y='delta'),stat='identity')+\n",
    "    gg.theme(figure_size=(1,5))+\n",
    "     gg.coord_cartesian(ylim=(0,1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spider( x, y, present_categories = True, color=None, xsize=14, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    \n",
    "    y_dic = {c: val for c, val in zip(x,y)}\n",
    "    # number of variable\n",
    "    all_categories = x.unique()\n",
    "    if present_categories:\n",
    "        categories= [c for c in x.values.categories if c in all_categories]\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles_dic = {var: n / float(N) * 2 * pi for n, var in enumerate(categories)}\n",
    "    angles = [angles_dic[c] for c in categories]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.25,0.5,0.75,1], size=0)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    # Ind1\n",
    "    values= [y_dic.get(c,0) for c in categories]\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "    #ax.fill(angles, values, color=color, alpha=0.2)\n",
    "    labels = []\n",
    "    for label, a in zip(ax.get_xticklabels(),angles):\n",
    "        lab = ax.text(a,1.1, label.get_text(),ha=label.get_ha(), va=label.get_va(), size=xsize)\n",
    "        lab.set_rotation(-np.rad2deg(a))\n",
    "    ax.set_xticklabels([])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dic = {\"dist_int_nb_self\": 'full',\n",
    "            'cc': 'cellcycle',\n",
    "             'int': 'internal',\n",
    "    \n",
    "             \"dist_nb_self\" : 'full nb',\n",
    "             'nbcc': 'cellcycle nb',\n",
    "             'self': 'autocorr',\n",
    "             'nb': 'nb',\n",
    "             'dist': 'dist-to-rim'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_CONDNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_MODELCLASS_F2 = V.COL_MODELCLASS+'_factor2'\n",
    "V.COL_CONDNAME_F = V.COL_CONDNAME + 'factor'\n",
    "V.COL_CONDNAME_FR = V.COL_CONDNAME_F + 'R'\n",
    "dat_mod_stats[V.COL_MODELCLASS_F2] =  pd.Categorical(dat_mod_stats[V.COL_MODELCLASS],\n",
    "                                                                        categories=\n",
    "                                                                        [\"dist_int_nb_self\",\n",
    "                                                                         'int',\n",
    "                                                                          'cc',\n",
    "                                                                         \"dist_nb_self\",\n",
    "                                                                         'self',\n",
    "                                                                         'nb',\n",
    "                                                                         'dist'\n",
    "                                                                        \n",
    "                                                                         \n",
    "                                                                         ])\n",
    "\n",
    "cell_ord = dat_mod_stats[V.COL_CONDNAME].unique()\n",
    "dat_mod_stats[V.COL_CONDNAME_F] = pd.Categorical(dat_mod_stats[V.COL_CONDNAME] ,\n",
    "                                                    categories=cell_ord\n",
    "                                                   )\n",
    "dat_mod_stats[V.COL_CONDNAME_FR] = pd.Categorical(dat_mod_stats[V.COL_CONDNAME] ,\n",
    "                                                    categories=reversed(cell_ord)\n",
    "                                                   )\n",
    "\n",
    "dat_mod_stats[V.COL_MODELCLASS_F2] = dat_mod_stats[V.COL_MODELCLASS_F2].values.rename_categories(class_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_class = 'dist_nb_self'\n",
    "V.COL_GOODNAME_S = V.COL_GOODNAME + '_sorted'\n",
    "\n",
    "chan = V.COL_IDCHANNAME\n",
    "sort_val = dat_mod_stats.loc[dat_mod_stats[V.COL_MODELCLASS] == ref_class,:].groupby(chan)[V.COL_R2].max().reset_index()\n",
    "dat_mod_stats[V.COL_GOODNAME_S] = pd.Categorical(dat_mod_stats[chan],\n",
    "                  categories=sort_val.sort_values(V.COL_R2, ascending=False)[chan].tolist(), ordered=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats[V.COL_IDCHANNAME] = dat_mod_stats.apply(lambda x: x[V.COL_GOODNAME] + ' - ' + x[V.COL_CHANNELNAME], axis=1)\n",
    "\n",
    "cdat = dat_mod_stats.pivot_table(columns=V.COL_IDCHANNAME, values='r2_corr', index=[V.COL_CONDNAME_FR,V.COL_MODELCLASS])\n",
    "\n",
    "rlink =  hclust.linkage(cdat.T, method='ward',metric='euclidean')\n",
    "\n",
    "marklvl = cdat.columns[hclust.leaves_list(rlink)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats[V.COL_CONDNAME].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "with sns.axes_style(\"whitegrid\",  {'grid.color': '0.1', 'axes.edgecolor': '0.',\n",
    "                                  'grid.linestyle': 'dotted'}) as s:\n",
    "    g = sns.FacetGrid(dat_mod_stats.query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    "                      .merge(dat_condmeta), col=V.COL_GOODNAME_S, col_wrap=12,\n",
    "                      subplot_kws=dict(projection='polar'),\n",
    "                      sharex=False, sharey=False, despine=False,\n",
    "                     hue=V.COL_CELLLINE, height=5, legend_out=True)\n",
    "\n",
    "    # Draw a scatterplot onto each axes in the grid\n",
    "    g.map(make_spider, V.COL_MODELCLASS_F2, r_var,hue=V.COL_CELLLINE).add_legend()\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}', size=16, weight='bold')\n",
    "    g.set_xlabels('')\n",
    "    for ax in g.axes:\n",
    "        ax.title.set_position([.5, 1.1])\n",
    "        ax.yaxis.labelpad = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "with sns.axes_style(\"whitegrid\",  {'grid.color': '0.1', 'axes.edgecolor': '0.',\n",
    "                                  'grid.linestyle': 'dotted'}) as s:\n",
    "    sns.set_palette(\"deep\")\n",
    "    g = sns.FacetGrid(dat_mod_stats.query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    "                      .merge(dat_condmeta), col=V.COL_GOODNAME_S, col_wrap=7,\n",
    "                      subplot_kws=dict(projection='polar'),\n",
    "                      sharex=False, sharey=False, despine=False,\n",
    "                     hue=V.COL_CELLLINE, height=4)\n",
    "\n",
    "    # Draw a scatterplot onto each axes in the grid\n",
    "    g.map(make_spider, V.COL_MODELCLASS_F2, r_var, xsize=17)\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}', size=16, weight='bold')\n",
    "    g.set_xlabels('')\n",
    "    for ax in g.axes:\n",
    "        ax.title.set_position([.5, 1.1])\n",
    "        ax.yaxis.labelpad = 26\n",
    "        ax.xaxis.axes.set_xlabel('')\n",
    "    #plt.tight_layout()\n",
    "    g.set_xlabels('')\n",
    "    g.set_ylabels('')\n",
    "    g.add_legend()\n",
    "\n",
    "g.savefig(fol_out_paper/'spyder_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_fil = ((dat_mod_stats.groupby(V.COL_GOODNAME_S)[r_var].max() > 0.4)\n",
    "            .rename('fil')\n",
    "              .reset_index())\n",
    "dat_fil = dat_fil.query('fil == True')\n",
    "V.COL_GOODNAME_S_F = V.COL_GOODNAME_S+'fil'\n",
    "\n",
    "def adapt_missing_categories(catcol):\n",
    "    vals = np.unique(catcol.values)\n",
    "    cat = [c for c in pd.Categorical(catcol).categories if c in vals]\n",
    "    return pd.Categorical(catcol,categories=cat)\n",
    "\n",
    "dat_fil[V.COL_GOODNAME_S_F] = adapt_missing_categories(dat_fil[V.COL_GOODNAME_S])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Sort the markers by average variablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_RELVAR = 'rel_r2'\n",
    "ref_class ='dist_nb_self'\n",
    "V.COL_GOODNAME_S_VAR = V.COL_GOODNAME_S_F+'var'\n",
    "V.COL_VAR = 'var'\n",
    "dat_mod_stats[V.COL_RELVAR] = dat_mod_stats.groupby(V.COL_GOODNAME)[r_var].transform(lambda x: x/x.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dat_varname = (dat_mod_stats\n",
    " .merge(dat_fil)\n",
    " .groupby([V.COL_GOODNAME, V.COL_MODELCLASS_F2])[V.COL_RELVAR].apply(lambda x: np.std(x))\n",
    " .groupby(V.COL_GOODNAME).max()\n",
    " .rename(V.COL_VAR)\n",
    " .sort_values(ascending=False)\n",
    "  .reset_index()\n",
    ")\n",
    "dat_varname[V.COL_GOODNAME_S_VAR] = pd.Categorical(dat_varname[V.COL_GOODNAME],categories=dat_varname[V.COL_GOODNAME])\n",
    "trow_var = 'row'\n",
    "dat_varname[trow_var] = [i % 3 for i in range(dat_varname.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "fns_out = [os.path.join(fol_out, f'spiderplots_row{f}.png') for f in range(3)]\n",
    "for r in range(3):\n",
    "    with sns.axes_style(\"whitegrid\",  {'grid.color': '0.1', 'axes.edgecolor': '0.',\n",
    "                                      'grid.linestyle': 'dotted'}) as s:\n",
    "        sns.set_palette(\"deep\")\n",
    "        tdat = (dat_mod_stats.merge(dat_fil).merge(dat_varname).query(f'{trow_var} == {r}').query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    "                      .merge(dat_condmeta))\n",
    "        tdat['col'] = adapt_missing_categories(tdat[V.COL_GOODNAME_S])\n",
    "        g = sns.FacetGrid(tdat, \n",
    "                          col='col', col_wrap=11,\n",
    "                          subplot_kws=dict(projection='polar'),\n",
    "                          sharex=False, sharey=False, despine=False,\n",
    "                         hue=V.COL_CELLLINE, height=3.5)\n",
    "\n",
    "        # Draw a scatterplot onto each axes in the grid\n",
    "        g.map(make_spider, V.COL_MODELCLASS_F2, r_var, xsize=17)\n",
    "        g.set_titles(row_template = '{row_name}', col_template = '{col_name}', size=16, weight='bold')\n",
    "        g.set_xlabels('')\n",
    "        for ax in g.axes:\n",
    "            ax.title.set_position([.5, 1.1])\n",
    "            ax.yaxis.labelpad = 26\n",
    "            ax.xaxis.axes.set_xlabel('')\n",
    "        g.fig.subplots_adjust(top=.8)\n",
    "        g.fig.savefig(fns_out[r])\n",
    "    #plt.tight_layout()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_cond(col):\n",
    "    return pd.Categorical(col, categories=[\"DLD1\", \"T47D\", \"293T\", 'HT29'])\n",
    "(gg.ggplot(dat_mod_stats.loc[dat_mod_stats[V.COL_MODELCLASS] == 'dist_int_nb_self',:],\n",
    "          gg.aes(x=r_var, fill=V.COL_CONDNAME_F))+\n",
    "         gg.facet_grid(V.COL_CONDNAME_F+'~.')+\n",
    "         gg.geom_histogram(color='black', breaks= [x/10+0.1 for x in range(10)])+\n",
    "        gg.xlim((0,1))+\n",
    "        gg.xlab('R2')+\n",
    "        gg.theme_seaborn(style='whitegrid',context='talk')+\n",
    "        gg.scale_color_cmap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doplot(x, y, color, label):\n",
    "    ax = plt.gca()\n",
    "    xval = x.values.codes\n",
    "    o = np.argsort(xval)\n",
    "    y = y.values\n",
    "    ax.plot(xval[o], y[o], color=color, linewidth=2, linestyle='solid')\n",
    "    ax.scatter(xval[o], y[o], color=color, linewidth=2, linestyle='solid')\n",
    "    ax.fill_between(xval[o], 0, y[o], color=color, alpha=0.2)\n",
    "    \n",
    "\n",
    "    ax.set_xticks(np.arange(len(xval)))\n",
    "    ax.set_xticklabels(x.values.categories,rotation=90)\n",
    "    plt.yticks([0, 0.25,0.5,0.75,1], size=10)\n",
    "    \n",
    "    plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mark = ['Er166', 'Nd150','Yb171', 'Er168']\n",
    "dic = {r[V.COL_CHANNELNAME]: r[V.COL_GOODNAME] for i,r in dat_mod_stats.iterrows() }\n",
    "example_goodname = [dic[g] for g in example_mark]\n",
    "V.COL_GOODNAME_SLECT = V.COL_GOODNAME +'select'\n",
    "\n",
    "dat_mod_stats[V.COL_GOODNAME_SLECT] = pd.Categorical(dat_mod_stats[V.COL_GOODNAME],\n",
    "                                                  categories=example_goodname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "with sns.axes_style(\"whitegrid\", {'grid.color': '0.1', 'axes.edgecolor': '0.',\n",
    "                                  'grid.linestyle': 'dotted'}) as s:\n",
    "    g = sns.FacetGrid(dat_mod_stats.loc[(dat_mod_stats[V.COL_CHANNELNAME].isin(example_mark)) &\n",
    "                             (dat_mod_stats[V.COL_MODELCLASS_F2].isna() == False)].query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    "                      .merge(dat_condmeta),\n",
    "                      col=V.COL_GOODNAME_SLECT,\n",
    "                      sharex=False, sharey=False, despine=False,\n",
    "                     hue=V.COL_CELLLINE)\n",
    "\n",
    "    # Draw a scatterplot onto each axes in the grid\n",
    "    g.map(doplot, V.COL_MODELCLASS_F2, V.COL_R2)\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}',\n",
    "             size=16, weight='bold')\n",
    "    g.set_xlabels('')\n",
    "    #g.map(plt.fill, V.COL_MODELCLASS_F2, V.COL_R2,color=color, alpha=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "with sns.axes_style(\"whitegrid\", {'grid.color': '0.1', 'axes.edgecolor': '0.',\n",
    "                                  'grid.linestyle': 'dotted'}) as s:\n",
    "    g = sns.FacetGrid(dat_mod_stats.loc[(dat_mod_stats[V.COL_CHANNELNAME].isin(example_mark)) &\n",
    "                             (dat_mod_stats[V.COL_MODELCLASS_F2].isna() == False) & \n",
    "                                       (dat_mod_stats[V.COL_CONDNAME] == 'HT29')],\n",
    "                      col=V.COL_GOODNAME_SLECT,\n",
    "                      sharex=False, sharey=False, despine=False,\n",
    "                     hue=V.COL_CONDNAME_FR)\n",
    "\n",
    "    # Draw a scatterplot onto each axes in the grid\n",
    "    g.map(doplot, V.COL_MODELCLASS_F2, V.COL_R2)\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}',\n",
    "             size=16, weight='bold')\n",
    "    g.set_xlabels('')\n",
    "    #g.map(plt.fill, V.COL_MODELCLASS_F2, V.COL_R2,color=color, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with sns.axes_style(\"whitegrid\",  {'grid.color': '0.1', 'axes.edgecolor': '0.',\n",
    "                                  'grid.linestyle': 'dotted'}) as s:\n",
    "    sns.set_palette(\"deep\")\n",
    "    g = sns.FacetGrid(dat_mod_stats.loc[(dat_mod_stats[V.COL_CHANNELNAME].isin(example_mark)) &\n",
    "                             (dat_mod_stats[V.COL_MODELCLASS_F2].isna() == False)].query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    "                      .merge(dat_condmeta),\n",
    "                      col=V.COL_GOODNAME_SLECT, col_wrap=6,\n",
    "                      subplot_kws=dict(projection='polar'),\n",
    "                      sharex=False, sharey=False, despine=False,\n",
    "                     hue=V.COL_CELLLINE, height=4)\n",
    "\n",
    "    # Draw a scatterplot onto each axes in the grid\n",
    "    g.map(make_spider, V.COL_MODELCLASS_F2, V.COL_R2)\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}', size=16, weight='bold')\n",
    "    for ax in g.axes:\n",
    "        ax.title.set_position([.5, 1.1])\n",
    "        ax.yaxis.labelpad = 25\n",
    "    g.set_xlabels('')\n",
    "    g.set_ylabels('')\n",
    "g.savefig(fol_out_paper/'spyderexamples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with sns.axes_style(\"whitegrid\",  {'grid.color': '0.1', 'axes.edgecolor': '0.',\n",
    "                                  'grid.linestyle': 'dotted'}) as s:\n",
    "    sns.set_palette(\"deep\")\n",
    "    tmpdat = (dat_mod_stats.loc[(dat_mod_stats[V.COL_CHANNELNAME].isin(example_mark)) &\n",
    "                             (dat_mod_stats[V.COL_MODELCLASS_F2].isna() == False)]\n",
    "              .query(f'{V.COL_CONDNAME} in {C.main_conds}')\n",
    "                      .merge(dat_condmeta))\n",
    "    for cl, grp in tmpdat.groupby(V.COL_CELLLINE):\n",
    "        g = sns.FacetGrid(grp,\n",
    "                          col=V.COL_GOODNAME_SLECT, col_wrap=6,\n",
    "                          subplot_kws=dict(projection='polar'),\n",
    "                          sharex=False, sharey=False, despine=False,\n",
    "                         hue=V.COL_CELLLINE, height=4)\n",
    "\n",
    "        # Draw a scatterplot onto each axes in the grid\n",
    "        g.map(make_spider, V.COL_MODELCLASS_F2, V.COL_R2)\n",
    "        g.set_titles(row_template = '{row_name}', col_template = '{col_name}', size=16, weight='bold')\n",
    "        for ax in g.axes:\n",
    "            ax.title.set_position([.5, 1.1])\n",
    "            ax.yaxis.labelpad = 25\n",
    "        g.set_xlabels('')\n",
    "        g.fig.suptitle(cl, size=16)\n",
    "        g.fig.subplots_adjust(top=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with sns.axes_style(\"whitegrid\",  {'grid.color': '0.1', 'axes.edgecolor': '0.',\n",
    "                                  'grid.linestyle': 'dotted'}) as s:\n",
    "    g = sns.FacetGrid(dat_mod_stats.loc[(dat_mod_stats[V.COL_CHANNELNAME].isin(example_mark)) &\n",
    "                             (dat_mod_stats[V.COL_MODELCLASS_F2].isna() == False)& \n",
    "                                       (dat_mod_stats[V.COL_CONDNAME] == 'HT29')],\n",
    "                      col=V.COL_GOODNAME_SLECT, col_wrap=6,\n",
    "                      subplot_kws=dict(projection='polar'),\n",
    "                      sharex=False, sharey=False, despine=False,\n",
    "                     hue=V.COL_CONDNAME_FR)\n",
    "\n",
    "    # Draw a scatterplot onto each axes in the grid\n",
    "    g.map(make_spider, V.COL_MODELCLASS_F2, V.COL_R2)\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}', size=16, weight='bold')\n",
    "    for ax in g.axes:\n",
    "        ax.title.set_position([.5, 1.1])\n",
    "        ax.yaxis.labelpad = 25\n",
    "    g.set_xlabels('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_stats[V.COL_MODELCLASS_F2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_code(c):\n",
    "    return c.values.codes\n",
    "dat_mod_stats['ymin'] = 0\n",
    "(gg.ggplot(dat_mod_stats.loc[(dat_mod_stats[V.COL_CHANNELNAME].isin(example_mark)) &\n",
    "                             (dat_mod_stats[V.COL_MODELCLASS_F2].isna() == False)],\n",
    "          gg.aes(x='get_code('+V.COL_MODELCLASS_F2+')',y=V.COL_R2, \n",
    "                 fill=V.COL_CONDNAME_F,\n",
    "                color=V.COL_CONDNAME_F))+\n",
    "         gg.facet_grid(V.COL_GOODNAME_S+'~.')+\n",
    "         #gg.geom_ribbon(gg.aes(ymin='ymin',alpha=0.2,))+\n",
    "        gg.geom_line()+\n",
    "\n",
    "        gg.theme_seaborn(style='whitegrid',context='poster'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = (dat_mod_stats[V.COL_MODELCLASS_F2].isna() == False)\n",
    "\n",
    "dat_hm = dat_mod_stats.loc[fil].pivot_table(index=[V.COL_CHANNELNAME, V.COL_CONDNAME, V.COL_GOODNAME],values=V.COL_R2, columns=V.COL_MODELCLASS_F2)\n",
    "#dat_hm = dat_pca.query('dist_int_nb_self > 0.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Load per-condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_repstats = pd.read_csv(fn_modstats_perrep).rename(columns={V.COL_CONDNAME: V.COL_CONDID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dat_condtab = bro.doquery(bro.session.query(db.conditions)).rename(columns={'well_name': 'well'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_MODELCLASS_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COL_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcol = V.COL_R2\n",
    "chans=[\"Yb171\", \"Er168\"]\n",
    "(dat_mod_repstats.merge(dat_condtab).merge(dat_layout)\n",
    " .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans} ')>> \n",
    " gg.ggplot(gg.aes(x=V.COL_MODELCLASS, y=rcol , color=f'pd.Categorical({V.COL_TP})'))+\n",
    " gg.facet_grid(f'{V.COL_CELLLINE}~{V.COL_CONC}+{V.COL_CHANNELNAME}')+\n",
    " gg.geom_boxplot(outlier_alpha=0)+\n",
    " gg.geom_point()+\n",
    " gg.geom_point((dat_mod_stats.merge(dat_condmeta)\n",
    "              .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans}')), color='black', size=2)+\n",
    " gg.theme(figure_size=(14,14))\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcol = 'r2_adj_corr'\n",
    "chans=[\"Yb171\", \"Er168\"]\n",
    "(dat_mod_repstats.merge(dat_condtab).merge(dat_layout)\n",
    " .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans} ')>> \n",
    " gg.ggplot(gg.aes(x=V.COL_MODELCLASS, y=rcol , color=f'pd.Categorical({V.COL_TP})'))+\n",
    " gg.facet_grid(f'{V.COL_CELLLINE}~{V.COL_CONC}+{V.COL_CHANNELNAME}')+\n",
    " gg.geom_boxplot(outlier_alpha=0)+\n",
    " gg.geom_point()+\n",
    " gg.geom_point((dat_mod_stats.merge(dat_condmeta)\n",
    "              .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans}')), color='black', size=2)+\n",
    " gg.coord_cartesian(ylim=(0,1))+\n",
    " gg.theme(figure_size=(14,14))\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat_mod_repstats.merge(dat_condtab).merge(dat_layout).merge(dat_mod_stats[[V.COL_MODELCLASS, V.COL_MODELCLASS_F]].drop_duplicates().dropna())\n",
    " .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans} '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcol = 'r2_adj_corr'\n",
    "chans=[\"Yb171\", \"Er168\", \"Er166\"]\n",
    "(dat_mod_repstats.merge(dat_condtab).merge(dat_layout).merge(dat_mod_stats[[V.COL_MODELCLASS, V.COL_MODELCLASS_F]].drop_duplicates().dropna(subset=[V.COL_MODELCLASS_F]))\n",
    " .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans} ')>> \n",
    " gg.ggplot(gg.aes(x=V.COL_CONC, y=rcol , color=f'pd.Categorical({V.COL_TP})'))+\n",
    " gg.facet_grid(f'{V.COL_CELLLINE}~{V.COL_CHANNELNAME}+{V.COL_MODELCLASS}')+\n",
    " gg.geom_boxplot(outlier_alpha=0)+\n",
    " gg.geom_point()+\n",
    " gg.geom_point((dat_mod_stats.merge(dat_condmeta).dropna(subset=[V.COL_MODELCLASS_F])\n",
    "              .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans}')), color='black', size=2)+\n",
    " gg.coord_cartesian(ylim=(0,1))+\n",
    " gg.theme(figure_size=(14,14))\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcol = 'r2_adj_corr'\n",
    "chans=[\"Yb171\", \"Er168\", \"Er166\"]\n",
    "(dat_mod_repstats.merge(dat_condtab).merge(dat_layout).merge(dat_mod_stats[[V.COL_MODELCLASS, V.COL_MODELCLASS_F]].drop_duplicates().dropna(subset=[V.COL_MODELCLASS_F]))\n",
    " .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans} ')>> \n",
    " gg.ggplot(gg.aes(x=V.COL_CONC, y=rcol , color=f'pd.Categorical({V.COL_TP})'))+\n",
    " gg.facet_grid(f'{V.COL_MODELCLASS_F}~{V.COL_CELLLINE}+{V.COL_CHANNELNAME}')+\n",
    " gg.geom_boxplot(outlier_alpha=0)+\n",
    " gg.geom_point()+\n",
    " gg.geom_point((dat_mod_stats.merge(dat_condmeta).dropna(subset=[V.COL_MODELCLASS_F])\n",
    "              .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans}')), color='black', size=2)+\n",
    " gg.coord_cartesian(ylim=(0,1))+\n",
    " gg.theme(figure_size=(14,14))\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_condtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod_repstats.merge(dat_condtab).merge(dat_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat_mod_repstats.merge(dat_condtab).merge(dat_layout).merge(dat_mod_stats[[V.COL_MODELCLASS, V.COL_MODELCLASS_F, V.COL_CHANNELNAME, V.COL_GOODNAME]].drop_duplicates().dropna(subset=[V.COL_MODELCLASS_F]))\n",
    " .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans} ')\n",
    ".query('(modelclass == \"dist\") & (cellline == \"293T\") & (concentration==1)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_variab_rep_plot(chan='Yb171', rcol='r2_adj_corr',figsize=(14,7)):\n",
    "    chans = [chan]\n",
    "    p = (dat_mod_repstats\n",
    "              .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}').rename(columns={'No. Observations': 'ncells'})\n",
    "         .query(f'{V.COL_CHANNELNAME} in {chans} ')\n",
    "         \n",
    "         .merge(dat_condtab)\n",
    "         .merge(dat_layout)\n",
    "         .merge(dat_mod_stats[[V.COL_MODELCLASS, V.COL_MODELCLASS_F, V.COL_CHANNELNAME, V.COL_GOODNAME]].drop_duplicates().dropna(subset=[V.COL_MODELCLASS_F])) >> \n",
    "     gg.ggplot(gg.aes(x=f'pd.Categorical({V.COL_CONC})', y=rcol , fill=f'pd.Categorical({V.COL_TP})'))+\n",
    "     gg.facet_grid(f'{V.COL_MODELCLASS_F}~{V.COL_GOODNAME}+{V.COL_CELLLINE}+{V.COL_TP}')+\n",
    "     gg.geom_hline(yintercept=1)+\n",
    "     gg.geom_hline(yintercept=0)+\n",
    "     gg.geom_boxplot(outlier_alpha=0, color='gray', fill='white')+\n",
    "     gg.geom_jitter(gg.aes(size='(ncells)', shape='ncells <100'), alpha=0.8, height=0, width=0.2)+\n",
    "     gg.scale_size_area(max_size=4, breaks=(100,150,200,400))+\n",
    "     gg.geom_point((dat_mod_stats.merge(dat_condmeta).dropna(subset=[V.COL_MODELCLASS_F])\n",
    "                  .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    "     .query(f'{V.COL_CHANNELNAME} in {chans}')), color='black', size=2, fill='black')+\n",
    "     #gg.coord_cartesian(ylim=(0,1))+\n",
    "     gg.theme(figure_size=(14,7))+\n",
    "     gg.ylab('Variability explained [Adj. R2]')+\n",
    "     gg.xlab('Size')\n",
    "\n",
    "    )\n",
    "    return p\n",
    "\n",
    "do_variab_rep_plot()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [],
   "source": [
    "gg.save_as_pdf_pages((do_variab_rep_plot(chan=c) for c in dat_mod_repstats[V.COL_CHANNELNAME].unique()), filename=os.path.join(fol_out, 'per_rep_variab_v1.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_variab_rep_plot(rcol='r2_corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdat = (dat_mod_repstats\n",
    "         .merge(dat_condtab)\n",
    "         .merge(dat_layout)\n",
    "        .rename(columns={'No. Observations': 'ncells'})\n",
    "        .query('ncells > 100')\n",
    "         .groupby(by=[V.COL_MODELCLASS, V.COL_CHANNELNAME, V.COL_CELLLINE, V.COL_TP, V.COL_CONC],observed=True)['r2_adj_corr']\n",
    "         .agg(**{'std': lambda x: np.std(x, ddof=1),\n",
    "                'mn': np.mean,\n",
    "                'md': np.median,\n",
    "                'n': len}).reset_index()\n",
    "       .query('n > 3')\n",
    "         .merge(dat_mod_stats[[V.COL_MODELCLASS, V.COL_MODELCLASS_F, V.COL_CHANNELNAME, V.COL_GOODNAME]].drop_duplicates())\n",
    "      )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(tdat, gg.aes(x=V.COL_MODELCLASS, y='std', color=V.COL_CELLLINE))+\n",
    "    gg.geom_boxplot(color='gray', fill='gray')+\n",
    "    # gg.geom_violin()\n",
    "    gg.geom_jitter(height=0, width=0.3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(tdat.query(f'{V.COL_MODELCLASS_F} in {cluster_models+[\"dist_int_nb_self\"]}'), gg.aes(x=V.COL_CHANNELNAME, y='std', color=V.COL_CELLLINE))+\n",
    "     gg.facet_grid(f'{V.COL_MODELCLASS}~.')+\n",
    "    gg.geom_boxplot(color='gray', fill='gray')+\n",
    "    gg.geom_point()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(tdat.query(f'{V.COL_MODELCLASS_F} in {cluster_models+[\"dist_int_nb_self\"]}'), gg.aes(x='mn', y='std', color=V.COL_CELLLINE))+\n",
    "     gg.facet_grid(f'{V.COL_MODELCLASS_F}~.')+\n",
    "    gg.geom_point()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(tdat.query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]+[\"dist_nb_self_cc\"]}'), gg.aes(x='mn', y='std/np.abs(mn)'))+\n",
    "     gg.facet_grid(f'{V.COL_MODELCLASS}~.')+\n",
    "    gg.geom_point(alpha=0.1)+\n",
    " gg.coord_cartesian(ylim=(0,1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsum = tdat.groupby(by=[V.COL_MODELCLASS]).mean()\n",
    "print(tsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsum = tdat.query('mn>0.05').groupby(by=[V.COL_MODELCLASS]).mean()\n",
    "print(tsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsum.eval('std/mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdat.query('std>0.2').groupby([V.COL_GOODNAME],observed=True)['std'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat_mod_repstats.merge(dat_condtab).merge(dat_layout).merge(dat_mod_stats[[V.COL_MODELCLASS, V.COL_MODELCLASS_F]].drop_duplicates().dropna(subset=[V.COL_MODELCLASS_F]))\n",
    " .query(f'{V.COL_MODELCLASS} in {cluster_models+[\"dist_int_nb_self\"]}')\n",
    " .query(f'{V.COL_CHANNELNAME} in {chans} '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Check cell sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COL_CELLLINE = 'cellline'\n",
    "COL_CONC = 'conc'\n",
    "COL_ISTELOX = 'istelox'\n",
    "COL_TP = 'tp'\n",
    "def split_names(x):\n",
    "    c = re.compile('(?P<{}>.*)_c(?P<{}>.*)_tp(?P<{}>.*)'.format(COL_CELLLINE, COL_CONC, COL_TP))\n",
    "    \n",
    "    m = c.match(x)\n",
    "    g = m.groups() \n",
    "    return pd.Series({l: g[i-1] for l, i in c.groupindex.items()},name=x.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fn_size = sm.input.fn_bf_quantification\n",
    "# variables bfanalysis\n",
    "COL_BF_AREA = 'AreaShape_Area'\n",
    "COL_BF_WELL = 'Metadata_well'\n",
    "COL_BF_PLATE = 'Metadata_plate'\n",
    "COL_RADIUS = 'radius'\n",
    "\n",
    "dat_conditions=bro.doquery(bro.session.query(db.conditions))\n",
    "dat_conditions = dat_conditions.join(dat_conditions[V.COL_CONDNAME].apply(split_names))\n",
    "dat_conditions[COL_CONC] = dat_conditions[COL_CONC].astype(np.float)\n",
    "dat_size = pd.read_csv(fn_size)\n",
    "BF_RESOLTUION = 5*0.65\n",
    "def get_radius(area, resolution=BF_RESOLTUION):\n",
    "    r = np.sqrt(area/np.pi)\n",
    "    return r*resolution\n",
    "\n",
    "dat = dat_size.merge(dat_conditions, left_on=[COL_BF_PLATE,COL_BF_WELL], right_on=[db.conditions.plate_id.key, db.conditions.well_name.key] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[COL_RADIUS] = dat[COL_BF_AREA].map(get_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=(gg.ggplot(dat, gg.aes(x=COL_CELLLINE, y=COL_RADIUS, fill=COL_TP))+\n",
    "     gg.facet_wrap(f'{COL_CONC}')+\n",
    "     gg.geom_boxplot(outlier_size=0)+\n",
    "     gg.geom_point(position=gg.position_dodge(width=0.5))+\n",
    "    gg.expand_limits(y=0)+\n",
    "    gg.xlab('Cell line')+\n",
    "    gg.ylab('Radius [um]')+\n",
    "    gg.ggtitle('Spheroid Size before harvesting\\n(assessed by brightfield imaging)'))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(dat, gg.aes(x=COL_CONC, y=COL_RADIUS, color=COL_TP))+\n",
    "     gg.facet_wrap(f'{COL_CELLLINE}')+\n",
    "     #gg.geom_boxplot(outlier_size=0, position='dodge')+\n",
    "     gg.geom_line()+\n",
    "     gg.geom_jitter(height=0, width=0.05)+\n",
    "    gg.expand_limits(y=0)+\n",
    "    gg.xlab('Cell line')+\n",
    "    gg.ylab('Radius [um]')+\n",
    "    gg.ggtitle('Spheroid Size before harvesting\\n(assessed by brightfield imaging)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p=(gg.ggplot(dat, gg.aes(x=COL_CELLLINE, y=COL_RADIUS, fill=COL_TP))+\n",
    "     gg.facet_wrap(f'{COL_CONC}')+\n",
    "     gg.geom_boxplot(outlier_size=0)+\n",
    "     gg.geom_point(position=gg.position_dodge(width=0.5))+\n",
    "    gg.expand_limits(y=0)+\n",
    "    gg.xlab('Cell line')+\n",
    "    gg.ylab('Radius [um]')+\n",
    "    gg.ggtitle('Spheroid Size before harvesting\\n(assessed by brightfield imaging)'))\n",
    "gg.ggsave(p, fol_out_paper / 'spheroid_sizes.pdf')\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Equation\n",
    "$y_{pi} = \\beta_{pi} +BS(d^{distrim})+ \\sum_{m\\neq p}\\beta^{nb}_{m}x^{nb}_m +\\beta_p^{nb}x^{nb}_p + \\sum_{m\\neq p}\\beta^{int}_{m}x^{int}_m + \\epsilon_{pi}$"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.3.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
